{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1586a21125465ef9",
   "metadata": {},
   "source": [
    "# Learning Journey AIG03\n",
    "## Leverage Document Grounding in Orchestration Service for RAG-based Content Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe31aa9cca6fa00c",
   "metadata": {},
   "source": [
    "In this learning journey, you will learn how to leverage the Document Grounding module in the Orchestration Service to generate content using the Retrieval-Augmented Generation (RAG) approach.\n",
    "The Document Grounding module helps in grounding the input questions to relevant documents.\n",
    "The grounding process involves retrieving relevant documents from a knowledge base and using them to high-quality generate responses.\n",
    "The knowledge base can be a collection of documents in a sharepoint folder, an elastic search engine, or data repository which contains vectors.\n",
    "\n",
    "In this learning journey, you will perform the following steps:\n",
    "- Create the knowledge base with the relevant documents.\n",
    "- Configure the Document Grounding module in the Orchestration Service.\n",
    "- Generate content based on the knowledge base using the RAG approach.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1ac4ebb04b4d795",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Install the Generative AI Hub SDK using the following command:"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%pip install generative-ai-hub-sdk",
   "id": "a4213b94dc1a5813"
  },
  {
   "cell_type": "markdown",
   "id": "9028883617764b1e",
   "metadata": {},
   "source": [
    "How to set the credentials for the Generative AI Hub SDK:\n",
    "see the AICore documentation for available options. [Note: maybe show or recommend an option here like local config file or environment variables]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc07f1e08c8f2cf",
   "metadata": {},
   "source": [
    "#### Todo: Provide credentials for Sid.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e369ced4edfcddd0",
   "metadata": {},
   "source": [
    "#### Step 1: Create a Vector Knowledge Base\n",
    "   - Upload a set of documents which will automatically be vectorized and added to the knowledge base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435207f7dc460342",
   "metadata": {},
   "source": [
    "Thera are 2 options to create the Knowledge Base:\n",
    "- Upload the documents to a sharepoint folder and run Pipeline API to vectorize the documents. (This option includes more detailed steps, which we have not yet performed. We still miss some information here.)\n",
    "- Upload the documents via AI Data Management (https://help.sap.com/docs/sap-ai-core/generative-ai-hub/create-resource-group-for-ai-data-management?locale=en-US)\n",
    "\n",
    "The AI Core Help describes in section Data API how to upload Documents\n",
    "https://help.sap.com/docs/sap-ai-core/generative-ai-hub/vector-api?locale=en-US\n",
    "\n",
    "For 1st version of the Learning Journey we should just reference the APIs and describe the sequence. We assume the user can create the Vector store herself.\n",
    "\n",
    "In 2nd version of the Learning Journey we add the sharepoint option. Maybe there is better documentation available for both options until then, which we can reference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0ed3438a395e0d",
   "metadata": {},
   "source": [
    "#### Step 2: Configure the Document Grounding Module\n",
    "   - Define the configuration for the Document Grounding module in the Orchestration Service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c82ecda612ac1bc",
   "metadata": {},
   "source": [
    "### Add the url to the orchestration service here\n",
    "Todo: guide the user to get the url from the AI Core service / AI Launchpad"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:22:31.736447Z",
     "start_time": "2025-02-02T13:22:31.730848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "orchestration_service_url = \"https://api.ai.prodeuonly.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/df6aaf7f157a488e\"\n",
    "#\"https://api.ai.prodeuonly.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/df6aaf7f157a488e\"\n",
    "#\"https://api.ai.intprod-eu12.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/dedccdc403fb2b8a\"\n"
   ],
   "id": "cae7ddb2f84f2994",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:22:37.333988Z",
     "start_time": "2025-02-02T13:22:35.225841Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Import libraries\n",
    "from gen_ai_hub.proxy import get_proxy_client\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.document_grounding import (GroundingModule, DocumentGrounding, GroundingFilterSearch,\n",
    "                                                                DataRepositoryType, DocumentGroundingFilter)\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService"
   ],
   "id": "59c9049ba6f6ca2d",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:22:38.585469Z",
     "start_time": "2025-02-02T13:22:38.580796Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set up the Orchestration Service\n",
    "aicore_client = get_proxy_client().ai_core_client\n",
    "orchestration_service = OrchestrationService(api_url=orchestration_service_url)\n",
    "llm = LLM(\n",
    "    name=\"gpt-4o\",\n",
    "    parameters={\n",
    "        'temperature': 0.0,\n",
    "    }\n",
    ")\n",
    "template = Template(\n",
    "            messages=[\n",
    "                SystemMessage(\"\"\"Facility Solutions Company provides services to luxury residential complexes, apartments,\n",
    "                individual homes, and commercial properties such as office buildings, retail spaces, industrial facilities, and educational institutions.\n",
    "                Customers are encouraged to reach out with maintenance requests, service deficiencies, follow-ups, or any issues they need by email.\n",
    "                \"\"\"),\n",
    "                UserMessage(\"\"\"You are a helpful assistant for any queries for answering questions.\n",
    "                Answer the request by providing relevant answers that fit to the request.\n",
    "                Request: {{ ?user_query }}\n",
    "                Context:{{ ?grounding_response }}\n",
    "                \"\"\"),\n",
    "            ]\n",
    "        )"
   ],
   "id": "a00e1690f602cb8b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:24:55.875601Z",
     "start_time": "2025-02-02T13:24:55.872422Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set up Document Grounding\n",
    "# Here, 'data_repositories' is empty. Ensure to add repository ID you would like to use to access the data for grounding.\n",
    "filters = [DocumentGroundingFilter(id=\"vector\",\n",
    "                                   data_repositories=[],\n",
    "                                   search_config=GroundingFilterSearch(max_chunk_count=2),\n",
    "                                   data_repository_type=DataRepositoryType.VECTOR.value\n",
    "                                   )\n",
    "]\n",
    "\n",
    "grounding_config = GroundingModule(\n",
    "            type=\"document_grounding_service\",\n",
    "            config=DocumentGrounding(input_params=[\"user_query\"], output_param=\"grounding_response\", filters=filters)\n",
    "        )\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    "    grounding=grounding_config\n",
    ")"
   ],
   "id": "429c5dd8c0e13475",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    " #### Step 3: Generate context-relevant answer for a user query\n",
    "   - Run the Orchestration Service with the Configuration from the previous step."
   ],
   "id": "21b996611eadcb38"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-02T13:25:08.151751Z",
     "start_time": "2025-02-02T13:24:59.240528Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response = orchestration_service.run(config=config,\n",
    "                            template_values=[\n",
    "                                TemplateValue(\"user_query\", \"Tell me about the orchestration service.\"),\n",
    "                            ])\n",
    "print(response.orchestration_result.choices[0].message.content)"
   ],
   "id": "b98e040f0afdaef9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orchestration in the context of business AI scenarios involves combining content generation with a set of essential functions. These functions are designed to enhance the efficiency and effectiveness of AI-driven processes. Key functions include:\n",
      "\n",
      "1. **Templating**: This function allows you to create prompts with placeholders that are dynamically filled during inference. It helps in customizing and personalizing content generation based on specific requirements.\n",
      "\n",
      "2. **Content Filtering**: This function enables you to control the type of content that is passed to and received from a generative AI model. It ensures that the content adheres to predefined guidelines and restrictions, maintaining quality and relevance.\n",
      "\n",
      "To create a deployment for orchestration, certain prerequisites must be met, such as having an SAP AI Launchpad service instance and service key, using the extended service plan, and having the appropriate roles or role collections assigned.\n",
      "\n",
      "In an orchestration workflow, different modules can be combined into a pipeline, which can be executed with a single API call. The response from one module serves as the input for the next, and the execution order is centrally defined. However, you can configure each module's details and omit optional ones by providing an orchestration configuration in JSON format with the request body.\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "d6a98757a81d90a5",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
