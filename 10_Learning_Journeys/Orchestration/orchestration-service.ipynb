{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d8f0d470dd5ce2",
   "metadata": {},
   "source": [
    "# Orchestration Service Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa2bb46ec75e47",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the SDK to interact with the Orchestration Service, enabling the creation of AI-driven workflows by seamlessly integrating various modules, such as templating, large language models (LLMs), data masking and content filtering. By leveraging these modules, you can build complex, automated workflows that enhance the capabilities of your AI solutions. For more details on configuring and using these modules, please refer to the [Orchestration Service Documentation](https://help.sap.com/docs/ai-launchpad/sap-ai-launchpad/orchestration)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87192898",
   "metadata": {},
   "source": [
    "## NOTE:\n",
    "### Please download the latest version of GenAi Hub v3.2.0(scheduled release date 7th Oct and beyond) from https://pypi.org/project/generative-ai-hub-sdk/ to execute this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763fe53a",
   "metadata": {},
   "source": [
    "To check the installed version of generative-ai-hub-sdk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7782ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: generative-ai-hub-sdk\n",
      "Version: 3.1.1\n",
      "Summary: generative AI hub SDK\n",
      "Home-page: https://www.sap.com/\n",
      "Author: SAP SE\n",
      "Author-email: \n",
      "License: SAP DEVELOPER LICENSE AGREEMENT\n",
      "Location: C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\n",
      "Requires: ai-core-sdk, click, dacite, langchain, langchain-community, openai, overloading, pydantic\n",
      "Required-by: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 10.156 seconds\n"
     ]
    }
   ],
   "source": [
    "!pip install generative-ai-hub-sdk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c6244a294485e",
   "metadata": {},
   "source": [
    "## Initializing the Orchestration Service\n",
    "\n",
    "⚠️Before using the SDK, you need to set up a virtual deployment of the Orchestration Service. Once deployed, you'll have access to a unique endpoint URL (deploymentUrl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e522c0b92cd29e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:01:05.528876Z",
     "start_time": "2024-09-13T09:01:05.526491Z"
    }
   },
   "outputs": [],
   "source": [
    "YOUR_API_URL = \"...\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13691a6f5ffee555",
   "metadata": {},
   "source": [
    "## Basic Orchestration Pipeline\n",
    "\n",
    "Now that you have YOUR_API_URL, let's walk through a basic orchestration pipeline for a translation task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c47b7e4c0adfe",
   "metadata": {},
   "source": [
    "### Step 1: Define the Template and Default Input Values\n",
    "\n",
    "The Template class is used to define structured message templates for generating dynamic interactions with language models. In this example, the template is designed for a translation assistant, allowing users to specify a language and text for translation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a59d3a2a5266df5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:19.710883Z",
     "start_time": "2024-09-13T09:00:18.077778Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 3.422 seconds\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "\n",
    "template = Template(\n",
    "    messages=[\n",
    "        SystemMessage(\"You are a helpful translation assistant.\"),\n",
    "        UserMessage(\n",
    "            \"Translate the following text to {{?to_lang}}: {{?text}}\"\n",
    "        ),\n",
    "    ],\n",
    "    defaults=[\n",
    "        TemplateValue(name=\"to_lang\", value=\"German\"),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd21a6c7c9db50e",
   "metadata": {},
   "source": [
    "This template can be used to create translation requests where the language and text to be translated are specified dynamically. The placeholders in the UserMessage will be replaced with the actual values provided at runtime, and the default value for the language is set to German."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1efb1b8a33d12de9",
   "metadata": {},
   "source": [
    "### Step 2: Define the LLM\n",
    "\n",
    "The LLM class is used to configure and initialize a language model for generating text based on specific parameters. In this example, we'll use the GPT-4o model to perform the translation task.\n",
    "\n",
    "ℹ️Note that virtual deployment of the language model is managed automatically by the Orchestration Service, so no additional deployment setup is required on your part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf3356f0268f267",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:19.716364Z",
     "start_time": "2024-09-13T09:00:19.711892Z"
    }
   },
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "\n",
    "llm = LLM(name=\"gpt-4o\", version=\"latest\", parameters={\"max_tokens\": 256, \"temperature\": 0.2})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0130f7ff9df59a",
   "metadata": {},
   "source": [
    "This configuration initializes the language model to use the gpt-4o variant with the latest updates. The model will generate responses up to 256 tokens in length and produce more predictable and focused output due to the low temperature setting."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97ee26cf9c303b7",
   "metadata": {},
   "source": [
    "### Step 3: Create the Orchestration Configuration\n",
    "\n",
    "The OrchestrationConfig class is used to create a configuration that integrates various components, such as templates and language models, into a unified orchestration setup. This configuration specifies how these components work together to achieve the desired workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5c18daf6bec0aec",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:19.726181Z",
     "start_time": "2024-09-13T09:00:19.717546Z"
    }
   },
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=template,\n",
    "    llm=llm,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26802bca242e40e0",
   "metadata": {},
   "source": [
    "### Step 4: Run the Orchestration Request\n",
    "\n",
    "The OrchestrationService class is used to interact with the orchestration service by providing a configuration and invoking its operations. This service handles the execution of workflows defined by the provided configuration and processes inputs accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7c7a3b8cfef44c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:19.755290Z",
     "start_time": "2024-09-13T09:00:19.727289Z"
    }
   },
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "orchestration_service = OrchestrationService(api_url=YOUR_API_URL, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5a114f96ccea5b",
   "metadata": {},
   "source": [
    "Call the run method with the required template_values. The service will process the input according to the configuration and return the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea61f817f25c985c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:21.073748Z",
     "start_time": "2024-09-13T09:00:19.755995Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Der Orchestrierungsdienst funktioniert!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 4.625 seconds\n"
     ]
    }
   ],
   "source": [
    "result = orchestration_service.run(template_values=[\n",
    "    TemplateValue(name=\"text\", value=\"The Orchestration Service is working!\")\n",
    "])\n",
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "994a9645b29ef1db",
   "metadata": {},
   "source": [
    "## Optional Modules"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d92be02fe6eea0b2",
   "metadata": {},
   "source": [
    "### Data Masking\n",
    "\n",
    "The Data Masking Module anonymizes or pseudonymizes personally identifiable information (PII) before it is processed by the LLM module. When data is anonymized, all identifying information is replaced with placeholders (e.g., MASKED_ENTITY), and the original data cannot be recovered, ensuring that no trace of the original information is retained. In contrast, pseudonymized data is substituted with unique placeholders (e.g., MASKED_ENTITY_ID), allowing the original information to be restored if needed. In both cases, the masking module identifies sensitive data and replaces it with appropriate placeholders before further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55de89ea8090d7eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:25.901205Z",
     "start_time": "2024-09-13T09:00:21.074835Z"
    }
   },
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.utils import load_text_file\n",
    "from gen_ai_hub.orchestration.models.data_masking import DataMasking\n",
    "from gen_ai_hub.orchestration.models.sap_data_privacy_integration import SAPDataPrivacyIntegration, MaskingMethod, \\\n",
    "    ProfileEntity\n",
    "\n",
    "data_masking = DataMasking(\n",
    "    providers=[\n",
    "        SAPDataPrivacyIntegration(\n",
    "            method=MaskingMethod.ANONYMIZATION,  # or MaskingMethod.PSEUDONYMIZATION\n",
    "            entities=[\n",
    "                ProfileEntity.EMAIL,\n",
    "                ProfileEntity.PHONE,\n",
    "                ProfileEntity.PERSON,\n",
    "                ProfileEntity.ORG,\n",
    "                ProfileEntity.LOCATION\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=Template(\n",
    "        messages=[\n",
    "            SystemMessage(\"You are a helpful AI assistant.\"),\n",
    "            UserMessage(\"Summarize the following CV in 10 sentences: {{?orgCV}}\"),\n",
    "        ]\n",
    "    ),\n",
    "    llm=LLM(\n",
    "        name=\"gpt-4o\",\n",
    "    ),\n",
    "    data_masking=data_masking\n",
    ")\n",
    "\n",
    "cv_as_string = load_text_file(\"data/cv.txt\")\n",
    "\n",
    "result = orchestration_service.run(\n",
    "    config=config,\n",
    "    template_values=[\n",
    "        TemplateValue(name=\"orgCV\", value=cv_as_string)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e44d871bc49bb3bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:25.908388Z",
     "start_time": "2024-09-13T09:00:25.903481Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MASKED_PERSON is a seasoned financial expert with a strong focus on strategic and financial planning, accurate forecasting, and process implementation. They hold a Master of Science in Finance (2014) and a Bachelor of Science in Finance (2011) from MASKED_ORG. Their skill set includes proficiency in SAP and Excel VBA, as well as staff leadership and development. They are a Certified Management Accountant. In their role as a Financial Manager from 2016 to 2018 at MASKED_ORG, they managed all financial processes and devised short and long-term financial strategies to meet company goals. They also recommended innovative ways to generate revenue and cut costs while conducting advanced deal analysis and negotiations with potential investors. Their earlier experience from 2013 to 2016 involved drafting executive reports that outlined business issues, risks, and profit opportunities. Throughout both roles, they employed market research and surveys to drive business performance improvements. Overall, they are skilled in advising corporations, small businesses, and individuals on asset allocation, investment strategies, and risk management.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 5.688 seconds\n"
     ]
    }
   ],
   "source": [
    "print(result.orchestration_result.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6beb1e933ba1eada",
   "metadata": {},
   "source": [
    "### Content Filtering\n",
    "\n",
    "The Content Filtering Module can be configured to filter both the input to the LLM module (input filter) and the output generated by the LLM (output filter). The module uses predefined classification services to detect inappropriate or unwanted content, allowing flexible configuration through customizable thresholds. These thresholds can be set to control the sensitivity of filtering, ensuring that content meets desired standards before it is processed or returned as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ff60002292d04a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:25.916096Z",
     "start_time": "2024-09-13T09:00:25.909810Z"
    }
   },
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.azure_content_filter import AzureContentFilter, AzureThreshold\n",
    "\n",
    "input_filter= AzureContentFilter(hate=AzureThreshold.ALLOW_SAFE,\n",
    "                                  violence=AzureThreshold.ALLOW_SAFE,\n",
    "                                  self_harm=AzureThreshold.ALLOW_SAFE,\n",
    "                                  sexual=AzureThreshold.ALLOW_SAFE)\n",
    "output_filter = AzureContentFilter(hate=AzureThreshold.ALLOW_SAFE,\n",
    "                                   violence=AzureThreshold.ALLOW_SAFE_LOW,\n",
    "                                   self_harm=AzureThreshold.ALLOW_SAFE_LOW_MEDIUM,\n",
    "                                   sexual=AzureThreshold.ALLOW_ALL)\n",
    "\n",
    "config = OrchestrationConfig(\n",
    "    template=Template(\n",
    "        messages=[\n",
    "            SystemMessage(\"You are a helpful AI assistant.\"),\n",
    "            UserMessage(\"{{?text}}\"),\n",
    "        ]\n",
    "    ),\n",
    "    llm=LLM(\n",
    "        name=\"gpt-4o\",\n",
    "    ),\n",
    "    input_filters=[input_filter],\n",
    "    output_filters=[output_filter]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc2bc3e0e569ada3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:26.251408Z",
     "start_time": "2024-09-13T09:00:25.919784Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Content filtered due to Safety violations. Please modify the prompt and try again.\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.orchestration.exceptions import OrchestrationError\n",
    "\n",
    "try:\n",
    "    result = orchestration_service.run(config=config, template_values=[\n",
    "        TemplateValue(name=\"text\", value=\"I hate you\")\n",
    "    ])\n",
    "except OrchestrationError as error:\n",
    "    print(error.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb761855b9abc42c",
   "metadata": {},
   "source": [
    "## Advanced Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7476db3ffb49eb14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:26.255718Z",
     "start_time": "2024-09-13T09:00:26.252854Z"
    }
   },
   "outputs": [],
   "source": [
    "service = OrchestrationService(api_url=YOUR_API_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c1f142ece2d309",
   "metadata": {},
   "source": [
    "### Translation Service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72113e559b0875ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:26.262292Z",
     "start_time": "2024-09-13T09:00:26.256962Z"
    }
   },
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "\n",
    "class TranslationService:\n",
    "    def __init__(self, orchestration_service: OrchestrationService):\n",
    "        self.service = orchestration_service\n",
    "        self.config = OrchestrationConfig(\n",
    "            template=Template(\n",
    "                messages=[\n",
    "                    SystemMessage(\"You are a helpful translation assistant.\"),\n",
    "                    UserMessage(\n",
    "                        \"Translate the following text to {{?to_lang}}: {{?text}}\"\n",
    "                    ),\n",
    "                ],\n",
    "                defaults=[\n",
    "                    TemplateValue(name=\"to_lang\", value=\"English\"),\n",
    "                ],\n",
    "            ),\n",
    "            llm=LLM(name=\"gpt-4o\"),\n",
    "        )\n",
    "\n",
    "    def translate(self, text, to_lang):\n",
    "        response = self.service.run(\n",
    "            config=self.config,\n",
    "            template_values=[\n",
    "                TemplateValue(name=\"to_lang\", value=to_lang),\n",
    "                TemplateValue(name=\"text\", value=text),\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        return response.orchestration_result.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb2e43db6665d162",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:26.265578Z",
     "start_time": "2024-09-13T09:00:26.263417Z"
    }
   },
   "outputs": [],
   "source": [
    "translator = TranslationService(orchestration_service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b48f620b8ece05b1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:27.134178Z",
     "start_time": "2024-09-13T09:00:26.266464Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bonjour, le monde !\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 4.531 seconds\n"
     ]
    }
   ],
   "source": [
    "result = translator.translate(text=\"Hello, world!\", to_lang=\"French\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c9cd07907bda369",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:27.986344Z",
     "start_time": "2024-09-13T09:00:27.136370Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¡Hola, mundo!\n"
     ]
    }
   ],
   "source": [
    "result = translator.translate(text=\"Hello, world!\", to_lang=\"Spanish\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6eafbcb25180d359",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:28.844851Z",
     "start_time": "2024-09-13T09:00:27.987573Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hallo, Welt!\n"
     ]
    }
   ],
   "source": [
    "result = translator.translate(text=\"Hello, world!\", to_lang=\"German\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67bb6ee8f9221c0f",
   "metadata": {},
   "source": [
    "### Chatbot with Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28a57d005dd6abfa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:28.855623Z",
     "start_time": "2024-09-13T09:00:28.847880Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.message import Message, SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "\n",
    "class ChatBot:\n",
    "    def __init__(self, orchestration_service: OrchestrationService):\n",
    "        self.service = orchestration_service\n",
    "        self.config = OrchestrationConfig(\n",
    "            template=Template(\n",
    "                messages=[\n",
    "                    SystemMessage(\"You are a helpful chatbot assistant.\"),\n",
    "                    UserMessage(\"{{?user_query}}\"),\n",
    "                ],\n",
    "            ),\n",
    "            llm=LLM(name=\"gpt-4\"),\n",
    "        )\n",
    "        self.history: List[Message] = []\n",
    "\n",
    "    def chat(self, user_input):\n",
    "        response = self.service.run(\n",
    "            config=self.config,\n",
    "            template_values=[\n",
    "                TemplateValue(name=\"user_query\", value=user_input),\n",
    "            ],\n",
    "            history=self.history,\n",
    "        )\n",
    "\n",
    "        message = response.orchestration_result.choices[0].message\n",
    "\n",
    "        self.history = response.module_results.templating\n",
    "        self.history.append(message)\n",
    "\n",
    "        return message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "25bac947d3f51ba2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:28.860400Z",
     "start_time": "2024-09-13T09:00:28.857468Z"
    }
   },
   "outputs": [],
   "source": [
    "bot = ChatBot(orchestration_service=service)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de06e9761b7af5f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:31.182801Z",
     "start_time": "2024-09-13T09:00:28.861679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm just a computer program, so I don't have feelings, but I'm here and ready to help you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(bot.chat(\"Hello, how are you?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8d4b835cbd787bb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:34.698533Z",
     "start_time": "2024-09-13T09:00:31.183759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't have real-time capabilities to check current weather conditions. However, you can easily find the weather by checking a weather website like Weather.com, using a weather app on your smartphone, or by asking a voice-activated device like Google Home or Amazon Alexa. How else may I assist you today?\n"
     ]
    }
   ],
   "source": [
    "print(bot.chat(\"What's the weather like today?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce80d406ccab9e68",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:37.286835Z",
     "start_time": "2024-09-13T09:00:34.699892Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yes, you first asked, \"Hello, how are you?\" How can I assist you further?\n"
     ]
    }
   ],
   "source": [
    "print(bot.chat(\"Can you remember what I first asked you?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0fee7d2dd8af5a4",
   "metadata": {},
   "source": [
    "### Sentiment Analysis with Few Shot Learning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9296deee2b6a286e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:37.292729Z",
     "start_time": "2024-09-13T09:00:37.287783Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import List, Tuple\n",
    "\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.message import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    AssistantMessage,\n",
    ")\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "\n",
    "class FewShotLearner:\n",
    "    def __init__(\n",
    "            self,\n",
    "            orchestration_service: OrchestrationService,\n",
    "            system_message: SystemMessage,\n",
    "            examples: List[Tuple[UserMessage, AssistantMessage]],\n",
    "    ):\n",
    "        self.service = orchestration_service\n",
    "        self.config = OrchestrationConfig(\n",
    "            template=self._create_few_shot_template(system_message, examples),\n",
    "            llm=LLM(name=\"gpt-35-turbo\"),\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _create_few_shot_template(\n",
    "            system_message: SystemMessage,\n",
    "            examples: List[Tuple[UserMessage, AssistantMessage]],\n",
    "    ) -> Template:\n",
    "        messages = [system_message]\n",
    "\n",
    "        for example in examples:\n",
    "            messages.append(example[0])\n",
    "            messages.append(example[1])\n",
    "        messages.append(UserMessage(\"{{?user_input}}\"))\n",
    "\n",
    "        return Template(messages=messages)\n",
    "\n",
    "    def predict(self, user_input: str) -> str:\n",
    "        response = self.service.run(\n",
    "            config=self.config,\n",
    "            template_values=[TemplateValue(name=\"user_input\", value=user_input)],\n",
    "        )\n",
    "\n",
    "        return response.orchestration_result.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1b054f8f344a862",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:37.296057Z",
     "start_time": "2024-09-13T09:00:37.293660Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_examples = [\n",
    "    (UserMessage(\"I love this product!\"), AssistantMessage(\"Positive\")),\n",
    "    (UserMessage(\"This is terrible service.\"), AssistantMessage(\"Negative\")),\n",
    "    (UserMessage(\"The weather is okay today.\"), AssistantMessage(\"Neutral\")),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5babd104942009f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:37.298703Z",
     "start_time": "2024-09-13T09:00:37.296878Z"
    }
   },
   "outputs": [],
   "source": [
    "sentiment_analyzer = FewShotLearner(\n",
    "    orchestration_service=service,\n",
    "    system_message=SystemMessage(\n",
    "        \"You are a sentiment analysis assistant. Classify the sentiment as Positive, Negative, or Neutral.\"\n",
    "    ),\n",
    "    examples=sentiment_examples,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f11c1b1bf9625782",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:37.764155Z",
     "start_time": "2024-09-13T09:00:37.299515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative\n"
     ]
    }
   ],
   "source": [
    "print(sentiment_analyzer.predict(\"The movie was a complete waste of time!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52f3cde99c4b35f4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:38.239471Z",
     "start_time": "2024-09-13T09:00:37.765554Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    sentiment_analyzer.predict(\"The traffic was fortunately unusually light today.\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6556f4990073d78f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:00:39.554482Z",
     "start_time": "2024-09-13T09:00:38.240676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neutral\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 21.547 seconds\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    sentiment_analyzer.predict(\"I'm not sure how I feel about the recent events.\")\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
