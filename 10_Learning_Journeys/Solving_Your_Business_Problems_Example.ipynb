{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "467a858f-9fa0-4432-be70-190f9a9b5d73",
   "metadata": {},
   "source": [
    "# Solving Your Business Problems Using Prompts and LLMs in SAP's Generative AI Hub (Facility Management Example)\n",
    "\n",
    "Start with introducing the scenario:\n",
    "- Company wants to analyse support mail\n",
    "- See company description in `company-scope.md`\n",
    "- Incoming mails should be assigned to the correct service category and assigned the correct urgency and sentiment\n",
    "\n",
    "**Goal**: Analyse every message and extract:\n",
    "- `urgency`\n",
    "- `sentiment`\n",
    "- `categories`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccb7a1f-53e2-4204-9c80-5602ff911001",
   "metadata": {},
   "source": [
    "## Install packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "583a2829-55d8-48cf-a1f6-5ac73fdea800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: generative-ai-hub-sdk>=3.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (3.1.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (4.66.5)\n",
      "Requirement already satisfied: langchain-community==0.2.10 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk>=3.1) (0.2.10)\n",
      "Requirement already satisfied: ai-core-sdk>=2.4.5 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk>=3.1) (2.4.5)\n",
      "Requirement already satisfied: dacite>=1.8.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk>=3.1) (1.8.1)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk>=3.1) (8.1.7)\n",
      "Requirement already satisfied: packaging==24.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk>=3.1) (24.1)\n",
      "Requirement already satisfied: langchain~=0.2.9 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk>=3.1) (0.2.15)\n",
      "Requirement already satisfied: openai>=1.3.3 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk>=3.1) (1.40.2)\n",
      "Requirement already satisfied: pydantic>=2.5.3 in c:\\users\\i746414\\appdata\\roaming\\python\\python311\\site-packages (from generative-ai-hub-sdk>=3.1) (2.8.2)\n",
      "Requirement already satisfied: overloading==0.5.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk>=3.1) (0.5.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (1.4.52)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (0.5.14)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (0.2.37)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (0.1.84)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (1.24.3)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (8.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: ai-api-client-sdk==2.2.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from ai-core-sdk>=2.4.5->generative-ai-hub-sdk>=3.1) (2.2.1)\n",
      "Requirement already satisfied: aenum~=3.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from ai-api-client-sdk==2.2.1->ai-core-sdk>=2.4.5->generative-ai-hub-sdk>=3.1) (3.1.15)\n",
      "Requirement already satisfied: pyhumps~=3.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from ai-api-client-sdk==2.2.1->ai-core-sdk>=2.4.5->generative-ai-hub-sdk>=3.1) (3.8.0)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain~=0.2.9->generative-ai-hub-sdk>=3.1) (0.2.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3.3->generative-ai-hub-sdk>=3.1) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3.3->generative-ai-hub-sdk>=3.1) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3.3->generative-ai-hub-sdk>=3.1) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3.3->generative-ai-hub-sdk>=3.1) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3.3->generative-ai-hub-sdk>=3.1) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3.3->generative-ai-hub-sdk>=3.1) (4.12.2)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic>=2.5.3->generative-ai-hub-sdk>=3.1) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic>=2.5.3->generative-ai-hub-sdk>=3.1) (2.20.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (1.8.1)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from anyio<5,>=3.5.0->openai>=1.3.3->generative-ai-hub-sdk>=3.1) (3.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (0.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.3.3->generative-ai-hub-sdk>=3.1) (2023.7.22)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.3.3->generative-ai-hub-sdk>=3.1) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3.3->generative-ai-hub-sdk>=3.1) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.23->langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (1.33)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (3.9.15)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\i746414\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2->langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (1.26.18)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.10->generative-ai-hub-sdk>=3.1) (1.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 17.078 seconds\n"
     ]
    }
   ],
   "source": [
    "!pip install -U \"generative-ai-hub-sdk>=3.1\" tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81429b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 8.344 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    "from ai_api_client_sdk.models.parameter_binding import ParameterBinding\n",
    "from enum import Enum\n",
    " \n",
    "# Inline credentials\n",
    "with open('config.json') as f:\n",
    "    credCF = json.load(f)\n",
    "\n",
    "# Set environment variables\n",
    "def set_environment_vars(credCF):\n",
    "    env_vars = {\n",
    "        'AICORE_AUTH_URL': credCF['url'] + '/oauth/token',\n",
    "        'AICORE_CLIENT_ID': credCF['clientid'],\n",
    "        'AICORE_CLIENT_SECRET': credCF['clientsecret'],\n",
    "        'AICORE_BASE_URL': credCF[\"serviceurls\"][\"AI_API_URL\"] + \"/v2\",\n",
    "        'AICORE_RESOURCE_GROUP': \"default\" \n",
    "    }\n",
    "\n",
    "    for key, value in env_vars.items():\n",
    "        os.environ[key] = value\n",
    "\n",
    "# Create AI Core client instance\n",
    "def create_ai_core_client(credCF):\n",
    "    set_environment_vars(credCF)  # Ensure environment variables are set\n",
    "    return AICoreV2Client(\n",
    "        base_url=os.environ['AICORE_BASE_URL'],\n",
    "        auth_url=os.environ['AICORE_AUTH_URL'],\n",
    "        client_id=os.environ['AICORE_CLIENT_ID'],\n",
    "        client_secret=os.environ['AICORE_CLIENT_SECRET'],\n",
    "        resource_group=os.environ['AICORE_RESOURCE_GROUP']\n",
    "    )\n",
    "\n",
    "ai_core_client = create_ai_core_client(credCF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "556d5599-87e5-4928-87df-bfe47953ccdf",
   "metadata": {},
   "source": [
    "## Imports and Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c5fc507-de9f-473c-9b56-ca7afe560666",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, Type, Union, Dict, Any, List, Callable\n",
    "import re, pathlib, json, time\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "73f257fc-837b-485f-b9a3-3668b968f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE_MESSAGE_IDX = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4dbb18-4fe5-4580-91e1-33f59e4e802f",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "973dc56f-7090-413c-a07d-25b8beeb8902",
   "metadata": {},
   "outputs": [],
   "source": [
    "HERE = pathlib.Path.cwd()\n",
    "\n",
    "with (HERE / 'filtered_mails-hardest.jsonl').open() as stream:\n",
    "    mails = [json.loads(line) for line in stream if line.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b087bb61-ce54-4e40-86b4-52036b40b068",
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_set, test_set = mails[:int(len(mails)/2)], mails[int(len(mails)/2):]\n",
    "test_set_small = test_set[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d2a9d68-251b-4b44-ab7e-832d05caddc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = set()\n",
    "urgency = set()\n",
    "sentiment = set()\n",
    "for mail in mails:\n",
    "    categories = categories.union(set(mail['ground_truth']['categories']))\n",
    "    urgency.add(mail['ground_truth']['urgency'])\n",
    "    sentiment.add(mail['ground_truth']['sentiment'])\n",
    "\n",
    "option_lists = {\n",
    "    'urgency': ', '.join(f\"`{entry}`\" for entry in urgency),\n",
    "    'sentiment': ', '.join(f\"`{entry}`\" for entry in sentiment),\n",
    "    'categories': ', '.join(f\"`{entry}`\" for entry in categories),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e3ab5ea5-450e-4aa0-a398-9762ea7d01be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'urgency': '`medium`, `high`, `low`',\n",
       " 'sentiment': '`negative`, `neutral`, `positive`',\n",
       " 'categories': '`specialized_cleaning_services`, `quality_and_safety_concerns`, `training_and_support_requests`, `facility_management_issues`, `customer_feedback_and_complaints`, `general_inquiries`, `emergency_repair_services`, `cleaning_services_scheduling`, `routine_maintenance_requests`, `sustainability_and_environmental_practices`'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "option_lists"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4644e47b-d553-4a5e-9633-06e5ef354b81",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45d4a2dd-c55b-4f57-aa6c-40b9a168b144",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 24.547 seconds\n"
     ]
    }
   ],
   "source": [
    "from gen_ai_hub.proxy import get_proxy_client\n",
    "\n",
    "\n",
    "client = get_proxy_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3416e7b-a3e2-4d4c-8de4-1323aa49056c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    "from ai_api_client_sdk.models.status import Status\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "def spinner(check_callback: Callable, timeout: int = 300, check_every_n_seconds: int = 10):\n",
    "    start = time.time()\n",
    "    last_check = start\n",
    "    while time.time() - start < timeout:\n",
    "        now = time.time()\n",
    "        if now - start > timeout:\n",
    "            break\n",
    "        if now - last_check > check_every_n_seconds:\n",
    "            return_value = check_callback()\n",
    "            if return_value:\n",
    "                return return_value\n",
    "        for char in '|/-\\\\':\n",
    "            clear_output(wait=True)  # Clears the output to show a fresh update\n",
    "            print(f'Waiting for the deployment to become ready... {char}')\n",
    "            time.sleep(0.2)  # Adjust the speed as needed\n",
    "\n",
    "\n",
    "def retrieve_or_deploy_orchestration(ai_core_client: AICoreV2Client,\n",
    "                                     scenario_id: str = \"orchestration\",\n",
    "                                     executable_id: str = \"orchestration\",\n",
    "                                     config_suffix: str = \"simple\",\n",
    "                                     start_timeout: int = 300):\n",
    "    if not config_suffix:\n",
    "        raise ValueError(\"Empty `config_suffix` not allowed\")\n",
    "    deployments = ai_core_client.deployment.query(\n",
    "        scenario_id=scenario_id,\n",
    "        executable_ids=[executable_id],\n",
    "        status=Status.RUNNING\n",
    "    )\n",
    "    if deployments.count > 0:\n",
    "        return sorted(deployments.resources, key=lambda x: x.start_time)[0]\n",
    "    config_name = f\"{config_suffix}-orchestration\"\n",
    "    configs = ai_core_client.configuration.query(\n",
    "        scenario_id=scenario_id,\n",
    "        executable_ids=[executable_id],\n",
    "        search=config_name\n",
    "    )\n",
    "    if configs.count > 0:\n",
    "        config = sorted(deployments.resources, key=lambda x: x.start_time)[0]\n",
    "    else:\n",
    "        config = ai_core_client.configuration.create(\n",
    "            scenario_id=scenario_id,\n",
    "            executable_id=executable_id,\n",
    "            name=config_name,\n",
    "        )\n",
    "    deployment = ai_core_client.deployment.create(configuration_id=config.id)\n",
    "\n",
    "    def check_ready():\n",
    "        updated_deployment = ai_core_client.deployment.get(deployment.id)\n",
    "        return None if updated_deployment.status != Status.RUNNING else updated_deployment\n",
    "    \n",
    "    return spinner(check_ready)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99a18974-f07e-4c4b-bb75-e809ba69b03d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 5.187 seconds\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "import yaml\n",
    "\n",
    "from gen_ai_hub.proxy import get_proxy_client\n",
    "from ai_api_client_sdk.models.status import Status\n",
    "\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.models.content_filter import AzureContentFilter\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "client = get_proxy_client()\n",
    "deployment = retrieve_or_deploy_orchestration(client.ai_core_client)\n",
    "orchestration_service = OrchestrationService(api_url=deployment.deployment_url, proxy_client=client)\n",
    "\n",
    "def send_request(prompt, _print=True, _model='meta--llama3-70b-instruct', **kwargs):\n",
    "    config = OrchestrationConfig(\n",
    "        llm=LLM(name=_model),\n",
    "        template=Template(messages=[UserMessage(prompt)])\n",
    "    )\n",
    "    template_values = [TemplateValue(name=key, value=value) for key, value in kwargs.items()]\n",
    "    answer = orchestration_service.run(config=config, template_values=template_values)\n",
    "    result = answer.module_results.llm.choices[0].message.content\n",
    "    if _print:\n",
    "        formatted_prompt = answer.module_results.templating[0].content\n",
    "        print(f\"<-- PROMPT --->\\n{formatted_prompt if _print else prompt}\\n<--- RESPONSE --->\\n{result}\")   \n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e74881b-845d-44a8-9150-39696b663f2c",
   "metadata": {},
   "source": [
    "## Sentiment & Urgency Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0f86b38b-39e8-44db-bd50-ef4927bea813",
   "metadata": {},
   "outputs": [],
   "source": [
    "mail = dev_set[EXAMPLE_MESSAGE_IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08ebd598-2c4a-4b0b-b384-ae1be0f4c3ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- PROMPT --->\n",
      "Giving the following message:\n",
      "---\n",
      "Subject: Urgent HVAC System Repair Needed\n",
      "\n",
      "Dear Support Team,\n",
      "\n",
      "I hope this message finds you well. My name is [Sender], and I am reaching out to you from [Residential Complex Name], where I have been residing for the past few years. I have always appreciated the meticulous care and attention your team provides in maintaining our facilities.\n",
      "\n",
      "However, I am currently facing a pressing issue with the HVAC system in my apartment. Over the past few days, the system has been malfunctioning, resulting in inconsistent temperatures and, at times, complete shutdowns. Given the current weather conditions, this has become quite unbearable and is affecting my daily routine significantly.\n",
      "\n",
      "I have attempted to troubleshoot the problem by resetting the system and checking the thermostat settings, but these efforts have not yielded any improvement. The situation seems to be beyond my control and requires professional intervention.\n",
      "\n",
      "I kindly request that a repair team be dispatched immediately to address this urgent issue. The urgency of the matter cannot be overstated, as it is impacting not only my comfort but also my ability to carry out daily activities effectively.\n",
      "\n",
      "Thank you for your prompt attention to this matter. I look forward to your swift response and resolution.\n",
      "\n",
      "Best regards,\n",
      "[Sender]\n",
      "---\n",
      "Your task is to extract\n",
      "- urgency\n",
      "- sentiment\n",
      "\n",
      "<--- RESPONSE --->\n",
      "Here are the extracted information:\n",
      "\n",
      "**Urgency:** High\n",
      "\n",
      "The language used in the email suggests a high level of urgency, with phrases such as \"Urgent HVAC System Repair Needed\", \"pressing issue\", \"unbearable\", \"affecting my daily routine significantly\", and \"the urgency of the matter cannot be overstated\". The sender is clearly experiencing discomfort and disruption to their daily life due to the malfunctioning HVAC system, and is requesting immediate attention to resolve the issue.\n",
      "\n",
      "**Sentiment:** Neutral/Negative\n",
      "\n",
      "The sentiment of the email is mostly neutral, as the sender expresses appreciation for the support team's efforts in maintaining the facilities. However, there is a negative undertone due to the frustration and discomfort caused by the malfunctioning HVAC system. The sender's language is polite and respectful, but there is a sense of urgency and concern that implies a negative emotional state.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 11.406 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt_1 = \"\"\"Giving the following message:\n",
    "---\n",
    "{{?input}}\n",
    "---\n",
    "Your task is to extract\n",
    "- urgency\n",
    "- sentiment\n",
    "\"\"\"\n",
    "\n",
    "f_1 = partial(send_request, prompt=prompt_1)\n",
    "\n",
    "response = f_1(input=mail[\"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e1ef3fd-7953-41cd-b0bc-99429d5cc6ac",
   "metadata": {},
   "source": [
    "## Sentiment & Urgency with Choices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f47224c2-bda8-40c2-8724-2fe3cd95536d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- PROMPT --->\n",
      "Giving the following message:\n",
      "---\n",
      "Subject: Scheduling Cleaning Services for My Studio\n",
      "\n",
      "Hi Support Team,\n",
      "\n",
      "I hope this message finds you well! My name is [Sender], and I’m a concept artist who has been enjoying the pristine environment your team helps maintain. Your services have been a game-changer for my creative space, and I truly appreciate the dedication and professionalism you bring to the table.\n",
      "\n",
      "I’m reaching out to discuss scheduling the next round of cleaning services for my studio. The space has been a whirlwind of creativity lately, and while it’s not urgent, I’d love to get a date on the calendar for a thorough cleaning. Your team’s attention to detail always leaves my workspace feeling fresh and inspiring, which is crucial for my work.\n",
      "\n",
      "I haven’t taken any steps yet to schedule this, as I wanted to touch base with you first to see what dates might be available. Ideally, I’m looking for a slot sometime in the next couple of weeks, but I’m flexible and happy to work around your schedule.\n",
      "\n",
      "Could you please assist me in setting up a convenient time for the cleaning? I’m looking forward to continuing our collaboration and keeping my studio in top shape.\n",
      "\n",
      "Thank you so much for your help!\n",
      "\n",
      "Best regards,\n",
      "[Sender]\n",
      "---\n",
      "Your task is to extract:\n",
      "- \"urgency\" as one of `medium`, `high`, `low`\n",
      "- \"sentiment\" as one of `negative`, `neutral`, `positive`\n",
      "- \"category\" as one of `specialized_cleaning_services`, `quality_and_safety_concerns`, `training_and_support_requests`, `facility_management_issues`, `customer_feedback_and_complaints`, `general_inquiries`, `emergency_repair_services`, `cleaning_services_scheduling`, `routine_maintenance_requests`, `sustainability_and_environmental_practices`\n",
      "\n",
      "<--- RESPONSE --->\n",
      "Here are the extracted values:\n",
      "\n",
      "* \"urgency\": low\n",
      "* \"sentiment\": positive\n",
      "* \"category\": cleaning_services_scheduling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 3.344 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt_2 = \"\"\"Giving the following message:\n",
    "---\n",
    "{{?input}}\n",
    "---\n",
    "Your task is to extract:\n",
    "- \"urgency\" as one of {{?urgency}}\n",
    "- \"sentiment\" as one of {{?sentiment}}\n",
    "- \"category\" as one of {{?categories}}\n",
    "\"\"\"\n",
    "\n",
    "f_2 = partial(send_request, prompt=prompt_2, **option_lists)\n",
    "\n",
    "response = f_2(input=mail[\"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d65966-1e3e-40cd-b37d-1f2633a9650a",
   "metadata": {},
   "source": [
    "## Sentiment & Urgency with Choices as `json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59938a9b-5854-45ac-97f5-c8b49a7e29a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "OrchestrationError",
     "evalue": "Error processing template: Missing required parameters: ['urgency', 'sentiment']",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\gen_ai_hub\\orchestration\\service.py:112\u001b[0m, in \u001b[0;36mOrchestrationService.run\u001b[1;34m(self, config, template_values, history)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 112\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\requests\\models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[1;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
      "\u001b[1;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d92ea9dba6880bae/completion",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mOrchestrationError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 13\u001b[0m\n\u001b[0;32m      1\u001b[0m prompt_3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;124mGiving the following message:\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124m---\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m{{\u001b[39m\u001b[38;5;124m?input}}\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124mYour complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above.\u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m     11\u001b[0m f_3 \u001b[38;5;241m=\u001b[39m partial(send_request, prompt\u001b[38;5;241m=\u001b[39mprompt_3, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moption_lists)\n\u001b[1;32m---> 13\u001b[0m response \u001b[38;5;241m=\u001b[39m f_3(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m=\u001b[39mmail[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Cell \u001b[1;32mIn[10], line 24\u001b[0m, in \u001b[0;36msend_request\u001b[1;34m(prompt, _print, _model, **kwargs)\u001b[0m\n\u001b[0;32m     19\u001b[0m config \u001b[38;5;241m=\u001b[39m OrchestrationConfig(\n\u001b[0;32m     20\u001b[0m     llm\u001b[38;5;241m=\u001b[39mLLM(name\u001b[38;5;241m=\u001b[39m_model),\n\u001b[0;32m     21\u001b[0m     template\u001b[38;5;241m=\u001b[39mTemplate(messages\u001b[38;5;241m=\u001b[39m[UserMessage(prompt)])\n\u001b[0;32m     22\u001b[0m )\n\u001b[0;32m     23\u001b[0m template_values \u001b[38;5;241m=\u001b[39m [TemplateValue(name\u001b[38;5;241m=\u001b[39mkey, value\u001b[38;5;241m=\u001b[39mvalue) \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems()]\n\u001b[1;32m---> 24\u001b[0m answer \u001b[38;5;241m=\u001b[39m orchestration_service\u001b[38;5;241m.\u001b[39mrun(config\u001b[38;5;241m=\u001b[39mconfig, template_values\u001b[38;5;241m=\u001b[39mtemplate_values)\n\u001b[0;32m     25\u001b[0m result \u001b[38;5;241m=\u001b[39m answer\u001b[38;5;241m.\u001b[39mmodule_results\u001b[38;5;241m.\u001b[39mllm\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _print:\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\Lib\\site-packages\\gen_ai_hub\\orchestration\\service.py:115\u001b[0m, in \u001b[0;36mOrchestrationService.run\u001b[1;34m(self, config, template_values, history)\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m requests\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[0;32m    114\u001b[0m     error_content \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[1;32m--> 115\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OrchestrationError(\n\u001b[0;32m    116\u001b[0m         request_id\u001b[38;5;241m=\u001b[39merror_content\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest_id\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    117\u001b[0m         message\u001b[38;5;241m=\u001b[39merror_content\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    118\u001b[0m         code\u001b[38;5;241m=\u001b[39merror_content\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcode\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    119\u001b[0m         location\u001b[38;5;241m=\u001b[39merror_content\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlocation\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m    120\u001b[0m         module_results\u001b[38;5;241m=\u001b[39merror_content\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule_results\u001b[39m\u001b[38;5;124m\"\u001b[39m, {}),\n\u001b[0;32m    121\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dacite\u001b[38;5;241m.\u001b[39mfrom_dict(\n\u001b[0;32m    124\u001b[0m     data_class\u001b[38;5;241m=\u001b[39mOrchestrationResponse,\n\u001b[0;32m    125\u001b[0m     data\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mjson(),\n\u001b[0;32m    126\u001b[0m     config\u001b[38;5;241m=\u001b[39mdacite\u001b[38;5;241m.\u001b[39mConfig(cast\u001b[38;5;241m=\u001b[39m[Enum]),\n\u001b[0;32m    127\u001b[0m )\n",
      "\u001b[1;31mOrchestrationError\u001b[0m: Error processing template: Missing required parameters: ['urgency', 'sentiment']"
     ]
    }
   ],
   "source": [
    "prompt_3 = \"\"\"Giving the following message:\n",
    "---\n",
    "{{?input}}\n",
    "---\n",
    "Extract and return a json with the follwoing keys and values:\n",
    "- \"urgency\" as one of {{?urgency}}\n",
    "- \"sentiment\" as one of {{?sentiment}}\n",
    "- \"category\" as one of {{?categories}}\n",
    "Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above.\n",
    "\"\"\"\n",
    "f_3 = partial(send_request, prompt=prompt_3, **option_lists)\n",
    "\n",
    "response = f_3(input=mail[\"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52253848-9c8b-42bb-b1f3-441a84d96a48",
   "metadata": {},
   "source": [
    "## Sentiment & Urgency with Choices as `json` Improved Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49ed2cd-3d05-4942-bf9a-1091e7312e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 2.234 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt_4 = \"\"\"Giving the following message:\n",
    "---\n",
    "{{?input}}\n",
    "---\n",
    "Extract and return a json with the follwoing keys and values:\n",
    "- \"urgency\" as one of {{?urgency}}\n",
    "- \"sentiment\" as one of {{?sentiment}}\n",
    "- \"category\" as one of {{?categories}}\n",
    "Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.\"\"\"\n",
    "f_4 = partial(send_request, prompt=prompt_4, **option_lists)\n",
    "\n",
    "response = f_4(input=mail[\"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee6bed0-c610-4561-b7dc-63b472bdb830",
   "metadata": {},
   "source": [
    "## Category Simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3be6c9f0-302c-4477-80e9-2c5fe2b7dc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- PROMPT --->\n",
      "Giving the following message:\n",
      "---\n",
      "Subject: Scheduling Cleaning Services for My Studio\n",
      "\n",
      "Hi Support Team,\n",
      "\n",
      "I hope this message finds you well! My name is [Sender], and I’m a concept artist who has been enjoying the pristine environment your team helps maintain. Your services have been a game-changer for my creative space, and I truly appreciate the dedication and professionalism you bring to the table.\n",
      "\n",
      "I’m reaching out to discuss scheduling the next round of cleaning services for my studio. The space has been a whirlwind of creativity lately, and while it’s not urgent, I’d love to get a date on the calendar for a thorough cleaning. Your team’s attention to detail always leaves my workspace feeling fresh and inspiring, which is crucial for my work.\n",
      "\n",
      "I haven’t taken any steps yet to schedule this, as I wanted to touch base with you first to see what dates might be available. Ideally, I’m looking for a slot sometime in the next couple of weeks, but I’m flexible and happy to work around your schedule.\n",
      "\n",
      "Could you please assist me in setting up a convenient time for the cleaning? I’m looking forward to continuing our collaboration and keeping my studio in top shape.\n",
      "\n",
      "Thank you so much for your help!\n",
      "\n",
      "Best regards,\n",
      "[Sender]\n",
      "---\n",
      "Assign a list of matching support category to the message.\n",
      "\n",
      "<--- RESPONSE --->\n",
      "Based on the content of the message, I would assign the following support categories:\n",
      "\n",
      "1. **Scheduling**: The sender is requesting to schedule a cleaning service for their studio.\n",
      "2. **Service Request**: The sender is requesting a specific service (cleaning) to be performed at their studio.\n",
      "3. **Booking/Availability**: The sender is inquiring about available dates and times for the cleaning service.\n",
      "4. **Facility Maintenance**: The sender is requesting maintenance services (cleaning) for their studio.\n",
      "\n",
      "These categories align with the sender's request and the topic of the message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 7.172 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt_5 = \"\"\"Giving the following message:\n",
    "---\n",
    "{{?input}}\n",
    "---\n",
    "Assign a list of matching support category to the message.\n",
    "\"\"\"\n",
    "f_5 = partial(send_request, prompt=prompt_5)\n",
    "\n",
    "response = f_5(input=mail[\"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375568b8-a762-48f2-bbcc-562048257576",
   "metadata": {},
   "source": [
    "## Categories form list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32552ef1-8556-4fcc-9535-396a19759474",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- PROMPT --->\n",
      "Giving the following message:\n",
      "---\n",
      "Subject: Scheduling Cleaning Services for My Studio\n",
      "\n",
      "Hi Support Team,\n",
      "\n",
      "I hope this message finds you well! My name is [Sender], and I’m a concept artist who has been enjoying the pristine environment your team helps maintain. Your services have been a game-changer for my creative space, and I truly appreciate the dedication and professionalism you bring to the table.\n",
      "\n",
      "I’m reaching out to discuss scheduling the next round of cleaning services for my studio. The space has been a whirlwind of creativity lately, and while it’s not urgent, I’d love to get a date on the calendar for a thorough cleaning. Your team’s attention to detail always leaves my workspace feeling fresh and inspiring, which is crucial for my work.\n",
      "\n",
      "I haven’t taken any steps yet to schedule this, as I wanted to touch base with you first to see what dates might be available. Ideally, I’m looking for a slot sometime in the next couple of weeks, but I’m flexible and happy to work around your schedule.\n",
      "\n",
      "Could you please assist me in setting up a convenient time for the cleaning? I’m looking forward to continuing our collaboration and keeping my studio in top shape.\n",
      "\n",
      "Thank you so much for your help!\n",
      "\n",
      "Best regards,\n",
      "[Sender]\n",
      "---\n",
      "Assign a list best matching support category tags to the message:\n",
      "`specialized_cleaning_services`, `quality_and_safety_concerns`, `training_and_support_requests`, `facility_management_issues`, `customer_feedback_and_complaints`, `general_inquiries`, `emergency_repair_services`, `cleaning_services_scheduling`, `routine_maintenance_requests`, `sustainability_and_environmental_practices`\n",
      "\n",
      "<--- RESPONSE --->\n",
      "Based on the content of the message, I would assign the following support category tags:\n",
      "\n",
      "* `cleaning_services_scheduling`\n",
      "* `routine_maintenance_requests`\n",
      "* `general_inquiries`\n",
      "* `specialized_cleaning_services`\n",
      "\n",
      "The message is primarily about scheduling a cleaning service for the sender's studio, which matches the `cleaning_services_scheduling` and `routine_maintenance_requests` categories. The sender is also inquiring about available dates and expressing appreciation for the service, which falls under `general_inquiries`. Finally, the message mentions the sender's studio and the need for a thorough cleaning, which relates to `specialized_cleaning_services`.\n"
     ]
    }
   ],
   "source": [
    "prompt_6 = \"\"\"Giving the following message:\n",
    "---\n",
    "{{?input}}\n",
    "---\n",
    "Assign a list best matching support category tags to the message:\n",
    "{{?categories}}\n",
    "\"\"\"\n",
    "option_lists = {\n",
    "    'categories': ', '.join(f\"`{entry}`\" for entry in categories),\n",
    "}\n",
    "f_6 = partial(send_request, prompt=prompt_6, **option_lists)\n",
    "\n",
    "response = f_6(input=mail[\"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00ed181-b1fe-4b7a-b27b-c283a2331b93",
   "metadata": {},
   "source": [
    "## Category with  Descriptions and `json` Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9e838619-793b-4271-a9ae-3504174b7bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- PROMPT --->\n",
      "Giving the following message:\n",
      "---\n",
      "Subject: Scheduling Cleaning Services for My Studio\n",
      "\n",
      "Hi Support Team,\n",
      "\n",
      "I hope this message finds you well! My name is [Sender], and I’m a concept artist who has been enjoying the pristine environment your team helps maintain. Your services have been a game-changer for my creative space, and I truly appreciate the dedication and professionalism you bring to the table.\n",
      "\n",
      "I’m reaching out to discuss scheduling the next round of cleaning services for my studio. The space has been a whirlwind of creativity lately, and while it’s not urgent, I’d love to get a date on the calendar for a thorough cleaning. Your team’s attention to detail always leaves my workspace feeling fresh and inspiring, which is crucial for my work.\n",
      "\n",
      "I haven’t taken any steps yet to schedule this, as I wanted to touch base with you first to see what dates might be available. Ideally, I’m looking for a slot sometime in the next couple of weeks, but I’m flexible and happy to work around your schedule.\n",
      "\n",
      "Could you please assist me in setting up a convenient time for the cleaning? I’m looking forward to continuing our collaboration and keeping my studio in top shape.\n",
      "\n",
      "Thank you so much for your help!\n",
      "\n",
      "Best regards,\n",
      "[Sender]\n",
      "---\n",
      "Extract and return a json with the follwoing keys and values:\n",
      "- \"categories\" list of the best matching support category tags from: `specialized_cleaning_services`, `quality_and_safety_concerns`, `training_and_support_requests`, `facility_management_issues`, `customer_feedback_and_complaints`, `general_inquiries`, `emergency_repair_services`, `cleaning_services_scheduling`, `routine_maintenance_requests`, `sustainability_and_environmental_practices`\n",
      "Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.\n",
      "\n",
      "<--- RESPONSE --->\n",
      "{\"categories\":[\"cleaning_services_scheduling\",\"general_inquiries\",\"facility_management_issues\",\"routine_maintenance_requests\"]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 11.546 seconds\n"
     ]
    }
   ],
   "source": [
    "prompt_7 = \"\"\"Giving the following message:\n",
    "---\n",
    "{{?input}}\n",
    "---\n",
    "Extract and return a json with the follwoing keys and values:\n",
    "- \"categories\" list of the best matching support category tags from: {{?categories}}\n",
    "Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.\n",
    "\"\"\"\n",
    "f_7 = partial(send_request, prompt=prompt_7, **option_lists)\n",
    "\n",
    "response = f_7(input=mail[\"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b9c98e-51bd-4a9e-a90a-afcc0c48ea1c",
   "metadata": {},
   "source": [
    "## Complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2f70872c-a286-4749-869b-0ee274b750f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- PROMPT --->\n",
      "Giving the following message:\n",
      "---\n",
      "Subject: Scheduling Cleaning Services for My Studio\n",
      "\n",
      "Hi Support Team,\n",
      "\n",
      "I hope this message finds you well! My name is [Sender], and I’m a concept artist who has been enjoying the pristine environment your team helps maintain. Your services have been a game-changer for my creative space, and I truly appreciate the dedication and professionalism you bring to the table.\n",
      "\n",
      "I’m reaching out to discuss scheduling the next round of cleaning services for my studio. The space has been a whirlwind of creativity lately, and while it’s not urgent, I’d love to get a date on the calendar for a thorough cleaning. Your team’s attention to detail always leaves my workspace feeling fresh and inspiring, which is crucial for my work.\n",
      "\n",
      "I haven’t taken any steps yet to schedule this, as I wanted to touch base with you first to see what dates might be available. Ideally, I’m looking for a slot sometime in the next couple of weeks, but I’m flexible and happy to work around your schedule.\n",
      "\n",
      "Could you please assist me in setting up a convenient time for the cleaning? I’m looking forward to continuing our collaboration and keeping my studio in top shape.\n",
      "\n",
      "Thank you so much for your help!\n",
      "\n",
      "Best regards,\n",
      "[Sender]\n",
      "---\n",
      "Extract and return a json with the follwoing keys and values:\n",
      "- \"urgency\" as one of `medium`, `high`, `low`\n",
      "- \"sentiment\" as one of `negative`, `neutral`, `positive`\n",
      "- \"categories\" list of the best matching support category tags from: `specialized_cleaning_services`, `quality_and_safety_concerns`, `training_and_support_requests`, `facility_management_issues`, `customer_feedback_and_complaints`, `general_inquiries`, `emergency_repair_services`, `cleaning_services_scheduling`, `routine_maintenance_requests`, `sustainability_and_environmental_practices`\n",
      "Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.\n",
      "\n",
      "<--- RESPONSE --->\n",
      "{\"urgency\":\"low\",\"sentiment\":\"positive\",\"categories\":[\"cleaning_services_scheduling\",\"routine_maintenance_requests\",\"facility_management_issues\"]}\n"
     ]
    }
   ],
   "source": [
    "prompt_8 = \"\"\"Giving the following message:\n",
    "---\n",
    "{{?input}}\n",
    "---\n",
    "Extract and return a json with the follwoing keys and values:\n",
    "- \"urgency\" as one of {{?urgency}}\n",
    "- \"sentiment\" as one of {{?sentiment}}\n",
    "- \"categories\" list of the best matching support category tags from: {{?categories}}\n",
    "Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.\n",
    "\"\"\"\n",
    "option_lists = {\n",
    "    'urgency': ', '.join(f\"`{entry}`\" for entry in urgency),\n",
    "    'sentiment': ', '.join(f\"`{entry}`\" for entry in sentiment),\n",
    "    'categories': ', '.join(f\"`{entry}`\" for entry in categories),\n",
    "}\n",
    "f_8 = partial(send_request, prompt=prompt_8, **option_lists)\n",
    "\n",
    "response = f_8(input=mail[\"message\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bad5ec1-2671-4f4e-accf-986b46799bd9",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "af333cce-aea1-461e-b580-2d3f135a1f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "\n",
    "class RateLimitedIterator:\n",
    "    def __init__(self, iterable, max_iterations_per_minute):\n",
    "        self._iterable = iter(iterable)\n",
    "        self._max_iterations_per_minute = max_iterations_per_minute\n",
    "        self._min_interval = 1.0 / (max_iterations_per_minute / 60.)\n",
    "        self._last_yield_time = None\n",
    "\n",
    "    def __iter__(self):\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        current_time = time.time()\n",
    "\n",
    "        if self._last_yield_time is not None:\n",
    "            elapsed_time = current_time - self._last_yield_time\n",
    "            if elapsed_time < self._min_interval:\n",
    "                time.sleep(self._min_interval - elapsed_time)\n",
    "\n",
    "        self._last_yield_time = time.time()\n",
    "        return next(self._iterable)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4a9c171-c0f1-4c6c-ab41-f9d7b9d5d7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(mail: Dict[str, str], extract_func: Callable, _print=True, **kwargs):\n",
    "    response = extract_func(input=mail[\"message\"], _print=_print, **kwargs)\n",
    "    result = {\n",
    "        \"is_valid_json\": False,\n",
    "        \"correct_categories\": False,\n",
    "        \"correct_sentiment\": False,\n",
    "        \"correct_urgency\": False,\n",
    "    }\n",
    "    try:\n",
    "        pred = json.loads(response)\n",
    "    except json.JSONDecodeError:\n",
    "        result[\"is_valid_json\"] = False\n",
    "    else:\n",
    "        result[\"is_valid_json\"] = True\n",
    "        result[\"correct_categories\"] = 1 - (len(set(mail[\"ground_truth\"][\"categories\"]) ^ set(pred[\"categories\"])) / len(categories))\n",
    "        result[\"correct_sentiment\"] = pred[\"sentiment\"] == mail[\"ground_truth\"][\"sentiment\"]\n",
    "        result[\"correct_urgency\"] = pred[\"urgency\"] == mail[\"ground_truth\"][\"urgency\"]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9ba4fd28-d77c-471f-891c-0c794aa121db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- PROMPT --->\n",
      "Giving the following message:\n",
      "---\n",
      "Subject: Scheduling Cleaning Services for My Studio\n",
      "\n",
      "Hi Support Team,\n",
      "\n",
      "I hope this message finds you well! My name is [Sender], and I’m a concept artist who has been enjoying the pristine environment your team helps maintain. Your services have been a game-changer for my creative space, and I truly appreciate the dedication and professionalism you bring to the table.\n",
      "\n",
      "I’m reaching out to discuss scheduling the next round of cleaning services for my studio. The space has been a whirlwind of creativity lately, and while it’s not urgent, I’d love to get a date on the calendar for a thorough cleaning. Your team’s attention to detail always leaves my workspace feeling fresh and inspiring, which is crucial for my work.\n",
      "\n",
      "I haven’t taken any steps yet to schedule this, as I wanted to touch base with you first to see what dates might be available. Ideally, I’m looking for a slot sometime in the next couple of weeks, but I’m flexible and happy to work around your schedule.\n",
      "\n",
      "Could you please assist me in setting up a convenient time for the cleaning? I’m looking forward to continuing our collaboration and keeping my studio in top shape.\n",
      "\n",
      "Thank you so much for your help!\n",
      "\n",
      "Best regards,\n",
      "[Sender]\n",
      "---\n",
      "Extract and return a json with the follwoing keys and values:\n",
      "- \"urgency\" as one of `medium`, `high`, `low`\n",
      "- \"sentiment\" as one of `negative`, `neutral`, `positive`\n",
      "- \"categories\" list of the best matching support category tags from: `specialized_cleaning_services`, `quality_and_safety_concerns`, `training_and_support_requests`, `facility_management_issues`, `customer_feedback_and_complaints`, `general_inquiries`, `emergency_repair_services`, `cleaning_services_scheduling`, `routine_maintenance_requests`, `sustainability_and_environmental_practices`\n",
      "Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.\n",
      "\n",
      "<--- RESPONSE --->\n",
      "{\"urgency\":\"low\",\"sentiment\":\"positive\",\"categories\":[\"cleaning_services_scheduling\",\"general_inquiries\",\"facility_management_issues\"]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'is_valid_json': True,\n",
       " 'correct_categories': 0.8,\n",
       " 'correct_sentiment': True,\n",
       " 'correct_urgency': True}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluation(mail, f_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4db50d08-aa03-4361-a889-02ea9ca45437",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 8.250 seconds\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "def transpose_list_of_dicts(list_of_dicts):\n",
    "    keys = list_of_dicts[0].keys()\n",
    "    transposed_dict = {key: [] for key in keys}\n",
    "    for d in list_of_dicts:\n",
    "        for key, value in d.items():\n",
    "            transposed_dict[key].append(value)\n",
    "    return transposed_dict\n",
    "\n",
    "def evalulation_full_dataset(dataset, func, rate_limit=100, _print=False, **kwargs):\n",
    "    results = [evaluation(mail, func, _print=_print, **kwargs) for mail in tqdm(RateLimitedIterator(dataset, rate_limit), total=len(dataset))]\n",
    "    results = transpose_list_of_dicts(results)\n",
    "    n = len(dataset)\n",
    "    for k, v in results.items():\n",
    "        results[k] = sum(v) / len(dataset)\n",
    "    return results\n",
    "\n",
    "\n",
    "def pretty_print_table(data):\n",
    "    # Get all row names (outer dict keys)\n",
    "    row_names = list(data.keys())\n",
    "\n",
    "    # Get all column names (inner dict keys)\n",
    "    if row_names:\n",
    "        column_names = list(data[row_names[0]].keys())\n",
    "    else:\n",
    "        column_names = []\n",
    "\n",
    "    # Calculate column widths\n",
    "    column_widths = [max(len(str(column_name)), max(len(f\"{data[row][column_name]:.2f}\") for row in row_names)) for column_name in column_names]\n",
    "    row_name_width = max(len(str(row_name)) for row_name in row_names)\n",
    "\n",
    "    # Print header\n",
    "    header = f\"{'':>{row_name_width}} \" + \" \".join([f\"{column_name:>{width}}\" for column_name, width in zip(column_names, column_widths)])\n",
    "    print(header)\n",
    "    print(\"=\" * len(header))\n",
    "\n",
    "    # Print rows\n",
    "    for row_name in row_names:\n",
    "        row = f\"{row_name:>{row_name_width}} \" + \" \".join([f\"{data[row_name][column_name]:>{width}.1%}\" for column_name, width in zip(column_names, column_widths)])\n",
    "        print(row)\n",
    "\n",
    "overall_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "45d7374a-6974-4245-8128-59d9526015ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dec9cec105b44fc4b916a4f3f80f4bc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  is_valid_json correct_categories correct_sentiment correct_urgency\n",
      "====================================================================================\n",
      "basic--llama3-70b        100.0%              84.5%             40.0%           60.0%\n"
     ]
    }
   ],
   "source": [
    "overall_result[\"basic--llama3-70b\"] = evalulation_full_dataset(test_set_small, f_8)\n",
    "pretty_print_table(overall_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd84ae0-90bb-4528-a23d-6d9cc9c2ce09",
   "metadata": {},
   "source": [
    "Rerunning the cell above shows that the output depends a lot on the given input example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adbeb50-23ee-465e-bcec-0db0b1bc56e1",
   "metadata": {},
   "source": [
    "## Few-Shot Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8b334bf1-bed1-430d-ac6c-766973cc8f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- PROMPT --->\n",
      "Your task is to extract and categorize messages. Here are some example:\n",
      "---\n",
      "<example>\n",
      "Subject: Inquiry About Training Programs for In-House Maintenance Team\n",
      "\n",
      "Hi Support Team,\n",
      "\n",
      "I hope this message finds you well. My name is Alex, and I’ve been a satisfied customer of Facility Solutions Company for the past year. I’m reaching out today with a request for more information regarding your training programs.\n",
      "\n",
      "As a parent who values evidence-based practices, I’m particularly interested in ensuring that our in-house maintenance team is equipped with the latest knowledge and skills. We’ve been managing our residential complex with a focus on sustainability and efficiency, and I believe that proper training is crucial for maintaining these standards.\n",
      "\n",
      "Could you provide me with details about the training programs you offer? Specifically, I’m looking for information on the curriculum, duration, and any certifications that might be included. Additionally, I’d like to know if there are any upcoming sessions that we could potentially enroll in.\n",
      "\n",
      "I haven’t taken any steps yet to resolve this on my own, as I wanted to get the most accurate and comprehensive information directly from your team. Your expertise and guidance would be greatly appreciated.\n",
      "\n",
      "Thank you for your time and assistance. I look forward to your response.\n",
      "\n",
      "Best regards, Alex\n",
      "\n",
      "[Sender]\n",
      "\n",
      "## Output\n",
      "\n",
      "{\"categories\": [\"general_inquiries\", \"training_and_support_requests\"], \"sentiment\": \"neutral\", \"urgency\": \"low\"}\n",
      "</example>\n",
      "---\n",
      "<example>\n",
      "Здравствуйте, команда поддержки Facility Solutions Company,\n",
      "\n",
      "Меня зовут Алексей, я живу в Москве и пользуюсь вашими услугами по управлению и обслуживанию нашего жилого комплекса. В целом, я доволен качеством предоставляемых услуг, но у меня возник вопрос, касающийся ваших практик в области устойчивого развития и охраны окружающей среды.\n",
      "\n",
      "Недавно я заметил, что в нашем комплексе не всегда используются экологически чистые продукты для уборки, несмотря на то, что это заявлено в ваших услугах. Это вызывает у меня некоторые сомнения относительно вашего подхода к устойчивому развитию и снижению углеродного следа.\n",
      "\n",
      "Я уже пытался обсудить этот вопрос с вашим местным менеджером, но, к сожалению, не получил четкого ответа. Поэтому я решил обратиться к вам напрямую, чтобы прояснить ситуацию.\n",
      "\n",
      "Могли бы вы, пожалуйста, предоставить более подробную информацию о том, какие именно экологически чистые продукты и практики вы используете в нашей резиденции? Также было бы полезно узнать, какие меры вы предпринимаете для повышения устойчивости и снижения воздействия на окружающую среду.\n",
      "\n",
      "Заранее благодарю за вашу помощь и надеюсь на скорый ответ.\n",
      "\n",
      "С уважением,\n",
      "Алексей\n",
      "\n",
      "[Sender]\n",
      "\n",
      "## Output\n",
      "\n",
      "{\"categories\": [\"specialized_cleaning_services\", \"sustainability_and_environmental_practices\"], \"sentiment\": \"neutral\", \"urgency\": \"low\"}\n",
      "</example>\n",
      "---\n",
      "<example>\n",
      "Hey Support Team,\n",
      "\n",
      "Hope you're all doing well. My name's [Sender], and I've been using Facility Solutions Company for a while now. You guys have been doing a solid job keeping things running smoothly at my place.\n",
      "\n",
      "I'm reaching out because I need some help with your training programs. I've been trying to get my in-house maintenance team up to speed with the best practices for facility management. I know you offer comprehensive training, and I think it could really benefit my team.\n",
      "\n",
      "I've looked through the resources on your website and tried to piece together some of the information, but I feel like a more structured approach would be better. Could you guide me on how to get started with your training programs? Maybe there's a specific course or set of materials you recommend for a team that's just getting started?\n",
      "\n",
      "Thanks a lot for your help. Looking forward to hearing from you soon.\n",
      "\n",
      "Best,\n",
      "[Sender]\n",
      "\n",
      "## Output\n",
      "\n",
      "{\"categories\": [\"training_and_support_requests\"], \"sentiment\": \"neutral\", \"urgency\": \"low\"}\n",
      "</example>\n",
      "---\n",
      "Use the examples when extract and categorize the following message:\n",
      "---\n",
      "Subject: Scheduling Cleaning Services for My Studio\n",
      "\n",
      "Hi Support Team,\n",
      "\n",
      "I hope this message finds you well! My name is [Sender], and I’m a concept artist who has been enjoying the pristine environment your team helps maintain. Your services have been a game-changer for my creative space, and I truly appreciate the dedication and professionalism you bring to the table.\n",
      "\n",
      "I’m reaching out to discuss scheduling the next round of cleaning services for my studio. The space has been a whirlwind of creativity lately, and while it’s not urgent, I’d love to get a date on the calendar for a thorough cleaning. Your team’s attention to detail always leaves my workspace feeling fresh and inspiring, which is crucial for my work.\n",
      "\n",
      "I haven’t taken any steps yet to schedule this, as I wanted to touch base with you first to see what dates might be available. Ideally, I’m looking for a slot sometime in the next couple of weeks, but I’m flexible and happy to work around your schedule.\n",
      "\n",
      "Could you please assist me in setting up a convenient time for the cleaning? I’m looking forward to continuing our collaboration and keeping my studio in top shape.\n",
      "\n",
      "Thank you so much for your help!\n",
      "\n",
      "Best regards,\n",
      "[Sender]\n",
      "---\n",
      "Extract and return a json with the follwoing keys and values:\n",
      "- \"urgency\" as one of `medium`, `high`, `low`\n",
      "- \"sentiment\" as one of `negative`, `neutral`, `positive`\n",
      "- \"categories\" list of the best matching support category tags from: `specialized_cleaning_services`, `quality_and_safety_concerns`, `training_and_support_requests`, `facility_management_issues`, `customer_feedback_and_complaints`, `general_inquiries`, `emergency_repair_services`, `cleaning_services_scheduling`, `routine_maintenance_requests`, `sustainability_and_environmental_practices`\n",
      "Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.\n",
      "\n",
      "<--- RESPONSE --->\n",
      "{\"categories\": [\"cleaning_services_scheduling\", \"routine_maintenance_requests\"], \"sentiment\": \"positive\", \"urgency\": \"low\"}\n"
     ]
    }
   ],
   "source": [
    "prompt_10 = \"\"\"Your task is to extract and categorize messages. Here are some example:\n",
    "---\n",
    "{{?few_shot_examples}}\n",
    "---\n",
    "Use the examples when extract and categorize the following message:\n",
    "---\n",
    "{{?input}}\n",
    "---\n",
    "Extract and return a json with the follwoing keys and values:\n",
    "- \"urgency\" as one of {{?urgency}}\n",
    "- \"sentiment\" as one of {{?sentiment}}\n",
    "- \"categories\" list of the best matching support category tags from: {{?categories}}\n",
    "Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.\n",
    "\"\"\"\n",
    "\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "k = 3\n",
    "examples = random.sample(dev_set, k)\n",
    "\n",
    "example_template = \"\"\"<example>\n",
    "{example_input}\n",
    "\n",
    "## Output\n",
    "\n",
    "{example_output}\n",
    "</example>\"\"\"\n",
    "\n",
    "examples = '\\n---\\n'.join([example_template.format(example_input=example[\"message\"], example_output=json.dumps(example[\"ground_truth\"])) for example in examples])\n",
    "\n",
    "\n",
    "f_10 = partial(send_request, prompt=prompt_10, few_shot_examples=examples, **option_lists)\n",
    "\n",
    "response = f_10(input=mail[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "60aab69b-78a8-4ec7-ba69-1d6ce50461c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a1ee070dabe472da30cb20c20025d29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     is_valid_json correct_categories correct_sentiment correct_urgency\n",
      "=======================================================================================\n",
      "   basic--llama3-70b        100.0%              84.5%             40.0%           60.0%\n",
      "few_shot--llama3-70b        100.0%              86.5%             70.0%           80.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 149.797 seconds\n"
     ]
    }
   ],
   "source": [
    "overall_result[\"few_shot--llama3-70b\"] = evalulation_full_dataset(test_set_small, f_10)\n",
    "pretty_print_table(overall_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11ba3381-47ab-42ca-a864-9e82bf82eca3",
   "metadata": {},
   "source": [
    "## Use Metaprompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "40991056-0ab4-40a2-b2d7-67c7ef5686a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "example_template_metaprompt = \"\"\"<example>\n",
    "{example_input}\n",
    "\n",
    "## Output\n",
    "{key}={example_output}\n",
    "</example>\"\"\"\n",
    "\n",
    "prompt_get_guide = \"\"\"Here are some example:\n",
    "---\n",
    "{{?examples}}\n",
    "---\n",
    "Use the examples above to come up with a guide on how to distinguish between {{?options}} {{?key}}.\n",
    "Use the following format:\n",
    "```\n",
    "### **<category 1>**\n",
    "- <instruction 1>\n",
    "- <instruction 2>\n",
    "- <instruction 3>\n",
    "### **<category 2>**\n",
    "- <instruction 1>\n",
    "- <instruction 2>\n",
    "- <instruction 3>\n",
    "...\n",
    "```\n",
    "When creating the guide:\n",
    "- make it step-by-step instructions\n",
    "- Consider than some labels in the examples might be in correct\n",
    "- Avoid including explicit information from the examples in the guide\n",
    "The guide has to cover: {{?options}}\n",
    "\"\"\"\n",
    "\n",
    "guides = {}\n",
    "\n",
    "for i, key in enumerate([\"categories\", \"urgency\", \"sentiment\"]):\n",
    "    options = option_lists[key]\n",
    "    selected_examples_txt_metaprompt = '\\n---\\n'.join([example_template_metaprompt.format(example_input=example[\"message\"], key=key, example_output=example[\"ground_truth\"][key]) for example in dev_set])\n",
    "    guides[f\"guide_{key}\"] = send_request(prompt=prompt_get_guide, examples=selected_examples_txt_metaprompt, key=key, options=options, _print=False, _model='gpt-4o')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0eb2d5d9-f59b-4257-9907-a8f50a3490ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### **High Urgency**\n",
      "- **Immediate Attention Required**: Determine if the message indicates that the problem needs to be resolved immediately due to significant negative impacts on safety, comfort, productivity, or critical operations.\n",
      "- **Escalated Issues**: Look for references to attempts already made to resolve the issue, such as contacting support or performing basic troubleshooting, which have not been successful.\n",
      "- **Severe Consequences**: Identify situations where continued delay could lead to severe consequences, including operational disruptions, safety risks, or significant discomfort.\n",
      "\n",
      "### **Medium Urgency**\n",
      "- **Routine Maintenance or Quality Concerns**: Check if the message involves scheduling routine maintenance or addressing ongoing quality issues that are important but not urgent.\n",
      "- **Efficiency and Effectiveness Improvements**: Evaluate if the message seeks to improve the efficiency or effectiveness of facility operations, which is important but not critical for immediate attention.\n",
      "- **Proactive Measures**: Determine if the message is about taking proactive steps to prevent potential issues rather than resolving an immediate problem.\n",
      "\n",
      "### **Low Urgency**\n",
      "- **General Inquiries or Information Requests**: Look for messages that primarily seek information or have general inquiries about services, which do not imply an urgent need.\n",
      "- **Planning and Consultation**: Identify requests for planning consultations, training programs, or general advice that do not require immediate action or intervention.\n",
      "- **Assurance on Existing Services**: Assess if the message is about verifying or understanding existing services and practices without indicating any immediate problems or disruptions.\n",
      "\n",
      "By following these instructions, you can accurately determine the urgency level of different requests or inquiries based on their content and context.\n"
     ]
    }
   ],
   "source": [
    "print(guides['guide_urgency'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1bb60416-90bb-4e1e-96d5-2ad3c3dc44c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- PROMPT --->\n",
      "Your task is to classify messages.\n",
      "This is an explanation of `urgency` labels:\n",
      "---\n",
      "### **High Urgency**\n",
      "- **Immediate Attention Required**: Determine if the message indicates that the problem needs to be resolved immediately due to significant negative impacts on safety, comfort, productivity, or critical operations.\n",
      "- **Escalated Issues**: Look for references to attempts already made to resolve the issue, such as contacting support or performing basic troubleshooting, which have not been successful.\n",
      "- **Severe Consequences**: Identify situations where continued delay could lead to severe consequences, including operational disruptions, safety risks, or significant discomfort.\n",
      "\n",
      "### **Medium Urgency**\n",
      "- **Routine Maintenance or Quality Concerns**: Check if the message involves scheduling routine maintenance or addressing ongoing quality issues that are important but not urgent.\n",
      "- **Efficiency and Effectiveness Improvements**: Evaluate if the message seeks to improve the efficiency or effectiveness of facility operations, which is important but not critical for immediate attention.\n",
      "- **Proactive Measures**: Determine if the message is about taking proactive steps to prevent potential issues rather than resolving an immediate problem.\n",
      "\n",
      "### **Low Urgency**\n",
      "- **General Inquiries or Information Requests**: Look for messages that primarily seek information or have general inquiries about services, which do not imply an urgent need.\n",
      "- **Planning and Consultation**: Identify requests for planning consultations, training programs, or general advice that do not require immediate action or intervention.\n",
      "- **Assurance on Existing Services**: Assess if the message is about verifying or understanding existing services and practices without indicating any immediate problems or disruptions.\n",
      "\n",
      "By following these instructions, you can accurately determine the urgency level of different requests or inquiries based on their content and context.\n",
      "---\n",
      "This is an explanation of `sentiment` labels:\n",
      "---\n",
      "```\n",
      "### **Negative Sentiment Identification**\n",
      "- **Identify Strong Negative Language:**\n",
      "  - Look for words or phrases that explicitly express dissatisfaction, frustration, disappointment, or anger.\n",
      "  - Examples: \"disappointed,\" \"frustrating,\" \"unacceptable,\" \"critical problem,\" \"glaring issues.\"\n",
      "  \n",
      "- **Analyze the Overall Tone:**\n",
      "  - Check if the overall tone of the message is accusatory, demanding, or conveys urgency due to a problematic situation.\n",
      "  - Determine if the sender is expressing a clear need for immediate resolution due to serious concerns.\n",
      "\n",
      "- **Evaluate Resolution Efforts:**\n",
      "  - Note if the sender has already attempted to resolve the issue unsuccessfully.\n",
      "  - Identify if the sender is indicating a breakdown in communication or a lack of satisfactory response from the receiver.\n",
      "\n",
      "### **Neutral Sentiment Identification**\n",
      "- **Identify Informative or Routine Requests:**\n",
      "  - Look for messages that make routine inquiries, request information, or ask for standard services without expressing strong emotions.\n",
      "  - Examples: \"Could you please provide,\" \"I am writing to inquire about,\" \"I would appreciate more information.\"\n",
      "\n",
      "- **Evaluate the Tone and Language:**\n",
      "  - The tone should be neither overly positive nor negative but rather factual and straightforward.\n",
      "  - The language should remain balanced, without significant expression of satisfaction or dissatisfaction.\n",
      "\n",
      "- **Check for Lack of Urgency or Strong Emotion:**\n",
      "  - Ensure the message does not contain words or phrases that indicate urgency, critical issues, or intense emotions.\n",
      "  - The sender’s tone should indicate a standard inquiry or request handling without immediate concerns.\n",
      "\n",
      "### **Positive Sentiment Identification**\n",
      "- **Identify Positive Language and Praise:**\n",
      "  - Look for words or phrases that explicitly express satisfaction, gratitude, appreciation, or commendation.\n",
      "  - Examples: \"appreciate,\" \"satisfied,\" \"fantastic job,\" \"commendable,\" \"impressed.\"\n",
      "\n",
      "- **Analyze the Overall Tone:**\n",
      "  - Check if the overall tone of the message is friendly, polite, and conveys a sense of thankfulness or contentment.\n",
      "  - Determine if the sender is complimenting the receiver’s past performance or expressing confidence in their abilities.\n",
      "\n",
      "- **Evaluate Expressions of Trust and Confidence:**\n",
      "  - Note if the sender conveys trust in the receiver’s ability to resolve issues or provide services effectively.\n",
      "  - Identify if the sender mentions positive past experiences that reinforce their faith in the receiver’s work.\n",
      "```\n",
      "---\n",
      "This is an explanation of `support` categories:\n",
      "---\n",
      "```\n",
      "### **specialized_cleaning_services**\n",
      "- Identify if the request is asking for specific types of cleaning services beyond regular cleaning, such as deep cleaning or carpet maintenance.\n",
      "- Check whether the inquiry mentions the need for targeted cleaning of areas like carpets, windows, upholstery, or other specific parts of the property.\n",
      "- Confirm that the request is not urgent but focuses on maintaining or restoring cleanliness in a specialized manner.\n",
      "\n",
      "### **quality_and_safety_concerns**\n",
      "- Look for mentions of inconsistencies or lapses in the quality of services being provided.\n",
      "- Identify any safety-related issues, such as improper storage of products, blocked emergency exits, or substandard cleaning practices.\n",
      "- Note if the sender expresses concern over the health, safety, or overall standards of the environment as a result of the services.\n",
      "\n",
      "### **training_and_support_requests**\n",
      "- Determine if the sender is asking for training programs, support, or guidance related to facility management or maintenance practices.\n",
      "- Check if there is a specific mention of needing help with understanding or implementing best practices or new protocols.\n",
      "- Identify requests for detailed instructions, new training materials, or further education for themselves or their team.\n",
      "\n",
      "### **facility_management_issues**\n",
      "- Look for statements about problems with the overall coordination and management of the facility, such as space utilization and scheduling conflicts.\n",
      "- Identify recurring issues that impact the efficiency or security of the facility, requiring a comprehensive review or adjustment.\n",
      "- Confirm that the issue is broader and not limited to a single service, focusing on the overall management or operational system.\n",
      "\n",
      "### **customer_feedback_and_complaints**\n",
      "- Detect expressions of dissatisfaction with current services, indicating something has not met expectations.\n",
      "- Identify any specific incidents or ongoing issues that the customer wants to be addressed or improved.\n",
      "- Look for mentions of prior attempts to resolve the issue directly without success, leading to this formal complaint.\n",
      "\n",
      "### **general_inquiries**\n",
      "- Recognize when the sender is requesting basic information about the services provided without mentioning specific issues or urgent needs.\n",
      "- Identify inquiries that seek general knowledge such as service descriptions, pricing, scheduling, or potential new services.\n",
      "- Ensure that the request is broad and information-gathering in nature rather than resolving specific problems.\n",
      "\n",
      "### **emergency_repair_services**\n",
      "- Look for mentions of urgent or critical issues that need immediate intervention, like malfunctioning HVAC systems or severe plumbing leaks.\n",
      "- Identify if the sender describes an issue that directly impacts safety, comfort, or the functionality of the facility and requires swift action.\n",
      "- Confirm that the sender has already made attempts to troubleshoot the problem without success, highlighting the urgency for professional repair.\n",
      "\n",
      "### **cleaning_services_scheduling**\n",
      "- Determine if the sender is looking to schedule or adjust their ongoing cleaning services, including regular or seasonal deep cleaning.\n",
      "- Identify requests that involve setting dates, times, and frequencies for cleaning sessions.\n",
      "- Confirm that the request is more about organizing and planning rather than addressing complaints or specialized needs.\n",
      "\n",
      "### **routine_maintenance_requests**\n",
      "- Identify mentions of regular or periodic checks and upkeep of systems, such as HVAC, plumbing, or electrical systems.\n",
      "- Look for requests that ensure the proper functioning of these systems through scheduled maintenance rather than emergency repairs.\n",
      "- Confirm that the sender emphasizes preventive measures to avoid potential issues rather than solving current crises.\n",
      "\n",
      "### **sustainability_and_environmental_practices**\n",
      "- Recognize inquiries related to the environmental impact of the services, such as the use of eco-friendly products and sustainable practices.\n",
      "- Identify when the sender requests information on how the company reduces its carbon footprint, energy efficiency measures, or waste reduction strategies.\n",
      "- Confirm that the key focus is on environmental responsibility and future initiatives rather than immediate service-related issues.\n",
      "```\n",
      "---\n",
      "Giving the following message:\n",
      "---\n",
      "Subject: Scheduling Cleaning Services for My Studio\n",
      "\n",
      "Hi Support Team,\n",
      "\n",
      "I hope this message finds you well! My name is [Sender], and I’m a concept artist who has been enjoying the pristine environment your team helps maintain. Your services have been a game-changer for my creative space, and I truly appreciate the dedication and professionalism you bring to the table.\n",
      "\n",
      "I’m reaching out to discuss scheduling the next round of cleaning services for my studio. The space has been a whirlwind of creativity lately, and while it’s not urgent, I’d love to get a date on the calendar for a thorough cleaning. Your team’s attention to detail always leaves my workspace feeling fresh and inspiring, which is crucial for my work.\n",
      "\n",
      "I haven’t taken any steps yet to schedule this, as I wanted to touch base with you first to see what dates might be available. Ideally, I’m looking for a slot sometime in the next couple of weeks, but I’m flexible and happy to work around your schedule.\n",
      "\n",
      "Could you please assist me in setting up a convenient time for the cleaning? I’m looking forward to continuing our collaboration and keeping my studio in top shape.\n",
      "\n",
      "Thank you so much for your help!\n",
      "\n",
      "Best regards,\n",
      "[Sender]\n",
      "---\n",
      "Extract and return a json with the follwoing keys and values:\n",
      "- \"urgency\" as one of `medium`, `high`, `low`\n",
      "- \"sentiment\" as one of `negative`, `neutral`, `positive`\n",
      "- \"categories\" list of the best matching support category tags from: `specialized_cleaning_services`, `quality_and_safety_concerns`, `training_and_support_requests`, `facility_management_issues`, `customer_feedback_and_complaints`, `general_inquiries`, `emergency_repair_services`, `cleaning_services_scheduling`, `routine_maintenance_requests`, `sustainability_and_environmental_practices`\n",
      "Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.\n",
      "\n",
      "<--- RESPONSE --->\n",
      "{\"urgency\": \"low\", \"sentiment\": \"positive\", \"categories\": [\"cleaning_services_scheduling\"]}\n"
     ]
    }
   ],
   "source": [
    "prompt_12 = \"\"\"Your task is to classify messages.\n",
    "This is an explanation of `urgency` labels:\n",
    "---\n",
    "{{?guide_urgency}}\n",
    "---\n",
    "This is an explanation of `sentiment` labels:\n",
    "---\n",
    "{{?guide_sentiment}}\n",
    "---\n",
    "This is an explanation of `support` categories:\n",
    "---\n",
    "{{?guide_categories}}\n",
    "---\n",
    "Giving the following message:\n",
    "---\n",
    "{{?input}}\n",
    "---\n",
    "Extract and return a json with the follwoing keys and values:\n",
    "- \"urgency\" as one of {{?urgency}}\n",
    "- \"sentiment\" as one of {{?sentiment}}\n",
    "- \"categories\" list of the best matching support category tags from: {{?categories}}\n",
    "Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.\n",
    "\"\"\"\n",
    "f_12 = partial(send_request, prompt=prompt_12, **option_lists, **guides)\n",
    "response = f_12(input=mail[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5ab365e2-2922-4c7c-a1e5-8b5fb3504564",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b00c8e63fb470ca71b4e4bd18fef85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          is_valid_json correct_categories correct_sentiment correct_urgency\n",
      "============================================================================================\n",
      "        basic--llama3-70b        100.0%              84.5%             40.0%           60.0%\n",
      "     few_shot--llama3-70b        100.0%              86.5%             70.0%           80.0%\n",
      "metaprompting--llama3-70b        100.0%              88.5%             55.0%           75.0%\n"
     ]
    }
   ],
   "source": [
    "overall_result[\"metaprompting--llama3-70b\"] = evalulation_full_dataset(test_set_small, f_12)\n",
    "pretty_print_table(overall_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72356cb-bcf0-43e3-9cdb-1ac774a756da",
   "metadata": {},
   "source": [
    "## Combine Few-Shot with Metaprompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "549849da-787a-47e0-ad27-acc04e2c441f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<-- PROMPT --->\n",
      "Your task is to classify messages.\n",
      "Here are some examples:\n",
      "---\n",
      "<example>\n",
      "Subject: Inquiry About Training Programs for In-House Maintenance Team\n",
      "\n",
      "Hi Support Team,\n",
      "\n",
      "I hope this message finds you well. My name is Alex, and I’ve been a satisfied customer of Facility Solutions Company for the past year. I’m reaching out today with a request for more information regarding your training programs.\n",
      "\n",
      "As a parent who values evidence-based practices, I’m particularly interested in ensuring that our in-house maintenance team is equipped with the latest knowledge and skills. We’ve been managing our residential complex with a focus on sustainability and efficiency, and I believe that proper training is crucial for maintaining these standards.\n",
      "\n",
      "Could you provide me with details about the training programs you offer? Specifically, I’m looking for information on the curriculum, duration, and any certifications that might be included. Additionally, I’d like to know if there are any upcoming sessions that we could potentially enroll in.\n",
      "\n",
      "I haven’t taken any steps yet to resolve this on my own, as I wanted to get the most accurate and comprehensive information directly from your team. Your expertise and guidance would be greatly appreciated.\n",
      "\n",
      "Thank you for your time and assistance. I look forward to your response.\n",
      "\n",
      "Best regards, Alex\n",
      "\n",
      "[Sender]\n",
      "\n",
      "## Output\n",
      "\n",
      "{\"categories\": [\"general_inquiries\", \"training_and_support_requests\"], \"sentiment\": \"neutral\", \"urgency\": \"low\"}\n",
      "</example>\n",
      "---\n",
      "<example>\n",
      "Здравствуйте, команда поддержки Facility Solutions Company,\n",
      "\n",
      "Меня зовут Алексей, я живу в Москве и пользуюсь вашими услугами по управлению и обслуживанию нашего жилого комплекса. В целом, я доволен качеством предоставляемых услуг, но у меня возник вопрос, касающийся ваших практик в области устойчивого развития и охраны окружающей среды.\n",
      "\n",
      "Недавно я заметил, что в нашем комплексе не всегда используются экологически чистые продукты для уборки, несмотря на то, что это заявлено в ваших услугах. Это вызывает у меня некоторые сомнения относительно вашего подхода к устойчивому развитию и снижению углеродного следа.\n",
      "\n",
      "Я уже пытался обсудить этот вопрос с вашим местным менеджером, но, к сожалению, не получил четкого ответа. Поэтому я решил обратиться к вам напрямую, чтобы прояснить ситуацию.\n",
      "\n",
      "Могли бы вы, пожалуйста, предоставить более подробную информацию о том, какие именно экологически чистые продукты и практики вы используете в нашей резиденции? Также было бы полезно узнать, какие меры вы предпринимаете для повышения устойчивости и снижения воздействия на окружающую среду.\n",
      "\n",
      "Заранее благодарю за вашу помощь и надеюсь на скорый ответ.\n",
      "\n",
      "С уважением,\n",
      "Алексей\n",
      "\n",
      "[Sender]\n",
      "\n",
      "## Output\n",
      "\n",
      "{\"categories\": [\"specialized_cleaning_services\", \"sustainability_and_environmental_practices\"], \"sentiment\": \"neutral\", \"urgency\": \"low\"}\n",
      "</example>\n",
      "---\n",
      "<example>\n",
      "Hey Support Team,\n",
      "\n",
      "Hope you're all doing well. My name's [Sender], and I've been using Facility Solutions Company for a while now. You guys have been doing a solid job keeping things running smoothly at my place.\n",
      "\n",
      "I'm reaching out because I need some help with your training programs. I've been trying to get my in-house maintenance team up to speed with the best practices for facility management. I know you offer comprehensive training, and I think it could really benefit my team.\n",
      "\n",
      "I've looked through the resources on your website and tried to piece together some of the information, but I feel like a more structured approach would be better. Could you guide me on how to get started with your training programs? Maybe there's a specific course or set of materials you recommend for a team that's just getting started?\n",
      "\n",
      "Thanks a lot for your help. Looking forward to hearing from you soon.\n",
      "\n",
      "Best,\n",
      "[Sender]\n",
      "\n",
      "## Output\n",
      "\n",
      "{\"categories\": [\"training_and_support_requests\"], \"sentiment\": \"neutral\", \"urgency\": \"low\"}\n",
      "</example>\n",
      "---\n",
      "This is an explanation of `urgency` labels:\n",
      "---\n",
      "### **High Urgency**\n",
      "- **Immediate Attention Required**: Determine if the message indicates that the problem needs to be resolved immediately due to significant negative impacts on safety, comfort, productivity, or critical operations.\n",
      "- **Escalated Issues**: Look for references to attempts already made to resolve the issue, such as contacting support or performing basic troubleshooting, which have not been successful.\n",
      "- **Severe Consequences**: Identify situations where continued delay could lead to severe consequences, including operational disruptions, safety risks, or significant discomfort.\n",
      "\n",
      "### **Medium Urgency**\n",
      "- **Routine Maintenance or Quality Concerns**: Check if the message involves scheduling routine maintenance or addressing ongoing quality issues that are important but not urgent.\n",
      "- **Efficiency and Effectiveness Improvements**: Evaluate if the message seeks to improve the efficiency or effectiveness of facility operations, which is important but not critical for immediate attention.\n",
      "- **Proactive Measures**: Determine if the message is about taking proactive steps to prevent potential issues rather than resolving an immediate problem.\n",
      "\n",
      "### **Low Urgency**\n",
      "- **General Inquiries or Information Requests**: Look for messages that primarily seek information or have general inquiries about services, which do not imply an urgent need.\n",
      "- **Planning and Consultation**: Identify requests for planning consultations, training programs, or general advice that do not require immediate action or intervention.\n",
      "- **Assurance on Existing Services**: Assess if the message is about verifying or understanding existing services and practices without indicating any immediate problems or disruptions.\n",
      "\n",
      "By following these instructions, you can accurately determine the urgency level of different requests or inquiries based on their content and context.\n",
      "---\n",
      "This is an explanation of `sentiment` labels:\n",
      "---\n",
      "```\n",
      "### **Negative Sentiment Identification**\n",
      "- **Identify Strong Negative Language:**\n",
      "  - Look for words or phrases that explicitly express dissatisfaction, frustration, disappointment, or anger.\n",
      "  - Examples: \"disappointed,\" \"frustrating,\" \"unacceptable,\" \"critical problem,\" \"glaring issues.\"\n",
      "  \n",
      "- **Analyze the Overall Tone:**\n",
      "  - Check if the overall tone of the message is accusatory, demanding, or conveys urgency due to a problematic situation.\n",
      "  - Determine if the sender is expressing a clear need for immediate resolution due to serious concerns.\n",
      "\n",
      "- **Evaluate Resolution Efforts:**\n",
      "  - Note if the sender has already attempted to resolve the issue unsuccessfully.\n",
      "  - Identify if the sender is indicating a breakdown in communication or a lack of satisfactory response from the receiver.\n",
      "\n",
      "### **Neutral Sentiment Identification**\n",
      "- **Identify Informative or Routine Requests:**\n",
      "  - Look for messages that make routine inquiries, request information, or ask for standard services without expressing strong emotions.\n",
      "  - Examples: \"Could you please provide,\" \"I am writing to inquire about,\" \"I would appreciate more information.\"\n",
      "\n",
      "- **Evaluate the Tone and Language:**\n",
      "  - The tone should be neither overly positive nor negative but rather factual and straightforward.\n",
      "  - The language should remain balanced, without significant expression of satisfaction or dissatisfaction.\n",
      "\n",
      "- **Check for Lack of Urgency or Strong Emotion:**\n",
      "  - Ensure the message does not contain words or phrases that indicate urgency, critical issues, or intense emotions.\n",
      "  - The sender’s tone should indicate a standard inquiry or request handling without immediate concerns.\n",
      "\n",
      "### **Positive Sentiment Identification**\n",
      "- **Identify Positive Language and Praise:**\n",
      "  - Look for words or phrases that explicitly express satisfaction, gratitude, appreciation, or commendation.\n",
      "  - Examples: \"appreciate,\" \"satisfied,\" \"fantastic job,\" \"commendable,\" \"impressed.\"\n",
      "\n",
      "- **Analyze the Overall Tone:**\n",
      "  - Check if the overall tone of the message is friendly, polite, and conveys a sense of thankfulness or contentment.\n",
      "  - Determine if the sender is complimenting the receiver’s past performance or expressing confidence in their abilities.\n",
      "\n",
      "- **Evaluate Expressions of Trust and Confidence:**\n",
      "  - Note if the sender conveys trust in the receiver’s ability to resolve issues or provide services effectively.\n",
      "  - Identify if the sender mentions positive past experiences that reinforce their faith in the receiver’s work.\n",
      "```\n",
      "---\n",
      "This is an explanation of `support` categories:\n",
      "---\n",
      "```\n",
      "### **specialized_cleaning_services**\n",
      "- Identify if the request is asking for specific types of cleaning services beyond regular cleaning, such as deep cleaning or carpet maintenance.\n",
      "- Check whether the inquiry mentions the need for targeted cleaning of areas like carpets, windows, upholstery, or other specific parts of the property.\n",
      "- Confirm that the request is not urgent but focuses on maintaining or restoring cleanliness in a specialized manner.\n",
      "\n",
      "### **quality_and_safety_concerns**\n",
      "- Look for mentions of inconsistencies or lapses in the quality of services being provided.\n",
      "- Identify any safety-related issues, such as improper storage of products, blocked emergency exits, or substandard cleaning practices.\n",
      "- Note if the sender expresses concern over the health, safety, or overall standards of the environment as a result of the services.\n",
      "\n",
      "### **training_and_support_requests**\n",
      "- Determine if the sender is asking for training programs, support, or guidance related to facility management or maintenance practices.\n",
      "- Check if there is a specific mention of needing help with understanding or implementing best practices or new protocols.\n",
      "- Identify requests for detailed instructions, new training materials, or further education for themselves or their team.\n",
      "\n",
      "### **facility_management_issues**\n",
      "- Look for statements about problems with the overall coordination and management of the facility, such as space utilization and scheduling conflicts.\n",
      "- Identify recurring issues that impact the efficiency or security of the facility, requiring a comprehensive review or adjustment.\n",
      "- Confirm that the issue is broader and not limited to a single service, focusing on the overall management or operational system.\n",
      "\n",
      "### **customer_feedback_and_complaints**\n",
      "- Detect expressions of dissatisfaction with current services, indicating something has not met expectations.\n",
      "- Identify any specific incidents or ongoing issues that the customer wants to be addressed or improved.\n",
      "- Look for mentions of prior attempts to resolve the issue directly without success, leading to this formal complaint.\n",
      "\n",
      "### **general_inquiries**\n",
      "- Recognize when the sender is requesting basic information about the services provided without mentioning specific issues or urgent needs.\n",
      "- Identify inquiries that seek general knowledge such as service descriptions, pricing, scheduling, or potential new services.\n",
      "- Ensure that the request is broad and information-gathering in nature rather than resolving specific problems.\n",
      "\n",
      "### **emergency_repair_services**\n",
      "- Look for mentions of urgent or critical issues that need immediate intervention, like malfunctioning HVAC systems or severe plumbing leaks.\n",
      "- Identify if the sender describes an issue that directly impacts safety, comfort, or the functionality of the facility and requires swift action.\n",
      "- Confirm that the sender has already made attempts to troubleshoot the problem without success, highlighting the urgency for professional repair.\n",
      "\n",
      "### **cleaning_services_scheduling**\n",
      "- Determine if the sender is looking to schedule or adjust their ongoing cleaning services, including regular or seasonal deep cleaning.\n",
      "- Identify requests that involve setting dates, times, and frequencies for cleaning sessions.\n",
      "- Confirm that the request is more about organizing and planning rather than addressing complaints or specialized needs.\n",
      "\n",
      "### **routine_maintenance_requests**\n",
      "- Identify mentions of regular or periodic checks and upkeep of systems, such as HVAC, plumbing, or electrical systems.\n",
      "- Look for requests that ensure the proper functioning of these systems through scheduled maintenance rather than emergency repairs.\n",
      "- Confirm that the sender emphasizes preventive measures to avoid potential issues rather than solving current crises.\n",
      "\n",
      "### **sustainability_and_environmental_practices**\n",
      "- Recognize inquiries related to the environmental impact of the services, such as the use of eco-friendly products and sustainable practices.\n",
      "- Identify when the sender requests information on how the company reduces its carbon footprint, energy efficiency measures, or waste reduction strategies.\n",
      "- Confirm that the key focus is on environmental responsibility and future initiatives rather than immediate service-related issues.\n",
      "```\n",
      "---\n",
      "Giving the following message:\n",
      "---\n",
      "Subject: Scheduling Cleaning Services for My Studio\n",
      "\n",
      "Hi Support Team,\n",
      "\n",
      "I hope this message finds you well! My name is [Sender], and I’m a concept artist who has been enjoying the pristine environment your team helps maintain. Your services have been a game-changer for my creative space, and I truly appreciate the dedication and professionalism you bring to the table.\n",
      "\n",
      "I’m reaching out to discuss scheduling the next round of cleaning services for my studio. The space has been a whirlwind of creativity lately, and while it’s not urgent, I’d love to get a date on the calendar for a thorough cleaning. Your team’s attention to detail always leaves my workspace feeling fresh and inspiring, which is crucial for my work.\n",
      "\n",
      "I haven’t taken any steps yet to schedule this, as I wanted to touch base with you first to see what dates might be available. Ideally, I’m looking for a slot sometime in the next couple of weeks, but I’m flexible and happy to work around your schedule.\n",
      "\n",
      "Could you please assist me in setting up a convenient time for the cleaning? I’m looking forward to continuing our collaboration and keeping my studio in top shape.\n",
      "\n",
      "Thank you so much for your help!\n",
      "\n",
      "Best regards,\n",
      "[Sender]\n",
      "---\n",
      "extract and return a json with the follwoing keys and values:\n",
      "- \"urgency\" as one of `medium`, `high`, `low`\n",
      "- \"sentiment\" as one of `negative`, `neutral`, `positive`\n",
      "- \"categories\" list of the best matching support category tags from: `specialized_cleaning_services`, `quality_and_safety_concerns`, `training_and_support_requests`, `facility_management_issues`, `customer_feedback_and_complaints`, `general_inquiries`, `emergency_repair_services`, `cleaning_services_scheduling`, `routine_maintenance_requests`, `sustainability_and_environmental_practices`\n",
      "Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.\n",
      "\n",
      "<--- RESPONSE --->\n",
      "{\"categories\": [\"cleaning_services_scheduling\"], \"sentiment\": \"positive\", \"urgency\": \"low\"}\n"
     ]
    }
   ],
   "source": [
    "prompt_13 = \"\"\"Your task is to classify messages.\n",
    "Here are some examples:\n",
    "---\n",
    "{{?few_shot_examples}}\n",
    "---\n",
    "This is an explanation of `urgency` labels:\n",
    "---\n",
    "{{?guide_urgency}}\n",
    "---\n",
    "This is an explanation of `sentiment` labels:\n",
    "---\n",
    "{{?guide_sentiment}}\n",
    "---\n",
    "This is an explanation of `support` categories:\n",
    "---\n",
    "{{?guide_categories}}\n",
    "---\n",
    "Giving the following message:\n",
    "---\n",
    "{{?input}}\n",
    "---\n",
    "extract and return a json with the follwoing keys and values:\n",
    "- \"urgency\" as one of {{?urgency}}\n",
    "- \"sentiment\" as one of {{?sentiment}}\n",
    "- \"categories\" list of the best matching support category tags from: {{?categories}}\n",
    "Your complete message should be a valid json string that can be read directly and only contain the keys mentioned in the list above. Never enclose it in ```json...```, no newlines, no unnessacary whitespaces.\n",
    "\"\"\"\n",
    "\n",
    "f_13 = partial(send_request, prompt=prompt_13, **option_lists, few_shot_examples=examples, **guides)\n",
    "\n",
    "response = f_13(input=mail[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ae9570a5-7626-4b34-980c-7eedb9320a8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54668151afe84ddba4505fa98bd28693",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       is_valid_json correct_categories correct_sentiment correct_urgency\n",
      "=========================================================================================================\n",
      "                     basic--llama3-70b        100.0%              84.5%             40.0%           60.0%\n",
      "                  few_shot--llama3-70b        100.0%              86.5%             70.0%           80.0%\n",
      "             metaprompting--llama3-70b        100.0%              88.5%             55.0%           75.0%\n",
      "metaprompting_and_few_shot--llama3-70b        100.0%              90.0%             70.0%           90.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 206.719 seconds\n"
     ]
    }
   ],
   "source": [
    "overall_result[\"metaprompting_and_few_shot--llama3-70b\"] = evalulation_full_dataset(test_set_small, f_13)\n",
    "pretty_print_table(overall_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d74e06a8-2817-44ca-97a1-ad889d15e14c",
   "metadata": {},
   "source": [
    "## Use `mistralai--mixtral-8x7b-instruct-v01`\n",
    "\n",
    "As the cheapest open source, SAP hosted model available on generative AI hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4bdcf02-542b-4028-9514-eff47f3735dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92796177cc104e91b61e36364dd4bdb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                       is_valid_json correct_categories correct_sentiment correct_urgency\n",
      "=========================================================================================================\n",
      "                     basic--llama3-70b        100.0%              84.5%             40.0%           60.0%\n",
      "                  few_shot--llama3-70b        100.0%              86.5%             70.0%           80.0%\n",
      "             metaprompting--llama3-70b        100.0%              88.5%             55.0%           75.0%\n",
      "metaprompting_and_few_shot--llama3-70b        100.0%              90.0%             70.0%           90.0%\n",
      "                   basic--mixtral-8x7b         95.0%              81.5%             35.0%           50.0%\n"
     ]
    }
   ],
   "source": [
    "overall_result[\"basic--mixtral-8x7b\"] = evalulation_full_dataset(test_set_small, f_8, _model='mistralai--mixtral-8x7b-instruct-v01')\n",
    "pretty_print_table(overall_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "cedd6d55-9d5e-4358-b375-19228cc36b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abe2a33d40c94171a41e40545d87bb71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         is_valid_json correct_categories correct_sentiment correct_urgency\n",
      "===========================================================================================================\n",
      "                       basic--llama3-70b        100.0%              84.5%             40.0%           60.0%\n",
      "                    few_shot--llama3-70b        100.0%              86.5%             70.0%           80.0%\n",
      "               metaprompting--llama3-70b        100.0%              88.5%             55.0%           75.0%\n",
      "  metaprompting_and_few_shot--llama3-70b        100.0%              90.0%             70.0%           90.0%\n",
      "                     basic--mixtral-8x7b         95.0%              81.5%             35.0%           50.0%\n",
      "metaprompting_and_few_shot--mixtral-8x7b        100.0%              92.0%             65.0%           75.0%\n"
     ]
    }
   ],
   "source": [
    "overall_result[\"metaprompting_and_few_shot--mixtral-8x7b\"] = evalulation_full_dataset(test_set_small, f_13, _model='mistralai--mixtral-8x7b-instruct-v01')\n",
    "pretty_print_table(overall_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e0c63-e6bc-4877-a914-1d1bfe3d992a",
   "metadata": {},
   "source": [
    "## Use `gpt-4o`\n",
    "\n",
    "As the best propriatary OpenAI available on generative AI hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bf513691-5e3c-4f61-8720-8e9a8c735494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd59c7fdc744b43af7e5f660da56fee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         is_valid_json correct_categories correct_sentiment correct_urgency\n",
      "===========================================================================================================\n",
      "                       basic--llama3-70b        100.0%              84.5%             40.0%           60.0%\n",
      "                    few_shot--llama3-70b        100.0%              86.5%             70.0%           80.0%\n",
      "               metaprompting--llama3-70b        100.0%              88.5%             55.0%           75.0%\n",
      "  metaprompting_and_few_shot--llama3-70b        100.0%              90.0%             70.0%           90.0%\n",
      "                     basic--mixtral-8x7b         95.0%              81.5%             35.0%           50.0%\n",
      "metaprompting_and_few_shot--mixtral-8x7b        100.0%              92.0%             65.0%           75.0%\n",
      "                            basic--gpt4o        100.0%              87.5%             25.0%           40.0%\n"
     ]
    }
   ],
   "source": [
    "overall_result[\"basic--gpt4o\"] = evalulation_full_dataset(test_set_small, f_8, _model='gpt-4o')\n",
    "pretty_print_table(overall_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a4026821-a237-4325-96de-4586169080c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8838c7d6fa344c159bff44e3c13729c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         is_valid_json correct_categories correct_sentiment correct_urgency\n",
      "===========================================================================================================\n",
      "                       basic--llama3-70b        100.0%              84.5%             40.0%           60.0%\n",
      "                    few_shot--llama3-70b        100.0%              86.5%             70.0%           80.0%\n",
      "               metaprompting--llama3-70b        100.0%              88.5%             55.0%           75.0%\n",
      "  metaprompting_and_few_shot--llama3-70b        100.0%              90.0%             70.0%           90.0%\n",
      "                     basic--mixtral-8x7b         95.0%              81.5%             35.0%           50.0%\n",
      "metaprompting_and_few_shot--mixtral-8x7b        100.0%              92.0%             65.0%           75.0%\n",
      "                            basic--gpt4o        100.0%              87.5%             25.0%           40.0%\n",
      "       metaprompting_and_few_shot--gpt4o        100.0%              93.0%             60.0%          100.0%\n"
     ]
    }
   ],
   "source": [
    "overall_result[\"metaprompting_and_few_shot--gpt4o\"] = evalulation_full_dataset(test_set_small, f_13, _model='gpt-4o')\n",
    "pretty_print_table(overall_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1031c543-ac4b-4cf1-b43a-92b5f4f131d4",
   "metadata": {},
   "source": [
    "## Using `gemini-1.5-flash`\n",
    "\n",
    "As the cheapest and fastest Google model available on generative AI hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "66d0ce94-57e3-4f41-8953-8cb7ab361d52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "025d77a531c040c39ae97e6587691605",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         is_valid_json correct_categories correct_sentiment correct_urgency\n",
      "===========================================================================================================\n",
      "                       basic--llama3-70b        100.0%              84.5%             40.0%           60.0%\n",
      "                    few_shot--llama3-70b        100.0%              86.5%             70.0%           80.0%\n",
      "               metaprompting--llama3-70b        100.0%              88.5%             55.0%           75.0%\n",
      "  metaprompting_and_few_shot--llama3-70b        100.0%              90.0%             70.0%           90.0%\n",
      "                     basic--mixtral-8x7b         95.0%              81.5%             35.0%           50.0%\n",
      "metaprompting_and_few_shot--mixtral-8x7b        100.0%              92.0%             65.0%           75.0%\n",
      "                            basic--gpt4o        100.0%              87.5%             25.0%           40.0%\n",
      "       metaprompting_and_few_shot--gpt4o        100.0%              93.0%             60.0%          100.0%\n",
      "                 basic--gemini-1.5-flash        100.0%              85.5%             45.0%           50.0%\n"
     ]
    }
   ],
   "source": [
    "overall_result[\"basic--gemini-1.5-flash\"] = evalulation_full_dataset(test_set_small, f_8, _model='gemini-1.5-flash')\n",
    "pretty_print_table(overall_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "02a1a9ef-4dee-4170-8340-fe100141405b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "026332b4f27240aa88d79fbb305c9330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             is_valid_json correct_categories correct_sentiment correct_urgency\n",
      "===============================================================================================================\n",
      "                           basic--llama3-70b        100.0%              84.5%             40.0%           60.0%\n",
      "                        few_shot--llama3-70b        100.0%              86.5%             70.0%           80.0%\n",
      "                   metaprompting--llama3-70b        100.0%              88.5%             55.0%           75.0%\n",
      "      metaprompting_and_few_shot--llama3-70b        100.0%              90.0%             70.0%           90.0%\n",
      "                         basic--mixtral-8x7b         95.0%              81.5%             35.0%           50.0%\n",
      "    metaprompting_and_few_shot--mixtral-8x7b        100.0%              92.0%             65.0%           75.0%\n",
      "                                basic--gpt4o        100.0%              87.5%             25.0%           40.0%\n",
      "           metaprompting_and_few_shot--gpt4o        100.0%              93.0%             60.0%          100.0%\n",
      "                     basic--gemini-1.5-flash        100.0%              85.5%             45.0%           50.0%\n",
      "metaprompting_and_few_shot--gemini-1.5-flash        100.0%              88.0%             75.0%           85.0%\n"
     ]
    }
   ],
   "source": [
    "overall_result[\"metaprompting_and_few_shot--gemini-1.5-flash\"] = evalulation_full_dataset(test_set_small, f_13, _model='gemini-1.5-flash')\n",
    "pretty_print_table(overall_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b8fdf8-fe07-4c42-bd31-0163a24356e8",
   "metadata": {},
   "source": [
    "## Use `gemini-1.5-pro`\n",
    "\n",
    "Best Google model available on generative AI hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "01b67183-4bb4-4d2a-ad1d-09377389bf02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e43825aef2447ada7ff6c482b938954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             is_valid_json correct_categories correct_sentiment correct_urgency\n",
      "===============================================================================================================\n",
      "                           basic--llama3-70b        100.0%              84.5%             40.0%           60.0%\n",
      "                        few_shot--llama3-70b        100.0%              86.5%             70.0%           80.0%\n",
      "                   metaprompting--llama3-70b        100.0%              88.5%             55.0%           75.0%\n",
      "      metaprompting_and_few_shot--llama3-70b        100.0%              90.0%             70.0%           90.0%\n",
      "                         basic--mixtral-8x7b         95.0%              81.5%             35.0%           50.0%\n",
      "    metaprompting_and_few_shot--mixtral-8x7b        100.0%              92.0%             65.0%           75.0%\n",
      "                                basic--gpt4o        100.0%              87.5%             25.0%           40.0%\n",
      "           metaprompting_and_few_shot--gpt4o        100.0%              93.0%             60.0%          100.0%\n",
      "                     basic--gemini-1.5-flash        100.0%              85.5%             45.0%           50.0%\n",
      "metaprompting_and_few_shot--gemini-1.5-flash        100.0%              88.0%             75.0%           85.0%\n",
      "                       basic--gemini-1.5-pro        100.0%              87.5%             45.0%           70.0%\n"
     ]
    }
   ],
   "source": [
    "overall_result[\"basic--gemini-1.5-pro\"] = evalulation_full_dataset(test_set_small, f_8, _model='gemini-1.5-pro')\n",
    "pretty_print_table(overall_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "93d6b9fe-48af-44df-b2ee-b49a6d7666e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "386bf7e3de654eabb5c3ddc942eda94c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                             is_valid_json correct_categories correct_sentiment correct_urgency\n",
      "===============================================================================================================\n",
      "                           basic--llama3-70b        100.0%              84.5%             40.0%           60.0%\n",
      "                        few_shot--llama3-70b        100.0%              86.5%             70.0%           80.0%\n",
      "                   metaprompting--llama3-70b        100.0%              88.5%             55.0%           75.0%\n",
      "      metaprompting_and_few_shot--llama3-70b        100.0%              90.0%             70.0%           90.0%\n",
      "                         basic--mixtral-8x7b         95.0%              81.5%             35.0%           50.0%\n",
      "    metaprompting_and_few_shot--mixtral-8x7b        100.0%              92.0%             65.0%           75.0%\n",
      "                                basic--gpt4o        100.0%              87.5%             25.0%           40.0%\n",
      "           metaprompting_and_few_shot--gpt4o        100.0%              93.0%             60.0%          100.0%\n",
      "                     basic--gemini-1.5-flash        100.0%              85.5%             45.0%           50.0%\n",
      "metaprompting_and_few_shot--gemini-1.5-flash        100.0%              88.0%             75.0%           85.0%\n",
      "                       basic--gemini-1.5-pro        100.0%              87.5%             45.0%           70.0%\n",
      "  metaprompting_and_few_shot--gemini-1.5-pro        100.0%              94.5%             70.0%          100.0%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at C:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 437.031 seconds\n"
     ]
    }
   ],
   "source": [
    "overall_result[\"metaprompting_and_few_shot--gemini-1.5-pro\"] = evalulation_full_dataset(test_set_small, f_13, _model='gemini-1.5-pro')\n",
    "pretty_print_table(overall_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56512c46-5293-49f7-942f-7cc605f70859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39841eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
