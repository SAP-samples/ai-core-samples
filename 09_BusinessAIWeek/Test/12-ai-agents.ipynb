{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Agents with Generative AI Hub\n",
    "\n",
    "Everyone is talking about AI Agents and how they are going to make LLMs more powerful. AI Agents are basically systems that have a set of tools that they can use and the LLM is the agents brain to decide which tool to use when. Some systems are more agentic than others, depending on the amount of autonomy and decision-making power they possess. \n",
    "\n",
    "If you want to know more about AI Agents and how to build one from scratch, check out this [Devtoberfest session](https://community.sap.com/t5/devtoberfest/getting-started-with-agents-using-sap-generative-ai-hub/ev-p/13865119).\n",
    "\n",
    "ðŸ‘‰ Before you start you will need to add the constant `LLM_DEPLOYMENT_ID` to [variables.py](variables.py). You can use the `gpt-4o-mini` model again that we deployed earlier. You find the deployment ID in SAP AI Launchpad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import init_env\n",
    "import variables\n",
    "\n",
    "init_env.set_environment_variables()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the packages you want to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools import WikipediaQueryRun\n",
    "from langchain_community.utilities import WikipediaAPIWrapper\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor, create_react_agent\n",
    "\n",
    "from gen_ai_hub.proxy.langchain.openai import ChatOpenAI\n",
    "from gen_ai_hub.proxy.langchain.openai import OpenAIEmbeddings\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will give the agent different tools to use. The first tool will be [access to Wikipedia](https://python.langchain.com/docs/integrations/tools/wikipedia/). This way instead of answering from it's training data, the model will check on Wikipedia articles first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wikipedia = WikipediaQueryRun(api_wrapper=WikipediaAPIWrapper())\n",
    "\n",
    "# Let's check if it works\n",
    "print(wikipedia.run(\"Bangalore\"))\n",
    "\n",
    "# Assign wikipedia to the set of tools\n",
    "tools = [wikipedia]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For agents the initial prompt including all the instructions is very important. \n",
    "# LangChain already has a good set of prompts that we can reuse here.\n",
    "prompt = hub.pull(\"hwchase17/react\")\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat model instance which will act as the brain of the agent\n",
    "llm = ChatOpenAI(deployment_id=variables.LLM_DEPLOYMENT_ID)\n",
    "\n",
    "# Create an agent with the llm, tools and prompt\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# Let's ask try the agent and ask about Bangalore\n",
    "agent_executor.invoke({\"input\": \"Tell me about Bangalore!\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Give the agent access to our HANA vector store\n",
    "Now the agent can use Wikipedia but wouldn't it be nice if the agent could pick between resources and decide when to use what?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.hanavector import HanaDB\n",
    "from langchain.tools.retriever import create_retriever_tool\n",
    "\n",
    "# connect to HANA instance\n",
    "connection = init_env.connect_to_hana_db()\n",
    "connection.isconnected()\n",
    "\n",
    "# Reference which embedding model, DB connection and table to use\n",
    "embeddings = OpenAIEmbeddings(deployment_id=variables.EMBEDDING_DEPLOYMENT_ID)\n",
    "db = HanaDB(\n",
    "    embedding=embeddings, connection=connection, table_name=variables.EMBEDDING_TABLE\n",
    ")\n",
    "\n",
    "# Create a retriever instance of the vector store\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 2})\n",
    "\n",
    "# We need to add a description to the retriever so that the llm knows when to use this tool.\n",
    "retriever_tool = create_retriever_tool(\n",
    "    retriever,\n",
    "    \"SAP orchestration service docu\",\n",
    "    \"Search for information SAP's orchestration service. For any questions about generative AI hub and sap's orchestration service, you must use this tool!\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask the Agent\n",
    "\n",
    "You can ask the agent anything in general and it will try to find an entry from Wikipedia, unless you ask about SAP's orchestration service. Then it will get the information from SAP HANA vector store, where it holds the documentation, instead of Wikipedia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's add the retriever as a tool\n",
    "tools = [wikipedia, retriever_tool]\n",
    "\n",
    "# And create the agent again with the two tools, wikipedia and the HANA vector store (retriever)\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)\n",
    "\n",
    "# First ask: What is Data Masking?\n",
    "# Then ask: What is Data Masking in SAP's Generative AI Hub?\n",
    "# Pay attention to the response! Do you see what is happening now?\n",
    "agent_executor.invoke({\"input\": \"What is data masking?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
