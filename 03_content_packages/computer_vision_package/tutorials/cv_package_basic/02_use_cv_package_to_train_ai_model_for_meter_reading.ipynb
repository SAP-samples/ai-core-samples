{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#Â Use Computer Vision Package to Train AI Model for Meter Reading\n",
    "\n",
    "Use computer vision package integrated with SAP AI Core, to train an AI model to read electricity meters.\n",
    "\n",
    "\n",
    "> **Time**: 45 mins   \n",
    "> **Level**: `advanced`  \n",
    "> **Tags**: `sap ai core`, `artificial-intelligence`, `license`  \n",
    "\n",
    "\n",
    "---\n",
    "**You will learn:**\n",
    "- How to use the command line interface of SAP AI Core SDK to explore a content package\n",
    "- How to use the computer vision package to create boilerplate Docker images for object detection (number recognition)\n",
    "- How to use the computer vision package to create templates for your model training pipeline on SAP AI Core\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "**Prerequisites**\n",
    " - You have completed the tutorial to [set up SAP Computer Vision package for SAP AI Core](cv-package-aicore-setup)\n",
    " - You have [set up your Git repository with SAP AI Core](https://help.sap.com/viewer/808d9d442fb0484e9b818924feeb9add/LATEST/en-US/3269092e37d141a293f0dbd7eaafc829.html)\n",
    " - You have [created a Docker registry secret in SAP AI Core](https://help.sap.com/viewer/2d6c5984063c40a59eda62f4a9135bee/LATEST/en-US/b29c7437a54f46f39c911052b05aabb1.html)\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "### Pre-read\n",
    "\n",
    "The `ai-core-sdk` Python package comes with a command line interface to explore content packages (like the computer vision package). The computer vision package helps you generate pipelines for common computer vision tasks, such as:\n",
    "\n",
    "- object detection: detect multiple objects in an image. Example: bottles, chairs, pedestrians, numbers.\n",
    "- image classification: differentiate an image based on category. Example: nature vs city, cat vs dog.\n",
    "- image retrieval: search for similar images in a catalog of trained images. Example: similar apparel, similar plant.\n",
    "\n",
    "In this tutorial, your task is to use object detection for number recognition. You'll train your AI code on a dataset containing images of electricity meters. The numbers in these images become objects which the AI code will learn to detect in new images of meter readings.\n",
    "\n",
    "> Your business challenge might be different, and you should consider how to use the computer vision package for your data and expected outcomes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 1: Inspect content package\n",
    "\n",
    "Start your virtual environment created in the prerequisite tutorial. Paste and run the snippet.\n",
    "\n",
    "```BASH\n",
    "source sap_cv_env/bin/activate\n",
    "```\n",
    "\n",
    "List the available content packages using the following snippet.\n",
    "\n",
    "> The `list` subcommand lists all content packages available in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31msap_nlp\u001b[0m\n",
      "====================\n",
      "\t- Something cool with transformers\n",
      "\n",
      "\n",
      "\u001b[31msap-cv\u001b[0m\n",
      "====================\n",
      "\t- Content Package for computer vision\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!aicore-content list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "You should see `sap-cv` content packages in the output.\n",
    "\n",
    "![image](img/aicore-cli-list-packages.png)\n",
    "\n",
    "\n",
    "List contents within `sap-cv` using the snippet below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32mimage-classification-train [ExecutionMetaflow]\u001b[0m\n",
      "====================\n",
      "\t-  Pipeline to train a model for image classification.\n",
      "\n",
      "\n",
      "\u001b[32mobject-detection-train [ExecutionMetaflow]\u001b[0m\n",
      "====================\n",
      "\t-  Pipeline to train a model for object detection.\n",
      "\n",
      "\n",
      "\u001b[32mtriplet-distance-learning-train [ExecutionMetaflow]\u001b[0m\n",
      "====================\n",
      "\t-  Pipeline to train a model for feature extraction using triplet\n",
      "\t  loss.\n",
      "\n",
      "\n",
      "\u001b[32mbatch-processing [ExecutionMetaflow]\u001b[0m\n",
      "====================\n",
      "\t-  Pipeline to batch processing data using a trained model.\n",
      "\n",
      "\n",
      "\u001b[95mmodel-serving [DeploymentYaml]\u001b[0m\n",
      "====================\n",
      "\t- Serve Models trained with the `sap-computer-vision` package on AIF.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!aicore-content list sap-cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "You should see all available pipelines relevant for computer vision tasks, as well as their details.\n",
    "\n",
    "![image](img/aicore-cli-list-workflows.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 2: Inspect content package using Python\n",
    "\n",
    "List available content packages using the following snippet in a new cell in a Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ContentPackage(name='sap_nlp', ''workflows=['text-classifer-workflow'])\n",
      "ContentPackage(name='sap-cv', ''workflows=['image-classification-train', 'object-detection-train', 'triplet-distance-learning-train', 'batch-processing', 'model-serving'])\n"
     ]
    }
   ],
   "source": [
    "from ai_core_sdk.content import get_content_packages\n",
    "\n",
    "pkgs = get_content_packages()\n",
    "\n",
    "for pkg in pkgs.values():\n",
    "    print(pkg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "List available pipelines in the `sap-cv` content package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Workflow(name='image-classification-train', type=ExecutionMetaflow)\n",
      "Workflow(name='object-detection-train', type=ExecutionMetaflow)\n",
      "Workflow(name='triplet-distance-learning-train', type=ExecutionMetaflow)\n",
      "Workflow(name='batch-processing', type=ExecutionMetaflow)\n",
      "Workflow(name='model-serving', type=DeploymentYaml)\n"
     ]
    }
   ],
   "source": [
    "sap_cv_pkg = pkgs['sap-cv']\n",
    "\n",
    "for workflow in sap_cv_pkg.workflows.values():\n",
    "    print(workflow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "You should see available `Workflow` (pipeline) Python objects.\n",
    "\n",
    "\n",
    "You don't need to know the internal definition of these workflows but it's helpful to understand their purpose.\n",
    "  - `type` indicates the following:\n",
    "  -   - `ExecutionMetaflow`: generates workflows for training using Metaflow library\n",
    "  -   - `DeploymentYaml`: generates workflows for online inferencing server\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Select `object-detection-train` pipeline using the snippet.\n",
    "workflow = sap_cv_pkg.workflows['object-detection-train']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 3: Create labels for template\n",
    "\n",
    "To generate a Docker image and templates, you need to pass values of labels to `sap-cv` generator. These values are used in creation of the pipelines.\n",
    "\n",
    "Paste and edit the snippet in your Jupyter notebook using the following details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "workflow_config = {\n",
    "   \"name\": \"sap-cv-package-tutorial-obj-detection-train\",\n",
    "   \"image\": \"<YOUR_DOCKER_USERNAME>/sap-cv-package-object-detection-train:0.0.1\",\n",
    "   \"labels\": {\n",
    "       \"scenarios.ai.sap.com/id\": \"sap-cv-package-tutorial\",\n",
    "       \"ai.sap.com/version\": \"0.0.1\"\n",
    "   },\n",
    "   \"annotations\": {\n",
    "       \"scenarios.ai.sap.com/name\": \"SAP CV Package Tutorial\",\n",
    "   },\n",
    "   \"imagePullSecret\": \"<YOUR_DOCKER_SECRET>\",\n",
    "   \"objectStoreSecret\": \"default-object-store-secret\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "| Labels | Description |\n",
    "| --- | --- |\n",
    "| `name` | Custom ID of workflow. Can be a string with alphanumeric characters and underscores.\n",
    "| `image` |The name to use in building Docker image. You must pass your username of [Docker registry](https://hub.docker.com) `<YOUR_DOCKER_USERNAME>/sap-cv-package-object-detection-train:0.0.1`.\n",
    "| `labels.scenarios.ai.sap.com/id` | Custom ID of the machine learning scenario. Can be any valid string. Should be unique on your SAP AI Core instance.\n",
    "| `labels.ai.sap.com/version` | A descriptive scenario version in any format. Example: `0.0.1`.\n",
    "| `annotations.scenarios.ai.sap.com/name` | Descriptive name of your scenario. Example: `Detection of Digits`, `Detection of Cars in Traffic`\n",
    "| `imagePullSecret` | Secret containing credentials to access your Docker repository. Should match with the registered secret name on your SAP AI Core\n",
    "| `objectStoreSecret` | Secret containing credentials to access the object store (either from BTP/S3). Should match with the registered object store secret name on your SAP AI Core. **Please add the suffix `-object-store-secret` to the name of your object store secret when adding to label.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 4: Generate Docker image for training\n",
    "\n",
    "The workflows (the variable `workflow` pointing to `object-detection-train` content) in computer vision package have a method `create-image` to build a Docker image using the template contained in computer vision package. The Docker image provides the runtime environment for the pipeline that you will create later in this tutorial.\n",
    "\n",
    "Paste and run the snippet. The variable `workflow_config` contains the key `image` which sets the name for the Docker image to be built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "workflow.create_image(workflow_config, silent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Push your built Docker image to your Docker registry with below snippet. The `!` (exclamation) prefix executes command in your terminal from your Jupyter notebook.\n",
    "\n",
    "!docker push <YOUR_DOCKER_USERNAME>/sap-cv-package-object-detection-train:0.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "> **INFORMATION** You may also generate the Docker image from content package using Command Line interface.\n",
    ">\n",
    "> ```BASH\n",
    "> aicore-content create-image -p <CONTENT_PACKAGE> -w <WORKFLOW> <WORKFLOW_CONFIG.YAML>\n",
    "> ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 5: Generate training template\n",
    "\n",
    "The workflows have another method `create-template` to build a training pipeline with placeholders for datasets and hyper-parameters. This training pipeline internally references the Docker image you created previously. You are not required to modify/ update the AI code contained, but you can tweak hyper-parameters to achieve different model qualities, demonstrated later in the tutorial.\n",
    "\n",
    "Pase and edit the following snippet. Replace `<YOUR_GIT_Repo_PATH>` with the absolute path to the directory that contains the repository you've on-boarded to SAP AI Core. This repository syncs using Git Ops.\n",
    "\n",
    " > In this tutorial, the workflow object points to the object-detection-train content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "output_file = '<YOUR_GIT_Repo_PATH>/sap-cv-package-tutorial-obj-detection-train.json'\n",
    "workflow.create_template(workflow_config, output_file, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "> **INFORMATION** You may also generate the training template from the content package using the command line interface.\n",
    ">```bash\n",
    "> aicore-content create-template -p <CONTENT_PACKAGE> -w <WORKFLOW> <WORKFLOW_CONFIG.YAML> -o <OUTPUT_TEMPLATE_FILE.JSON\n",
    ">```\n",
    "\n",
    "Now, commit and push this generated template to the Git repository that you have specified in SAP AI Core.\n",
    "\n",
    "You can use the following snippet for commands to push the template to GitHub. Paste and edit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "print(f'''Run in Terminal:\n",
    "cd <YOUR_GIT_Repo_PATH>\n",
    "git add <path_within_repo>/{pathlib.Path(output_file).name}\n",
    "git commit -m \\'updated template {workflow_config[\"name\"]}\\'\n",
    "git push\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "After the template is pushed to the Git repo, you'll need to wait a few minutes for the template in the repo to sync with SAP AI Core. On-boarded Git repositories are regularly synced with SAP AI Core (~3 mins)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 6: Download training data\n",
    "\n",
    "You'll need to use a dataset which contains images of electricity meters for this tutorial. The model will attempt to read the meters using object detection. Find more information about the dataset on [Gas-Meter Reading Datasets, Applied Recognition Technology Laboratory](http://artelab.dista.uninsubria.it/downloads/datasets/automatic_meter_reading/gas_meter_reading/gas_meter_reading.html)\n",
    "\n",
    "Run the following snippet to download the training dataset to your local system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "! [ -d \"MeterDataset\" ] && echo \"skipping\" || (wget -nc --no-check-certificate \"http://artelab.dista.uninsubria.it/downloads/datasets/automatic_meter_reading/gas_meter_reading/gas_meter_reading.zip\" && unzip -qq gas_meter_reading -d .)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 7: Upload data to object store\n",
    "\n",
    "\n",
    "SAP AI Core fetches the training dataset from the object store (cloud), therefore you need to upload the data to the object store.\n",
    "\n",
    "Upload the dataset to your AWS object store using the following snippet.\n",
    "\n",
    "> The object store should be the same as the one whose secret you've used in prerequisite tutorials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "s3_target = \"s3://<YOUR_S3_BUCKET>/meter-reading/Rough-Digit-Classification\"\n",
    "# Example: s3://hcp-787c1894-e893-4c8edf-b406-440347f6b411/kannan/meter-reading/Rough-Digit-Classification\n",
    "\n",
    "! mv MeterDataset/Rough-Digit-Classification/JPEGImages MeterDataset/Rough-Digit-Classification/Images\n",
    "\n",
    "! aws s3 cp --recursive --quiet MeterDataset/Rough-Digit-Classification {s3_target}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 8: Register dataset reference as artifact for SAP AI core\n",
    "\n",
    "Paste and edit the snippet. Replace `< >` with your values.\n",
    "\n",
    "\n",
    "| Variable/ Parameter | Description |\n",
    "| --- | --- |\n",
    "| `ai_core_path` (`url`) | Path relative to `pathPrefix` of your object store secret created in SAP AI Core. Note the format: `ai://<object-store-secret-name>/<path-to-artifact>`.\n",
    "| `artifact_name` | Descriptive name for the artifact\n",
    "| `scenario_id` | Descriptive tag to identify that the purpose and value are the same as the one used in template creation\n",
    "| `kind` | Descriptive tag `DATASET` to identify purpose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from ai_core_sdk.models import Artifact\n",
    "\n",
    "ai_core_path =  'ai://default/meter-reading/Rough-Digit-Classification'\n",
    "# example of artifact-path: 'ai://default/meter-reading/Rough-Digit-Classification'\n",
    "\n",
    "artifact_name = 'tutorial-dataset-meter-reading-digits'\n",
    "\n",
    "try:\n",
    "    artifact = [r for r in ai_api_client.artifact.query().resources if r.name == artifact_name][0]\n",
    "    print('Found artifact')\n",
    "except IndexError:\n",
    "    print('Artifact Created')\n",
    "    artifact = ai_api_client.artifact.create(\n",
    "        name=artifact_name,\n",
    "        scenario_id=workflow_config[\"labels\"][\"scenarios.ai.sap.com/id\"],\n",
    "        kind=Artifact.Kind.DATASET,\n",
    "        url=ai_core_path,\n",
    "        description='Meter Reading Digits Dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The previous snippet checks if an artifact of the same name has already registered in SAP AI Core.\n",
    "If it has already been registered, it will return the ID of the existing artifact. If the artifact does not exist, a new artifact is created.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 9: Set hyperparameters for the template\n",
    "\n",
    "Run the following snippet to create a `params` object with `Parameter Bindings`. You'll use the variable `params` to create the configuration for execution (training)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from ai_core_sdk.models import ParameterBinding\n",
    "\n",
    "params = [\n",
    "    ParameterBinding(\"baselr\", \"0.001\"),\n",
    "    ParameterBinding(\"earlystopping\", \"False\"),\n",
    "    ParameterBinding(\"ntrainsteps\", \"100\"), # increase to 5000 for more accurate results but takes longer time to train ~ 1 Hr.\n",
    "    ParameterBinding(\"train\", \"0.8\"),\n",
    "    ParameterBinding(\"validation\", \"0.1\"),\n",
    "    ParameterBinding(\"test\", \"0.1\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "These parameters impact the training of the model for object detection.\n",
    "> Once you have a baseline model, you can tweak hyper-parameters here to test different model settings and improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 10: Create configuration for training\n",
    "\n",
    "Run the following snippet to check if a configuration of the same name already exists in SAP AI Core. If it exists, it will use the existing configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from ai_core_sdk.models import InputArtifactBinding\n",
    "\n",
    "config_name = 'tutorial-sapcv-meter-reading'\n",
    "# can customize, example config name 'sapcv-tutorial-meter-reading'\n",
    "\n",
    "try:\n",
    "    configuration = [r for r in ai_api_client.configuration.query().resources if r.name == config_name][0]\n",
    "    print('Found configuration')\n",
    "except IndexError:\n",
    "    print('Configuration Created')\n",
    "    configuration = ai_api_client.configuration.create(\n",
    "        name=config_name,\n",
    "        scenario_id=workflow_config[\"labels\"][\"scenarios.ai.sap.com/id\"],\n",
    "        executable_id=workflow_config[\"name\"],\n",
    "        input_artifact_bindings=[InputArtifactBinding('datain', artifact.id)], # dataset to use `datain` is placeholder name in the template\n",
    "        parameter_bindings=params # hyper-parameter values to use.\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#### Details of configuration variables\n",
    "\n",
    "| Parameter | Description |\n",
    "| --- | --- |\n",
    "| `name` | Name of configuration |\n",
    "| `scenario_id` | Used to connect the configuration to the scenario ID mentioned previously in our workflow configuration |\n",
    "| `executable_id` | Name of the workflow mentioned in workflow configuration |\n",
    "| `input_artifact_binding` | Binds the dataset artifact you created (in the previous tutorial) to the placeholder for dataset in the template |\n",
    "| `parameter_bindings` | Parameters for the training you set in previous step |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 11: Start training\n",
    "\n",
    "Start training by initiating the execution, using the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "execution = ai_api_client.execution.create(configuration.id) # configuration from previous step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Wait for the training to finish. You may use the below snippet to check if training has finished.\n",
    "This snippet checks if the execution variable is present in notebook environment. If it is present it checks for the status of this execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# Execute in interval of 5 mins\n",
    "#\n",
    "from ai_core_sdk.models import Status\n",
    "\n",
    "if 'execution' not in locals():\n",
    "    execution_id = input('Restarting this Notebook again? Provide ExecutionID: ')\n",
    "else:\n",
    "    execution_id = execution.id\n",
    "execution = ai_api_client.execution.get(execution_id)\n",
    "if execution.status == Status.COMPLETED:\n",
    "    trained_model = execution.output_artifacts[0]\n",
    "    print('Training finished!')\n",
    "else:\n",
    "    trained_model = None\n",
    "    print('Training not finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "> **CAUTION:** Do not close you Jupyter notebook. To make predictions, you need to use the same notebook in the follow-up tutorial. You can use SAP AI Launchpad to monitor your execution in the next step. Continue to use your notebook when the execution reaches `COMPLETED` state."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 12: Monitor execution\n",
    "\n",
    "Use  **SAP AI Launchpad**, and open the **Workspace** app.  Select your SAP AI Core Connection and **Resource Group**.\n",
    "\n",
    "Navigate to the **Executions** tab. You should see that a new execution is listed with the configuration you created.\n",
    "\n",
    "Confirm that the **Current Status** is either `PENDING` or `RUNNING`.\n",
    "\n",
    "![image](img/execution-1-started.png)\n",
    "\n",
    "Choose your execution and navigate to its details. You should see detailed information about your execution, showing the entire pipeline with the name of the executable, artifact used, and configuration.\n",
    "\n",
    "![image](img/execution-2-started-process-flow.png)\n",
    "\n",
    "The `Logs` tab shows the logs from the executing pipeline.\n",
    "\n",
    "![image](img/execution-3-started-pipelinelogs.png)\n",
    "\n",
    "After the model training has started, you can see the loss metrics of the computer vision model in the logs. The estimated time to completion for training appears under `eta`.\n",
    "\n",
    "![image](img/execution-4-running-pipelinelogs.png)\n",
    "\n",
    "After model training is completed, a trained model appears under **Output Artifacts**. As part of the pipeline, this model is stored in the object store. The template generated by computer vision package handles all this behind the scenes for you.\n",
    "\n",
    "![image](img/execution-5-completed.png)\n",
    "\n",
    "On your Jupyter notebook, re-run the previous cell to determine the execution status. This fetches the trained model from the output artifacts of the execution and output `Training Completed`.\n",
    "\n",
    "![image](img/execution-6-training-finished.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 13: Summary\n",
    "\n",
    "As a recap, in this tutorial, you have looked at creating Docker images and templates for a computer vision scenario.\n",
    "\n",
    "### Cheat sheet  \n",
    "\n",
    "#### Workflow Configuration(Label)\n",
    "\n",
    "```JSON\n",
    "{\n",
    "   \"name\": \"sap-cv-package-tutorial-obj-detection-train\",\n",
    "   \"image\": \"<YOUR_DOCKER_USERNAME>/sap-cv-package-object-detection-train:0.0.1\",\n",
    "   \"labels\": {\n",
    "       \"scenarios.ai.sap.com/id\": \"sap-cv-package-tutorial\",\n",
    "       \"ai.sap.com/version\": \"0.0.1\"\n",
    "   },\n",
    "   \"annotations\": {\n",
    "       \"scenarios.ai.sap.com/name\": \"SAP CV Package Tutorial\",\n",
    "   },\n",
    "   \"imagePullSecret\": \"<YOUR_DOCKER_SECRET>\",\n",
    "   \"objectStoreSecret\": \"default-object-store-secret\"\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "#### Build Docker image:  \n",
    "\n",
    "- Python: `workflow.create_image(workflow_config)`\n",
    "\n",
    "- CLI: `ai-core-content create-image <workflow_config_file>`  \n",
    "\n",
    "#### Create Templates:  \n",
    "\n",
    "- Python: `workflow.create_template(workflow_config, out_file)`  \n",
    "\n",
    "- CLI: `ai-core-content create-template workflow_config out_file`  \n",
    "\n",
    "Everything else is regular SAP AI Core usage, that is, the other steps are similar to any other SAP AI Core tutorial.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
