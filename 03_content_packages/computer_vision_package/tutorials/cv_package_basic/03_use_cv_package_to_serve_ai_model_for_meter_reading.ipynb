{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "#Â Use Computer Vision Package to Serve AI Model for Meter Reading\n",
    "\n",
    "Deploy an object detection model in SAP AI Core for number recognition of meter readings.\n",
    "\n",
    "> **Time**: 45 mins   \n",
    "> **Level**: `advanced`  \n",
    "> **Tags**: `sap ai core`, `artificial-intelligence`, `license`  \n",
    "\n",
    "---\n",
    "**You will learn**\n",
    "- How to generate serving templates for a computer vision package\n",
    "- How to generate and deploy an online inferencing server using a computer vision package\n",
    "- How to consume endpoints for online inferencing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "---\n",
    "**Prerequisites**\n",
    "- You have trained an AI model for object detection using the [set up tutorial](cv-package-aicore-train-object-detection).\n",
    "- You are using the Jupyter notebook from the [set up tutorial](cv-package-aicore-train-object-detection).\n",
    "\n",
    "> **IMPORTANT** You must have successfully created an execution using the [prerequisite tutorial](cv-package-aicore-train-object-detection). You\"ll need the value of the variable `trained_model` to complete this tutorial.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 1: Get reference content for serving template and Docker image\n",
    "\n",
    "The computer vision package (`sap-cv`) provides reference `model-serving` workflow, for creating a serving template and creating a Docker image for the deployment server. The reference content is used like a boilerplate, and helps accelerate creation of your serving template and server.\n",
    "\n",
    "To store the reference content, paste and run the snippet. The name of the reference content is `model-serving`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "workflow = sap_cv_pkg.workflows['model-serving']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 2: Create labels for serving template\n",
    "\n",
    "Paste and edit the snippet to store the serving template labels in JSON format. You must use your own Docker username for `image`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "workflow_config = {\n",
    "   \"name\": \"sap-cv-package-tutorial-obj-detection-serving\",\n",
    "   \"image\": \"<YOUR_DOCKER_USERNAME>/sap-cv-package-model-serving:0.0.1\",\n",
    "   \"annotations\": {\n",
    "       \"scenarios.ai.sap.com/name\": \"SAP CV Package Tutorial\",\n",
    "       \"executables.ai.sap.com/name\": \"sapcv-tutorial-obj-detection-serve\",\n",
    "   },\n",
    "   \"labels\": {\n",
    "       \"scenarios.ai.sap.com/id\": \"sap-cv-package-tutorial\",\n",
    "       \"ai.sap.com/version\": \"0.0.1\"\n",
    "   },\n",
    "   \"imagePullSecret\": \"<YOUR_DOCKER_SECRET>\",\n",
    "   \"objectStoreSecret\": \"default-object-store-secret\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 3: Generate Docker image for serving\n",
    "\n",
    "The reference workflow contains a `create_image` function. This function builds a Docker image using the serving template code contained in the computer vision package.\n",
    "\n",
    "Paste and run the snippet.\n",
    "\n",
    "> The variable `workflow_config` contains the key `image` which indicates the name of the new Docker image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "workflow.create_image(workflow_config, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "![image](img/serving-docker-create-image.png)\n",
    "\n",
    "Paste the snippet. You should see your Docker image in your system's local memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "!docker images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "![image](img/docker-image-ls.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 4: Upload Docker image to cloud\n",
    "\n",
    "Upload your Docker image to the cloud Docker repository. SAP AI Core will download the image from the cloud repository and run the deployment.\n",
    "\n",
    "Paste and edit the snippet. The exclamation prefix `!` executes the command in your system's terminal from your Jupyter notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "!docker push <YOUR_DOCKER_USERNAME>/sap_cv_obj_detection:0.0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "![image](img/serving-docker-pushing.png)\n",
    "\n",
    "It may take a few minutes for the Docker registry to upload your code. After completion, you'll see a `Pushed` message in the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 5: Generate model serving template\n",
    "\n",
    "The reference content contains a `create_template` function. This function builds a template using the serving template code contained in the computer vision package.\n",
    "\n",
    "Paste and edit the snippet. The `output_file` is the target location for your new serving template. The target location must be a valid system location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "output_file = '/path/to/output/sap-cv-demo-aicore-sdk-cli-serving.yaml'\n",
    "workflow.create_template(None, output_file, silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The snippet creates a generic workflow template.\n",
    "\n",
    "> You passed `None` as a value for `workflow_config` as it is not required to generate a model serving template.\n",
    "\n",
    "Open the generated YAML file in the text editor. Paste the required values (use the screenshots to confirm the lines to edit).\n",
    "\n",
    "```YAML\n",
    "...\n",
    "metadata:\n",
    "  name: sap-cv-package-tutorial-obj-detection-serving\n",
    "  annotations:\n",
    "    scenarios.ai.sap.com/name: \"SAP CV Package Tutorial\"\n",
    "    executables.ai.sap.com/description: \"Serve Model of sap_computer_vision package\"\n",
    "    executables.ai.sap.com/name: \"sapcv-tutorial-obj-detection-serve\"\n",
    "  labels:\n",
    "    scenarios.ai.sap.com/id: \"sap-cv-package-tutorial\"\n",
    "    ai.sap.com/version: \"0.0.1\"\n",
    "...\n",
    "spec:\n",
    "    ...\n",
    "    imagePullSecrets:\n",
    "      - name: <YOUR_DOCKER_SECRET>\n",
    "    template:\n",
    "        ...\n",
    "        spec:\n",
    "            ...\n",
    "            image: <YOUR_DOCKER_USERNAME>/sap-cv-package-model-serving:0.0.1\n",
    "\n",
    "```\n",
    "\n",
    "![image](img/demo-serving-template-edit-1.png)\n",
    "\n",
    "![image](img/demo-serving-template-edit-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 6: Sync new serving template with SAP AI Core\n",
    "\n",
    "Save the new serving template to the GitHub repository, in the folder tracked by **Application** of SAP AI Core.\n",
    "\n",
    "You may run this snippet in a Jupyter notebook cell if you need help with committing and pushing to Git. Paste and edit the snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "print(f'''Run in Terminal:\n",
    "cd <YOUR_REPO>\n",
    "git add <YOUR_PATH_WITHIN_REPO>/{pathlib.Path(output_file).name}\n",
    "git commit -m \\'updated template {workflow_config[\"name\"]}\\'\n",
    "git push\n",
    "''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "- Replace `<YOUR_REPO>` with your GitHub repository .\n",
    "- Replace `<YOUR_PATH_WITHIN_REPO>` with directory within your repo which contains the template file.\n",
    "\n",
    "> **AI Core Git Ops Sync:**\n",
    "Once the template is pushed into the Git repo, you need to wait for AI Core to sync with this repository. AI Core syncs with the on-boarded Git repositories at periodic intervals. Once the template is synced with AI Core you can execute the serving template to start model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 7: Get model ID for trained model\n",
    "\n",
    "Paste and run the snippet to check the trained model.\n",
    "\n",
    ">**CAUTION** The variable `trained_model` references the value from the prerequisite tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "if trained_model is None:\n",
    "    print('Training not finished -> model not ready for deployment')\n",
    "else:\n",
    "    serving_config_name = f'demo-object-detection-meter-reading-serving-{trained_model.id[:6]}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 8: Create configuration for the deployment\n",
    "\n",
    "Paste and run the snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "params = [\n",
    "    ParameterBinding(\"iou_threshold\", \"0.5\")\n",
    "]\n",
    "\n",
    "try:\n",
    "    configuration = [r for r in ai_api_client.configuration.query().resources if r.name == serving_config_name][0]\n",
    "    print('Found configuration')\n",
    "except IndexError:\n",
    "    with open(output_file) as stream:\n",
    "        template_metadata = yaml.safe_load(stream)['metadata']\n",
    "    configuration_deployment = ai_api_client.configuration.create(\n",
    "        name=serving_config_name,\n",
    "        scenario_id=template_metadata[\"labels\"][\"scenarios.ai.sap.com/id\"],\n",
    "        executable_id=template_metadata[\"name\"],\n",
    "        input_artifact_bindings=[InputArtifactBinding('trainedmodels', trained_model.id)],\n",
    "        parameter_bindings=params\n",
    "    )\n",
    "    print('Configuration Created')nb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "The snippet checks your SAP AI Core instance for a configuration with the same name as variable `serving_config_name` (initialized in the previous step). A new configuration is only created if the name doesn't already exist.\n",
    "\n",
    "\n",
    "The remaining configuration data is retrieved from your serving template YAML file. The following table summarizes the values.\n",
    "\n",
    "| Key | Purpose |\n",
    "| --- | --- |\n",
    "| `name` | to identify configuration |\n",
    "| `scenario_id` & `executable_id`| to associate the YAML file to your configuration |\n",
    "| `input_artifact_bindings` | to select the trained models as an input to the template code, the Docker image |\n",
    "| `parameter` | (value not from the YAML file) parameters to be used during inference |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 9: Start deployment\n",
    "\n",
    "Paste and run the snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "deployment = ai_api_client.deployment.create(configuration_deployment.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "To create and start a deployment, you need the `ID` of the deployment configuration created in the previous step. You may need to wait a few moments, while SAP AI Core fetches the resources mentioned in the deployment configuration, and starts the server for online inferencing.\n",
    "\n",
    "To check the deployment status, paste and run the snippet. You may need to execute the snippet again (wait a few minutes) to retrieve the updated status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from ai_core_sdk.resource_clients import RestClient\n",
    "\n",
    "if 'deployment' not in locals():\n",
    "    deployment_id = input('Restarting this Notebook again? Provide DeploymentID: ')\n",
    "else:\n",
    "    deployment_id = deployment.id\n",
    "\n",
    "deployment = ai_api_client.deployment.get(deployment_id)\n",
    "\n",
    "if deployment.status == Status.RUNNING:    \n",
    "    deployment_client = RestClient(deployment.deployment_url, ai_api_client.rest_client.get_token)\n",
    "    deployment_client.headers = ai_api_client.rest_client.headers\n",
    "    print('Deployment Ready!')\n",
    "else:\n",
    "    trained_model = None\n",
    "    print('Deployment not Ready!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "\n",
    "The snippet checks the status of the deployment. It also fetches the `Deployment URL` and the Rest Client (`deployment_client`) using it. You can use `deployment_client` to send inference requests to the deployed model.\n",
    "\n",
    "If required, wait a few minutes and execute the snippet again. The expected output is `Deployment Ready`.\n",
    "\n",
    "\n",
    "> You can also use the **ML Operations** app in **SAP AI Launchpad** to check the status of your deployment. When ready, the deployment's **Current Status** changes to `RUNNING`.\n",
    "\n",
    "\n",
    "You'll find the deployment URL in the deployment details. The other components used in this deployment (workflow, input artifacts, configuration) can be found in the **Process Flow** pane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 10: Check status endpoint of inference server\n",
    "\n",
    "Check the status of your deployment using the `/v1/status` endpoint. This endpoint is provided as a standard part of the Docker image generated for model serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "status_path = '/v1/status'\n",
    "status = deployment_client.get(status_path)\n",
    "print(json.dumps(status, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 11: Detect meter reading from test image\n",
    "\n",
    "Paste the snippet to display a test image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import numpy as np\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def decode_image_path(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    img_np = cv2.imencode('.jpg', cv2.imread(img_path))\n",
    "    return img, base64.b64encode(img_np[1]).decode()\n",
    "\n",
    "img_path = 'MeterDataset/Rough-Digit-Classification/Images/00450000100544_0.jpg'\n",
    "\n",
    "img, img_str = decode_image_path(img_path)\n",
    "plt.imshow(img[:,:,::-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Determine the meter reading from the test image using the `/models/model:predict` endpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "predict_path = f'/v1/models/model:predict'\n",
    "predict = deployment_client.post(predict_path, body={'images': img_str})\n",
    "\n",
    "print(json.dumps(predict, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 12: Visualize detected meter reading\n",
    "\n",
    "Display the predicted bounding box for your image using the following snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import torch\n",
    "\n",
    "from detectron2.structures.instances import Instances\n",
    "from detectron2.structures.boxes import Boxes\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "\n",
    "class Metadata:\n",
    "    thing_classes = [str(i) for i in range(10)]\n",
    "\n",
    "    def get(self, k, default):\n",
    "        return getattr(self, k, default)\n",
    "\n",
    "\n",
    "inst = Instances(img.shape[:2],\n",
    "                 pred_boxes=Boxes(torch.tensor(predict[0]['pred_boxes'])),\n",
    "                 scores=torch.tensor(predict[0]['scores']),\n",
    "                 pred_classes=torch.tensor(predict[0]['pred_classes'])\n",
    "                 )\n",
    "\n",
    "\n",
    "vis = Visualizer(img_rgb=img[:,:,::-1], metadata=Metadata())\n",
    "vis.draw_instance_predictions(inst).fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "![image](img/prediction-visualized.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Step 13: Stop deployment server\n",
    "\n",
    "After you have tried determining meter readings for multiple examples, it's a good idea to stop the deployment (this saves resources)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from ai_api_client_sdk.models.target_status import TargetStatus\n",
    "response = ai_api_client.deployment.modify(deployment_id, target_status=TargetStatus.STOPPED)\n",
    "print(response.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "You can also stop a deployment using the **ML Operations** app in **SAP AI Launchpad**. In the deployment's details screen, choose **Stop**.\n",
    "\n",
    "![image](img/deployment-stopped.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
