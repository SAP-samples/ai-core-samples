{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d8f0d470dd5ce2",
   "metadata": {},
   "source": [
    "# Orchestration with GenAI Hub"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa2bb46ec75e47",
   "metadata": {},
   "source": [
    "This notebook demonstrates setting up data masking and content filtering, configuring an orchestration pipeline, and querying multiple LLM models with GenAI Hub."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05fc1942",
   "metadata": {},
   "source": [
    "Installing the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f83cfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install hdbcli pandas generative-ai-hub-sdk[all] langchain --break-system-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdccc0b7",
   "metadata": {},
   "source": [
    "The code imports required libraries, reads credentials from a creds.json file, and sets environment variables for authentication and API access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96da5c85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://anuragv2-39wjy902.authentication.eu10.hana.ondemand.com/oauth/token\n",
      "sb-adcd4907-f1a7-462d-ba8e-646390ee4185!b398425|aicore!b540\n",
      "107d3e9b-9a41-4b30-9b24-a091a45956cd$VmYxjzammFm50xkj1O37HmzgX3maoNrwfrlm99qUhi0=\n",
      "https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2\n",
      "llm-deployed\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    "from ai_api_client_sdk.models.parameter_binding import ParameterBinding\n",
    "from enum import Enum\n",
    " \n",
    "# Inline credentials\n",
    "with open('creds.json') as f:\n",
    "    credCF = json.load(f)\n",
    "\n",
    "# Set environment variables\n",
    "def set_environment_vars(credCF):\n",
    "    env_vars = {\n",
    "        'AICORE_AUTH_URL': credCF['url'] + '/oauth/token',\n",
    "        'AICORE_CLIENT_ID': credCF['clientid'],\n",
    "        'AICORE_CLIENT_SECRET': credCF['clientsecret'],\n",
    "        'AICORE_BASE_URL': credCF[\"serviceurls\"][\"AI_API_URL\"] + \"/v2\",\n",
    "        'AICORE_RESOURCE_GROUP': \"llm-deployed\" \n",
    "    }\n",
    "\n",
    "    for key, value in env_vars.items():\n",
    "        os.environ[key] = value\n",
    "        print(value)\n",
    "\n",
    "# Create AI Core client instance\n",
    "def create_ai_core_client(credCF):\n",
    "    set_environment_vars(credCF)  # Ensure environment variables are set\n",
    "    return AICoreV2Client(\n",
    "        base_url=os.environ['AICORE_BASE_URL'],\n",
    "        auth_url=os.environ['AICORE_AUTH_URL'],\n",
    "        client_id=os.environ['AICORE_CLIENT_ID'],\n",
    "        client_secret=os.environ['AICORE_CLIENT_SECRET'],\n",
    "        resource_group=os.environ['AICORE_RESOURCE_GROUP']\n",
    "    )\n",
    "\n",
    "ai_core_client = create_ai_core_client(credCF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c6244a294485e",
   "metadata": {},
   "source": [
    "## Initializing the Orchestration Service\n",
    "\n",
    "⚠️Before using the SDK, you need to set up a virtual deployment of the Orchestration Service. Once deployed, you'll have access to a unique endpoint URL (deploymentUrl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e522c0b92cd29e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:01:05.528876Z",
     "start_time": "2024-09-13T09:01:05.526491Z"
    }
   },
   "outputs": [],
   "source": [
    "YOUR_API_URL = \"https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/d414014d74d0eb17\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e073bc93",
   "metadata": {},
   "source": [
    "\n",
    "# Import Libraries\n",
    "Here, we load essential libraries to manage the orchestration setup and handle data masking and content filtering for queries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bea6bdd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data masking, content filtering, and orchestration\n",
    "import pandas as pd\n",
    "from gen_ai_hub.orchestration.utils import load_text_file\n",
    "from gen_ai_hub.orchestration.models.data_masking import DataMasking\n",
    "from gen_ai_hub.orchestration.models.sap_data_privacy_integration import SAPDataPrivacyIntegration, MaskingMethod, ProfileEntity\n",
    "from gen_ai_hub.orchestration.models.azure_content_filter import AzureContentFilter\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig, Template\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dac7637",
   "metadata": {},
   "source": [
    "# Step 1: Templating\n",
    "\n",
    "Explanation of Templating Code\n",
    "This code defines a template for an AI assistant using orchestration configuration. The `Template` object is set up with system and user messages to guide the assistant’s response behavior. \n",
    "\n",
    "Key Components:\n",
    "- **SystemMessage**: Sets a predefined instruction for the AI assistant. This message typically includes the assistant's role and any specific guidelines it should follow.\n",
    "- **UserMessage**: Represents the user's input and how it is structured in the conversation.\n",
    "  \n",
    "In this revised prompt, only queries are passed to the assistant without any additional context. The AI is expected to respond based solely on the provided input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "595999ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = Template(\n",
    "    messages=[\n",
    "            SystemMessage(\n",
    "                \"\"\"You are an AI assistant. You are provided with the top RAG results (Context) from a Reddit post. \n",
    "                Use the following Context {{?context}} to answer the User_input {{?text}} by selecting the most relevant response. \n",
    "                Ensure you provide an answer **exactly as it appears** in the Context, with no alterations or variations. \n",
    "                Do not generate any new information.\n",
    "\n",
    "                NOTE:\n",
    "                Use only the provided Context {{?context}} to answer User_input {{?text}}. \n",
    "                If no answer found reply 'I don't know'.\"\"\"\n",
    "            ),\n",
    "            UserMessage(\"User_input: {{?text}}, Context: {{?context}}\")\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f511302b",
   "metadata": {},
   "source": [
    "# Step 2: Setup Data Masking\n",
    " This step involves configuring data masking to anonymize or pseudonymize sensitive information (e.g., email, phone, person names).\n",
    " * `SAPDataPrivacyIntegration` is used to specify which types of data should be masked.\n",
    " * Choose between `ANONYMIZATION` or `PSEUDONYMIZATION` as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d315a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure data masking settings\n",
    "data_masking = DataMasking(\n",
    "    providers=[\n",
    "        SAPDataPrivacyIntegration(\n",
    "            method=MaskingMethod.ANONYMIZATION,  # Choose MaskingMethod.PSEUDONYMIZATION if pseudonymization is needed\n",
    "            entities=[\n",
    "                ProfileEntity.EMAIL,\n",
    "                ProfileEntity.PHONE,\n",
    "                ProfileEntity.PERSON,\n",
    "                ProfileEntity.ORG,\n",
    "                ProfileEntity.LOCATION\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b319178a",
   "metadata": {},
   "source": [
    "# Step 3: Define Content Filters\n",
    " Setting up filters for specific content types ensures that the query inputs and outputs are within acceptable limits for the intended application.\n",
    " * Input and output filters are configured to exclude certain types of content, such as violence or self-harm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34088634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure input and output content filters\n",
    "input_filter = AzureContentFilter(hate=0, sexual=4, self_harm=0, violence=2)\n",
    "output_filter = AzureContentFilter(hate=0, sexual=4, self_harm=0, violence=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2053d75",
   "metadata": {},
   "source": [
    "# Step 4: Create the Orchestration Config Function\n",
    " This function configures orchestration for a given query, setting up the template, model, and content filters.\n",
    " Each model uses the same orchestration setup and applies data masking and content filtering to the responses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c5db273",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "# Define orchestration function\n",
    "def Orchestration_run(query, context, model_name):\n",
    "    # Configure the orchestration with templating and model\n",
    "    config = OrchestrationConfig(\n",
    "        template=template,\n",
    "        llm=LLM(name=model_name),\n",
    "        input_filters=[input_filter],\n",
    "        output_filters=[output_filter]\n",
    "    )\n",
    "    \n",
    "    orchestration_service = OrchestrationService(api_url=YOUR_API_URL, config=config)\n",
    "    \n",
    "    # Run orchestration with the provided query and context\n",
    "    result = orchestration_service.run(\n",
    "        config=config,\n",
    "        template_values=[\n",
    "            TemplateValue(name=\"text\", value=query),\n",
    "            TemplateValue(name=\"context\", value=context)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    masked_result = result.orchestration_result.choices[0].message.content\n",
    "    return masked_result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6af9bbde",
   "metadata": {},
   "source": [
    "# Step 5: Querying LLM Models \n",
    "In this step, we will modify the orchestration code to query multiple LLM models directly. The objective is to send predefined questions to each model and receive their responses \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32f6e942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models to query\n",
    "models = [\"gpt-4o\", \"gemini-1.5-pro\", \"meta--llama3-70b-instruct\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f72ae18",
   "metadata": {},
   "source": [
    "Define the Questions to Query\n",
    "\n",
    "We will define a list of questions that we want to ask the LLM models. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5bde8876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define questions to be queried\n",
    "questions = [\n",
    "    \"What are the primary benefits of using SAP AI Core for managing AI scenarios?\", \n",
    "    \"How does SAP AI Core facilitate the integration of AI models with other SAP solutions?\", \n",
    "    \"What improvements does the latest version of SAP AI Core offer for developers?\", \n",
    "    \"Why is prompt lifecycle management essential in the context of generative AI?\", \n",
    "    \"In what ways can the Generative AI Hub assist in the development of AI models?\", \n",
    "    \"How do APIs in SAP AI Core contribute to enhanced machine learning functionalities?\", \n",
    "    \"What methods can be employed to optimize the performance of AI models in SAP AI Core?\", \n",
    "    \"Can you describe the process for managing datasets and model files using the Artifacts feature?\", \n",
    "    \"What strategies can ensure the effective deployment and maintenance of AI models within SAP AI Core?\", \n",
    "    \"What role does the AI API play in monitoring the performance metrics of AI models?\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d5791b",
   "metadata": {},
   "source": [
    "Setting Up Context for the Orchestration Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af796a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\"\"Title: Understanding the Basics of SAP AI Core\n",
    "Query: What is SAP AI Core and what are its main functions?\n",
    "Answer: SAP AI Core is a service within the SAP Business Technology Platform that manages AI assets in a \n",
    "standardized and scalable manner. It supports the execution and operations of AI scenarios, allowing for \n",
    "seamless integration with SAP solutions. Its main functions include lifecycle management of AI scenarios, \n",
    "data-driven decision-making, and automation of tasks using machine learning capabilities.\n",
    "Title: Latest Updates in SAP AI Core\n",
    "Query: What new features were introduced in the latest version of SAP AI Core?\n",
    "Answer: The latest version of SAP AI Core includes enhancements in generative AI capabilities, improved \n",
    "integration with open-source frameworks, and better support for prompt lifecycle management. These \n",
    "updates aim to streamline the development and deployment of AI models, making it easier for businesses to \n",
    "leverage AI technologies.\n",
    "Title: How to Connect Your Data to SAP AI Core\n",
    "Query: What steps should I follow to connect my data with SAP AI Core?\n",
    "Answer: To connect your data with SAP AI Core, you can use cloud storage to store AI assets such as datasets \n",
    "and model files. You will reference these assets using the Artifacts feature in SAP AI Core, which allows for \n",
    "efficient management and retrieval of your data.\n",
    "Title: Training Your AI Model in SAP AI Core\n",
    "Query: How can I effectively train my AI model using SAP AI Core?\n",
    "Answer: Training your AI model in SAP AI Core involves executing a training workflow that allows you to input \n",
    "your data and configure the model parameters. The platform supports various machine learning frameworks, \n",
    "enabling you to optimize your model for better performance.\n",
    "Title: Exploring the Generative AI Hub\n",
    "Query: What is the Generative AI Hub and how can I use it?\n",
    "Answer: The Generative AI Hub is a component of SAP AI Core that allows users to experiment with generative \n",
    "AI models. It provides tools for prompt experimentation, management, and administrative functions, enabling \n",
    "users to create and run natural language prompts effectively.\n",
    "Title: The Role of APIs in SAP AI Core\n",
    "Query: How do APIs enhance the functionality of SAP AI Core?\n",
    "Answer: APIs in SAP AI Core facilitate the integration of AI capabilities into applications, allowing developers to \n",
    "access machine learning functionalities seamlessly. They provide standardized methods for interacting with AI \n",
    "models, making it easier to implement AI solutions in various business processes.\n",
    "Title: Metrics Tracking in AI Core\n",
    "Query: How can I track the performance metrics of my AI models in SAP AI Core?\n",
    "Answer: You can track performance metrics in SAP AI Core using the AI API, which allows you to monitor \n",
    "various aspects of your AI models, such as accuracy, response time, and resource usage. This tracking helps in \n",
    "optimizing model performance and ensuring effective deployment.\n",
    "Title: Advanced Features of SAP AI Core\n",
    "Query: What advanced features does SAP AI Core offer for AI development?\n",
    "Answer: SAP AI Core offers advanced features such as AI Content as a Service, which enables users to provide \n",
    "their AI content on the Service Marketplace. Additionally, it includes orchestration capabilities that combine \n",
    "content generation with essential business functions, enhancing the overall AI development process.\n",
    "Title: Best Practices for Using Generative AI\n",
    "Query: What are some best practices for utilizing generative AI models in SAP AI Core?\n",
    "Answer: Best practices for using generative AI models include clearly defining your prompts, experimenting \n",
    "with different model parameters, and continuously monitoring the output for quality. It's also important to \n",
    "manage prompt lifecycles effectively to ensure optimal performance and relevance.\n",
    "Title: What is AI Content as a Service?\n",
    "Query: Can someone explain AI Content as a Service in SAP AI Core?\n",
    "Answer: AI Content as a Service in SAP AI Core allows users to make their AI-generated content available on \n",
    "the Service Marketplace. This feature leverages GitOps to streamline the deployment and management of AI \n",
    "content, making it accessible for other developers and businesses.\n",
    "Title: Lifecycle Management in AI Core\n",
    "Query: Why is lifecycle management important in SAP AI Core?\n",
    "Answer: Lifecycle management is crucial in SAP AI Core as it ensures that AI models are effectively trained, \n",
    "deployed, and maintained. This process helps in managing updates, monitoring performance, and optimizing \n",
    "models over time, leading to improved reliability and effectiveness.\n",
    "Title: How to Experiment with Natural Language Prompts\n",
    "Query: What is the process for experimenting with natural language prompts in SAP AI Core?\n",
    "Answer: To experiment with natural language prompts, you can access the Generative AI Hub within SAP AI \n",
    "Core. Here, you can create and run various prompts using different generative AI models, allowing you to test \n",
    "and refine your inputs for better outcomes.\n",
    "Title: Supported AI Models in SAP AI Core\n",
    "Query: What AI models are supported by SAP AI Core?\n",
    "Answer: SAP AI Core supports a variety of AI models, including those from Azure OpenAI and GCP Vertex AI. \n",
    "This diverse support allows users to choose the most suitable models for their specific applications and use \n",
    "cases.\n",
    "Title: Managing AI Assets in SAP AI Core\n",
    "Query: What is the best way to manage AI assets in SAP AI Core?\n",
    "Answer: The best way to manage AI assets in SAP AI Core is by utilizing the Artifacts feature, which allows you \n",
    "to organize and reference your datasets and model files efficiently. This structured approach helps in \n",
    "maintaining clarity and accessibility of your AI resources.\n",
    "Title: The Importance of Prompt Lifecycle Management\n",
    "Query: What is prompt lifecycle management and why is it important?\n",
    "Answer: Prompt lifecycle management involves overseeing the creation, testing, and optimization of prompts \n",
    "used in generative AI models. It is important because it ensures that prompts are effective and relevant, \n",
    "leading to better model performance and user satisfaction.\n",
    "Title: How to Access Generative AI Capabilities\n",
    "Query: What steps do I need to take to access generative AI capabilities in SAP AI Core?\n",
    "Answer: To access generative AI capabilities, you must activate the Generative AI Hub within SAP AI Core. \n",
    "Once activated, you can explore various models and tools for prompt experimentation and management.\n",
    "Title: Best Practices for AI Model Deployment\n",
    "Query: What are some best practices for deploying AI models in SAP AI Core?\n",
    "Answer: Best practices for deploying AI models include thoroughly testing your models before deployment, \n",
    "monitoring performance metrics post-deployment, and ensuring that you have a rollback plan in case of \n",
    "issues. Additionally, keeping documentation up to date is essential for maintaining clarity.\n",
    "Title: How to Provide Feedback on SAP AI Core Documentation\n",
    "Query: Is there a way to provide feedback on the SAP AI Core documentation?\n",
    "Answer: Yes, you can provide feedback on the SAP AI Core documentation through GitHub by creating an \n",
    "issue. This allows you to communicate any concerns or suggestions directly to the authors and development \n",
    "team.\n",
    "Title: Understanding the AI API Overview\n",
    "Query: Can someone summarize the AI API Overview in SAP AI Core?\n",
    "Answer: The AI API Overview in SAP AI Core outlines the available APIs for integrating AI functionalities into \n",
    "applications. It provides developers with the necessary tools to leverage machine learning capabilities and \n",
    "streamline the development process.\n",
    "Title: Exploring the Generative AI Hub Architecture\n",
    "Query: What does the architecture of the Generative AI Hub look like in SAP AI Core?\n",
    "Answer: The architecture of the Generative AI Hub in SAP AI Core includes components for prompt \n",
    "experimentation, management, and administrative tools. It allows users to create and run natural language \n",
    "prompts while managing collections and metadata for better organization and efficiency.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6017776",
   "metadata": {},
   "source": [
    "Execute Queries for Each Model\n",
    "\n",
    "We will iterate through the defined models, send each question, and store the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04e91f77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":::gpt-4o:::\n",
      "\n",
      "QUERY:  What are the primary benefits of using SAP AI Core for managing AI scenarios??????\n",
      "\n",
      "RESPONSE:  The primary benefits of using SAP AI Core for managing AI scenarios are as follows:\n",
      "\n",
      "**SAP AI Core is a service within the SAP Business Technology Platform that manages AI assets in a \n",
      "standardized and scalable manner. It supports the execution and operations of AI scenarios, allowing for \n",
      "seamless integration with SAP solutions. Its main functions include lifecycle management of AI scenarios, \n",
      "data-driven decision-making, and automation of tasks using machine learning capabilities.**\n",
      "\n",
      "\n",
      "QUERY:  How does SAP AI Core facilitate the integration of AI models with other SAP solutions??????\n",
      "\n",
      "RESPONSE:  **APIs in SAP AI Core facilitate the integration of AI capabilities into applications, allowing developers to access machine learning functionalities seamlessly. They provide standardized methods for interacting with AI models, making it easier to implement AI solutions in various business processes.**\n",
      "\n",
      "\n",
      "QUERY:  What improvements does the latest version of SAP AI Core offer for developers??????\n",
      "\n",
      "RESPONSE:  **Answer:**\n",
      "\n",
      "The latest version of SAP AI Core includes enhancements in generative AI capabilities, improved integration with open-source frameworks, and better support for prompt lifecycle management. These updates aim to streamline the development and deployment of AI models, making it easier for businesses to leverage AI technologies.\n",
      "\n",
      "\n",
      "QUERY:  Why is prompt lifecycle management essential in the context of generative AI??????\n",
      "\n",
      "RESPONSE:  Prompt lifecycle management involves overseeing the creation, testing, and optimization of prompts used in generative AI models. It is important because it ensures that prompts are effective and relevant, leading to better model performance and user satisfaction.\n",
      "\n",
      "\n",
      "QUERY:  In what ways can the Generative AI Hub assist in the development of AI models??????\n",
      "\n",
      "RESPONSE:  The Generative AI Hub is a component of SAP AI Core that allows users to experiment with generative AI models. It provides tools for prompt experimentation, management, and administrative functions, enabling users to create and run natural language prompts effectively.\n",
      "\n",
      "\n",
      "QUERY:  How do APIs in SAP AI Core contribute to enhanced machine learning functionalities??????\n",
      "\n",
      "RESPONSE:  **Query: How do APIs in SAP AI Core contribute to enhanced machine learning functionalities?**\n",
      "\n",
      "**Answer:**\n",
      "APIs in SAP AI Core facilitate the integration of AI capabilities into applications, allowing developers to access machine learning functionalities seamlessly. They provide standardized methods for interacting with AI models, making it easier to implement AI solutions in various business processes.\n",
      "\n",
      "\n",
      "QUERY:  What methods can be employed to optimize the performance of AI models in SAP AI Core??????\n",
      "\n",
      "RESPONSE:  I don't know.\n",
      "\n",
      "\n",
      "QUERY:  Can you describe the process for managing datasets and model files using the Artifacts feature??????\n",
      "\n",
      "RESPONSE:  To connect your data with SAP AI Core, you can use cloud storage to store AI assets such as datasets and model files. You will reference these assets using the Artifacts feature in SAP AI Core, which allows for efficient management and retrieval of your data.\n",
      "\n",
      "\n",
      "QUERY:  What strategies can ensure the effective deployment and maintenance of AI models within SAP AI Core??????\n",
      "\n",
      "RESPONSE:  I don't know.\n",
      "\n",
      "\n",
      "QUERY:  What role does the AI API play in monitoring the performance metrics of AI models??????\n",
      "\n",
      "RESPONSE:  **Answer: You can track performance metrics in SAP AI Core using the AI API, which allows you to monitor various aspects of your AI models, such as accuracy, response time, and resource usage. This tracking helps in optimizing model performance and ensuring effective deployment.**\n",
      "\n",
      "\n",
      ":::gemini-1.5-pro:::\n",
      "\n",
      "QUERY:  What are the primary benefits of using SAP AI Core for managing AI scenarios??????\n",
      "\n",
      "RESPONSE:  SAP AI Core is a service within the SAP Business Technology Platform that manages AI assets in a \n",
      "standardized and scalable manner. It supports the execution and operations of AI scenarios, allowing for \n",
      "seamless integration with SAP solutions. Its main functions include lifecycle management of AI scenarios, \n",
      "data-driven decision-making, and automation of tasks using machine learning capabilities. \n",
      "\n",
      "\n",
      "\n",
      "QUERY:  How does SAP AI Core facilitate the integration of AI models with other SAP solutions??????\n",
      "\n",
      "RESPONSE:  SAP AI Core is a service within the SAP Business Technology Platform that manages AI assets in a \n",
      "standardized and scalable manner. It supports the execution and operations of AI scenarios, allowing for \n",
      "seamless integration with SAP solutions. \n",
      "\n",
      "\n",
      "\n",
      "QUERY:  What improvements does the latest version of SAP AI Core offer for developers??????\n",
      "\n",
      "RESPONSE:  The latest version of SAP AI Core includes enhancements in generative AI capabilities, improved \n",
      "integration with open-source frameworks, and better support for prompt lifecycle management. These \n",
      "updates aim to streamline the development and deployment of AI models, making it easier for businesses to \n",
      "leverage AI technologies. \n",
      "\n",
      "\n",
      "\n",
      "QUERY:  Why is prompt lifecycle management essential in the context of generative AI??????\n",
      "\n",
      "RESPONSE:  Prompt lifecycle management involves overseeing the creation, testing, and optimization of prompts \n",
      "used in generative AI models. It is important because it ensures that prompts are effective and relevant, \n",
      "leading to better model performance and user satisfaction. \n",
      "\n",
      "\n",
      "\n",
      "QUERY:  In what ways can the Generative AI Hub assist in the development of AI models??????\n",
      "\n",
      "RESPONSE:  The Generative AI Hub is a component of SAP AI Core that allows users to experiment with generative \n",
      "AI models. It provides tools for prompt experimentation, management, and administrative functions, enabling \n",
      "users to create and run natural language prompts effectively. \n",
      "\n",
      "\n",
      "\n",
      "QUERY:  How do APIs in SAP AI Core contribute to enhanced machine learning functionalities??????\n",
      "\n",
      "RESPONSE:  APIs in SAP AI Core facilitate the integration of AI capabilities into applications, allowing developers to \n",
      "access machine learning functionalities seamlessly. They provide standardized methods for interacting with AI \n",
      "models, making it easier to implement AI solutions in various business processes. \n",
      "\n",
      "\n",
      "\n",
      "QUERY:  What methods can be employed to optimize the performance of AI models in SAP AI Core??????\n",
      "\n",
      "RESPONSE:  Training your AI model in SAP AI Core involves executing a training workflow that allows you to input \n",
      "your data and configure the model parameters. The platform supports various machine learning frameworks, \n",
      "enabling you to optimize your model for better performance. \n",
      "\n",
      "\n",
      "\n",
      "QUERY:  Can you describe the process for managing datasets and model files using the Artifacts feature??????\n",
      "\n",
      "RESPONSE:  The best way to manage AI assets in SAP AI Core is by utilizing the Artifacts feature, which allows you \n",
      "to organize and reference your datasets and model files efficiently. This structured approach helps in \n",
      "maintaining clarity and accessibility of your AI resources. \n",
      "\n",
      "\n",
      "\n",
      "QUERY:  What strategies can ensure the effective deployment and maintenance of AI models within SAP AI Core??????\n",
      "\n",
      "RESPONSE:  Best practices for deploying AI models include thoroughly testing your models before deployment, \n",
      "monitoring performance metrics post-deployment, and ensuring that you have a rollback plan in case of \n",
      "issues. Additionally, keeping documentation up to date is essential for maintaining clarity. \n",
      "\n",
      "\n",
      "\n",
      "QUERY:  What role does the AI API play in monitoring the performance metrics of AI models??????\n",
      "\n",
      "RESPONSE:  You can track performance metrics in SAP AI Core using the AI API, which allows you to monitor \n",
      "various aspects of your AI models, such as accuracy, response time, and resource usage. This tracking helps in \n",
      "optimizing model performance and ensuring effective deployment. \n",
      "\n",
      "\n",
      "\n",
      ":::meta--llama3-70b-instruct:::\n",
      "\n",
      "QUERY:  What are the primary benefits of using SAP AI Core for managing AI scenarios??????\n",
      "\n",
      "RESPONSE:  SAP AI Core is a service within the SAP Business Technology Platform that manages AI assets in a standardized and scalable manner. It supports the execution and operations of AI scenarios, allowing for seamless integration with SAP solutions. Its main functions include lifecycle management of AI scenarios, data-driven decision-making, and automation of tasks using machine learning capabilities.\n",
      "\n",
      "\n",
      "QUERY:  How does SAP AI Core facilitate the integration of AI models with other SAP solutions??????\n",
      "\n",
      "RESPONSE:  SAP AI Core facilitates the integration of AI models with other SAP solutions by supporting the execution and operations of AI scenarios, allowing for seamless integration with SAP solutions.\n",
      "\n",
      "\n",
      "QUERY:  What improvements does the latest version of SAP AI Core offer for developers??????\n",
      "\n",
      "RESPONSE:  The latest version of SAP AI Core includes enhancements in generative AI capabilities, improved integration with open-source frameworks, and better support for prompt lifecycle management. These updates aim to streamline the development and deployment of AI models, making it easier for businesses to leverage AI technologies.\n",
      "\n",
      "\n",
      "QUERY:  Why is prompt lifecycle management essential in the context of generative AI??????\n",
      "\n",
      "RESPONSE:  Prompt lifecycle management involves overseeing the creation, testing, and optimization of prompts used in generative AI models. It is important because it ensures that prompts are effective and relevant, leading to better model performance and user satisfaction.\n",
      "\n",
      "\n",
      "QUERY:  In what ways can the Generative AI Hub assist in the development of AI models??????\n",
      "\n",
      "RESPONSE:  The Generative AI Hub assists in the development of AI models by providing tools for prompt experimentation, management, and administrative functions, enabling users to create and run natural language prompts effectively.\n",
      "\n",
      "\n",
      "QUERY:  How do APIs in SAP AI Core contribute to enhanced machine learning functionalities??????\n",
      "\n",
      "RESPONSE:  APIs in SAP AI Core facilitate the integration of AI capabilities into applications, allowing developers to access machine learning functionalities seamlessly. They provide standardized methods for interacting with AI models, making it easier to implement AI solutions in various business processes.\n",
      "\n",
      "\n",
      "QUERY:  What methods can be employed to optimize the performance of AI models in SAP AI Core??????\n",
      "\n",
      "RESPONSE:  I don't know.\n",
      "\n",
      "\n",
      "QUERY:  Can you describe the process for managing datasets and model files using the Artifacts feature??????\n",
      "\n",
      "RESPONSE:  To connect your data with SAP AI Core, you can use cloud storage to store AI assets such as datasets and model files. You will reference these assets using the Artifacts feature in SAP AI Core, which allows for efficient management and retrieval of your data.\n",
      "\n",
      "\n",
      "QUERY:  What strategies can ensure the effective deployment and maintenance of AI models within SAP AI Core??????\n",
      "\n",
      "RESPONSE:  Best practices for deploying AI models include thoroughly testing your models before deployment, monitoring performance metrics post-deployment, and ensuring that you have a rollback plan in case of issues. Additionally, keeping documentation up to date is essential for maintaining clarity.\n",
      "\n",
      "\n",
      "QUERY:  What role does the AI API play in monitoring the performance metrics of AI models??????\n",
      "\n",
      "RESPONSE:  You can track performance metrics in SAP AI Core using the AI API, which allows you to monitor various aspects of your AI models, such as accuracy, response time, and resource usage. This tracking helps in optimizing model performance and ensuring effective deployment.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store the results\n",
    "master = {}\n",
    "\n",
    "# Iterate through all model names\n",
    "for model_name in models:\n",
    "    print(f\":::{model_name}:::\\n\")\n",
    "    \n",
    "    master[model_name] = {\n",
    "        \"question\": [],\n",
    "        \"answer\": []\n",
    "    }\n",
    "    \n",
    "    for query in questions:\n",
    "\n",
    "        # Call Orchestration_run with query and context\n",
    "        ans = Orchestration_run(query=query, context=context, model_name=model_name)\n",
    "        \n",
    "        master[model_name][\"question\"].append(query)\n",
    "        master[model_name][\"answer\"].append(ans)\n",
    "        \n",
    "        print(\"QUERY: \", query + '?????\\n')\n",
    "        print(\"RESPONSE: \", ans + '\\n')\n",
    "        print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21af83af",
   "metadata": {},
   "source": [
    "Exporting Results to Excel\n",
    "\n",
    "In this section, we convert the collected results from each model into a single DataFrame for easy export\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7c184a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert results to a DataFrame for exporting\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "# Create a DataFrame for each model's results and concatenate them\n",
    "for model_name in models:\n",
    "    model_df = pd.DataFrame(master[model_name])\n",
    "    model_df['model'] = model_name  # Add a column for the model name\n",
    "    results_df = pd.concat([results_df, model_df], ignore_index=True)\n",
    "\n",
    "# Save the results to an Excel file\n",
    "results_df.to_excel(\"llm_responses.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
