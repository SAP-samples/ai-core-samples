{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4d8f0d470dd5ce2",
   "metadata": {},
   "source": [
    "# Orchestration Service Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cfa2bb46ec75e47",
   "metadata": {},
   "source": [
    "This notebook demonstrates how to use the SDK to interact with the Orchestration Service, enabling the creation of AI-driven workflows by seamlessly integrating various modules, such as templating, large language models (LLMs), data masking and content filtering. By leveraging these modules, you can build complex, automated workflows that enhance the capabilities of your AI solutions. For more details on configuring and using these modules, please refer to the [Orchestration Service Documentation](https://help.sap.com/docs/ai-launchpad/sap-ai-launchpad/orchestration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8bb3a93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hdbcli in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (2.19.21)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pandas in c:\\users\\i746414\\appdata\\roaming\\python\\python311\\site-packages (2.2.2)\n",
      "Requirement already satisfied: generative-ai-hub-sdk[all] in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (3.2.6)\n",
      "Requirement already satisfied: langchain in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (0.2.15)\n",
      "Collecting lexical_diversity\n",
      "  Obtaining dependency information for lexical_diversity from https://files.pythonhosted.org/packages/62/37/d6f959b2255b1321b3d359d902dbd83dec3c7bb6443168d79f8911a94ae3/lexical_diversity-0.1.1-py3-none-any.whl.metadata\n",
      "  Downloading lexical_diversity-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: nltk in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: overloading==0.5.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk[all]) (0.5.0)\n",
      "Requirement already satisfied: openai>=1.3.3 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk[all]) (1.40.2)\n",
      "Requirement already satisfied: packaging==23.2 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk[all]) (23.2)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk[all]) (8.1.7)\n",
      "Requirement already satisfied: dacite>=1.8.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk[all]) (1.8.1)\n",
      "Requirement already satisfied: pydantic>=2.5.3 in c:\\users\\i746414\\appdata\\roaming\\python\\python311\\site-packages (from generative-ai-hub-sdk[all]) (2.8.2)\n",
      "Requirement already satisfied: ai-core-sdk>=2.4.6 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk[all]) (2.4.8)\n",
      "Requirement already satisfied: langchain-community==0.2.10 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk[all]) (0.2.10)\n",
      "Requirement already satisfied: langchain-aws==0.1.7 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk[all]) (0.1.7)\n",
      "Requirement already satisfied: langchain-google-vertexai==1.0.8 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk[all]) (1.0.8)\n",
      "Requirement already satisfied: langchain-openai~=0.1.4 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk[all]) (0.1.23)\n",
      "Requirement already satisfied: google-cloud-aiplatform==1.60.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk[all]) (1.60.0)\n",
      "Requirement already satisfied: boto3==1.34.132 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from generative-ai-hub-sdk[all]) (1.34.132)\n",
      "Requirement already satisfied: botocore<1.35.0,>=1.34.132 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from boto3==1.34.132->generative-ai-hub-sdk[all]) (1.34.145)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from boto3==1.34.132->generative-ai-hub-sdk[all]) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from boto3==1.34.132->generative-ai-hub-sdk[all]) (0.10.2)\n",
      "Requirement already satisfied: google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (2.17.1)\n",
      "Requirement already satisfied: google-auth<3.0.0dev,>=2.14.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (2.28.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (1.23.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (4.25.3)\n",
      "Requirement already satisfied: google-cloud-storage<3.0.0dev,>=1.32.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (2.18.2)\n",
      "Requirement already satisfied: google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (3.25.0)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0dev,>=1.3.3 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (1.12.5)\n",
      "Requirement already satisfied: shapely<3.0.0dev in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (2.0.3)\n",
      "Requirement already satisfied: docstring-parser<1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (0.16)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.2.2 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-aws==0.1.7->generative-ai-hub-sdk[all]) (0.2.37)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk[all]) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk[all]) (1.4.52)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk[all]) (3.9.3)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk[all]) (0.5.14)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk[all]) (0.1.84)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk[all]) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-community==0.2.10->generative-ai-hub-sdk[all]) (8.2.3)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: joblib in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk) (1.2.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk) (2022.7.9)\n",
      "Requirement already satisfied: tqdm in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from nltk) (4.66.5)\n",
      "Requirement already satisfied: ai-api-client-sdk==2.2.2 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from ai-core-sdk>=2.4.6->generative-ai-hub-sdk[all]) (2.2.2)\n",
      "Requirement already satisfied: aenum~=3.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from ai-api-client-sdk==2.2.2->ai-core-sdk>=2.4.6->generative-ai-hub-sdk[all]) (3.1.15)\n",
      "Requirement already satisfied: pyhumps~=3.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from ai-api-client-sdk==2.2.2->ai-core-sdk>=2.4.6->generative-ai-hub-sdk[all]) (3.8.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.10->generative-ai-hub-sdk[all]) (1.2.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.10->generative-ai-hub-sdk[all]) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.10->generative-ai-hub-sdk[all]) (1.3.3)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.10->generative-ai-hub-sdk[all]) (6.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community==0.2.10->generative-ai-hub-sdk[all]) (1.8.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from click>=8.1.3->generative-ai-hub-sdk[all]) (0.4.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain-aws==0.1.7->generative-ai-hub-sdk[all]) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-core<0.3,>=0.2.2->langchain-aws==0.1.7->generative-ai-hub-sdk[all]) (4.12.2)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langchain-openai~=0.1.4->generative-ai-hub-sdk[all]) (0.7.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from langsmith<0.2.0,>=0.1.0->langchain-community==0.2.10->generative-ai-hub-sdk[all]) (3.9.15)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3.3->generative-ai-hub-sdk[all]) (3.5.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3.3->generative-ai-hub-sdk[all]) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3.3->generative-ai-hub-sdk[all]) (0.27.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3.3->generative-ai-hub-sdk[all]) (0.5.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from openai>=1.3.3->generative-ai-hub-sdk[all]) (1.3.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic>=2.5.3->generative-ai-hub-sdk[all]) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from pydantic>=2.5.3->generative-ai-hub-sdk[all]) (2.20.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community==0.2.10->generative-ai-hub-sdk[all]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community==0.2.10->generative-ai-hub-sdk[all]) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\i746414\\appdata\\roaming\\python\\python311\\site-packages (from requests<3,>=2->langchain-community==0.2.10->generative-ai-hub-sdk[all]) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from requests<3,>=2->langchain-community==0.2.10->generative-ai-hub-sdk[all]) (2023.7.22)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community==0.2.10->generative-ai-hub-sdk[all]) (3.0.3)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.10->generative-ai-hub-sdk[all]) (3.21.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.10->generative-ai-hub-sdk[all]) (0.9.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (1.62.0)\n",
      "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (1.62.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0dev,>=1.34.1->google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (1.62.0)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (5.3.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (4.7.2)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0dev,>=1.6.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (2.4.1)\n",
      "Requirement already satisfied: google-resumable-media<3.0dev,>=0.6.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-bigquery!=3.20.0,<4.0.0dev,>=1.15.0->google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (2.7.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0dev,>=0.12.4 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-resource-manager<3.0.0dev,>=1.3.3->google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (0.13.1)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from google-cloud-storage<3.0.0dev,>=1.32.0->google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (1.6.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from httpx<1,>=0.23.0->openai>=1.3.3->generative-ai-hub-sdk[all]) (1.0.4)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai>=1.3.3->generative-ai-hub-sdk[all]) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.2.2->langchain-aws==0.1.7->generative-ai-hub-sdk[all]) (2.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0dev,>=2.14.1->google-cloud-aiplatform==1.60.0->generative-ai-hub-sdk[all]) (0.4.8)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\i746414\\appdata\\local\\anaconda3\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community==0.2.10->generative-ai-hub-sdk[all]) (1.0.0)\n",
      "Downloading lexical_diversity-0.1.1-py3-none-any.whl (117 kB)\n",
      "   ---------------------------------------- 0.0/117.8 kB ? eta -:--:--\n",
      "   -------------------------------------- - 112.6/117.8 kB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 117.8/117.8 kB 1.4 MB/s eta 0:00:00\n",
      "Installing collected packages: lexical_diversity\n",
      "Successfully installed lexical_diversity-0.1.1\n"
     ]
    }
   ],
   "source": [
    "pip install hdbcli pandas generative-ai-hub-sdk[all] langchain lexical_diversity nltk --break-system-packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b386afd4",
   "metadata": {},
   "source": [
    "### NOTE: This is the Initial Iteration with Evaluation Metric, work in progress... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96da5c85",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at c:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at c:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at c:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at c:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 105.391 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Executing <Task pending name='Task-4' coro=<Kernel.dispatch_queue() running at c:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:516> wait_for=<Future pending cb=[Task.task_wakeup()] created at c:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\queues.py:248> cb=[IOLoop.add_future.<locals>.<lambda>() at c:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\site-packages\\tornado\\ioloop.py:685] created at c:\\Users\\I746414\\AppData\\Local\\anaconda3\\Lib\\asyncio\\tasks.py:670> took 11.015 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import json\n",
    "import os\n",
    "from IPython.display import clear_output\n",
    "from ai_core_sdk.ai_core_v2_client import AICoreV2Client\n",
    "from ai_api_client_sdk.models.parameter_binding import ParameterBinding\n",
    "from enum import Enum\n",
    " \n",
    "# Inline credentials\n",
    "with open('creds.json') as f:\n",
    "    credCF = json.load(f)\n",
    "\n",
    "# Set environment variables\n",
    "def set_environment_vars(credCF):\n",
    "    env_vars = {\n",
    "        'AICORE_AUTH_URL': credCF['url'] + '/oauth/token',\n",
    "        'AICORE_CLIENT_ID': credCF['clientid'],\n",
    "        'AICORE_CLIENT_SECRET': credCF['clientsecret'],\n",
    "        'AICORE_BASE_URL': credCF[\"serviceurls\"][\"AI_API_URL\"] + \"/v2\",\n",
    "        'AICORE_RESOURCE_GROUP': \"llm-deployed\" \n",
    "    }\n",
    "\n",
    "    for key, value in env_vars.items():\n",
    "        os.environ[key] = value\n",
    "        print(value)\n",
    "\n",
    "# Create AI Core client instance\n",
    "def create_ai_core_client(credCF):\n",
    "    set_environment_vars(credCF)  # Ensure environment variables are set\n",
    "    return AICoreV2Client(\n",
    "        base_url=os.environ['AICORE_BASE_URL'],\n",
    "        auth_url=os.environ['AICORE_AUTH_URL'],\n",
    "        client_id=os.environ['AICORE_CLIENT_ID'],\n",
    "        client_secret=os.environ['AICORE_CLIENT_SECRET'],\n",
    "        resource_group=os.environ['AICORE_RESOURCE_GROUP']\n",
    "    )\n",
    "\n",
    "ai_core_client = create_ai_core_client(credCF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c6244a294485e",
   "metadata": {},
   "source": [
    "## Initializing the Orchestration Service\n",
    "\n",
    "⚠️Before using the SDK, you need to set up a virtual deployment of the Orchestration Service. Once deployed, you'll have access to a unique endpoint URL (deploymentUrl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e522c0b92cd29e4d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-13T09:01:05.528876Z",
     "start_time": "2024-09-13T09:01:05.526491Z"
    }
   },
   "outputs": [],
   "source": [
    "YOUR_API_URL = \"https://api.ai.prod.eu-central-1.aws.ml.hana.ondemand.com/v2/inference/deployments/de3f0730ef89b19d\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca5e939",
   "metadata": {},
   "source": [
    "### Data from Reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f805caaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLIENT_ID = \"a7MrDySej99w6jTAwrOenQ\"\n",
    "SECRET_KEY = \"UDOkopBDlgu2ar42d3AaaNtYXgsZBw\"\n",
    "username = \"Sad-Parsnip9117\"\n",
    "password = \"Redrose@87\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b18b7647",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "auth = requests.auth.HTTPBasicAuth(CLIENT_ID,SECRET_KEY)\n",
    "data = {\n",
    "    'grant_type':'password',\n",
    "    'username':username,\n",
    "    'password':password\n",
    "}\n",
    "headers = {'User-Agent':'MyAPI/0.0.1'}\n",
    "res = requests.post('https://www.reddit.com/api/v1/access_token',auth=auth,data=data,headers=headers)\n",
    "TOKEN = res.json()['access_token']\n",
    "headers['Authorization'] = f'bearer {TOKEN}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab97a0f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'access_token': 'eyJhbGciOiJSUzI1NiIsImtpZCI6IlNIQTI1NjpzS3dsMnlsV0VtMjVmcXhwTU40cWY4MXE2OWFFdWFyMnpLMUdhVGxjdWNZIiwidHlwIjoiSldUIn0.eyJzdWIiOiJ1c2VyIiwiZXhwIjoxNzI4MDQ2NDk5LjYzMjU0NiwiaWF0IjoxNzI3OTYwMDk5LjYzMjU0NSwianRpIjoiOUJEX3hEcEd6OUJlUDd1Z3NHNEEzeUNiaFJteFlnIiwiY2lkIjoiYTdNckR5U2VqOTl3NmpUQXdyT2VuUSIsImxpZCI6InQyXzE4ZjB5NHo2bG8iLCJhaWQiOiJ0Ml8xOGYweTR6NmxvIiwibGNhIjoxNzI1ODY5MTI4NjcyLCJzY3AiOiJlSnlLVnRKU2lnVUVBQURfX3dOekFTYyIsImZsbyI6OX0.XraywzPn2c3yZp-DlRWkCBLmliYkubowIZZxqobsJ-_Mxm-WtTWoRFhBiUERJlrGXuCTNnXriOB9aV7CvmodCp6hCnwX_rW0-ymZaero-cvJueYtM2KpL7nZZBCkaDDx_feq90WOXuWz2bCBcZYkGhKaT45joZzlrtahEuovLpgxfZR_zu8ZBEmH_1Db3E0v9KWvOhGz0p8ZfLIvw4aTSgPd2ZYfQCgB7V_Bk0b6RedVmtnK4QRMwyXeSwy6fTRAexj50bEEanN2YmjVCNTZsF_TwPkSmDbFzqAOJJF31Xdn_FkwzKbxHOwnXKUU3ZwqppziDOfMXSkurzb7767eJQ',\n",
       " 'token_type': 'bearer',\n",
       " 'expires_in': 86400,\n",
       " 'scope': '*'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca2b47d",
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_data = requests.get('https://oauth.reddit.com/r/SAPAIcore/',headers=headers).json()['data']['children']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e058ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = [data['data']['id'] for data in reddit_data]\n",
    "comments = {}\n",
    "for i in ids:\n",
    "    comment_data = requests.get(f'https://oauth.reddit.com/r/SAPAIcore//comments/{i}',headers=headers).json()\n",
    "    comments[f\"{i}\"] = []\n",
    "    def parse_comments(data):\n",
    "        for j in data:\n",
    "            comments[f\"{i}\"].append(j['data']['body'])\n",
    "            if j['data']['replies'] != '':\n",
    "                parse_comments(j['data']['replies']['data']['children'])\n",
    "    if(len(comment_data[1]['data']['children'])):\n",
    "        parse_comments(comment_data[1]['data']['children'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca554a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI core\n"
     ]
    }
   ],
   "source": [
    "extracted_data = []\n",
    "for post in enumerate(reddit_data):\n",
    "    post_content = post[1]['data']['selftext']\n",
    "    \n",
    "    # Removed anonymization logic\n",
    "    # if user_intention(post_content):\n",
    "    row = [int(post[0] + 1)]\n",
    "    row.append(post[1]['data']['title'])\n",
    "    row.append(post_content)\n",
    "    row.append(str(comments[post[1]['data']['id']]))\n",
    "    print(row[1])\n",
    "    extracted_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce61957f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of document chunks: 1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(extracted_data,columns=[\"ID\", \"TITLE\", \"POST\", \"COMMENTS\"])\n",
    "\n",
    "df.to_csv(\"output1.csv\", index=False)\n",
    "\n",
    "from langchain.document_loaders.csv_loader import CSVLoader\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "loader = CSVLoader(\n",
    "    file_path=\"output1.csv\",\n",
    "    csv_args={\n",
    "        \"delimiter\": \",\",\n",
    "        \"quotechar\": '\"'\n",
    "    },\n",
    ")\n",
    "\n",
    "# Process data\n",
    "text_documents = loader.load()\n",
    "text_chunks = text_documents\n",
    "print(f\"Number of document chunks: {len(text_documents)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "63cd665c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HC Vector Engine\n",
    "from hdbcli import dbapi\n",
    "from langchain_community.vectorstores.hanavector import HanaDB\n",
    "\n",
    "host_address = \"ec41b786-96de-467b-9ff5-db725945f89c.hna0.prod-us10.hanacloud.ondemand.com\"\n",
    "hdb_user = \"DBADMIN\"\n",
    "hdb_password = \"9hEW4UK86Fdt\"\n",
    "\n",
    "connection = dbapi.connect(\n",
    "    host_address,\n",
    "    port=\"443\",\n",
    "    user=hdb_user,\n",
    "    password=hdb_password,\n",
    "    autocommit=True,\n",
    "    sslValidateCertificate=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5a229da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gen_ai_hub.proxy.langchain.init_models import init_embedding_model\n",
    "embeddings = init_embedding_model('text-embedding-ada-002')\n",
    "db = HanaDB(\n",
    "    embedding=embeddings, connection=connection, table_name=\"SUBREDDIT_POST_ORC4\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "47c0086b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete already existing documents from the table\n",
    "db.delete(filter={})\n",
    "\n",
    "# add the loaded document chunks\n",
    "db.add_documents(text_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f349bd04",
   "metadata": {},
   "source": [
    "### Data Masking\n",
    "\n",
    "The Data Masking Module anonymizes or pseudonymizes personally identifiable information (PII) before it is processed by the LLM module. When data is anonymized, all identifying information is replaced with placeholders (e.g., MASKED_ENTITY), and the original data cannot be recovered, ensuring that no trace of the original information is retained. In contrast, pseudonymized data is substituted with unique placeholders (e.g., MASKED_ENTITY_ID), allowing the original information to be restored if needed. In both cases, the masking module identifies sensitive data and replaces it with appropriate placeholders before further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc3fccd",
   "metadata": {},
   "source": [
    "### Content Filtering\n",
    "\n",
    "The Content Filtering Module can be configured to filter both the input to the LLM module (input filter) and the output generated by the LLM (output filter). The module uses predefined classification services to detect inappropriate or unwanted content, allowing flexible configuration through customizable thresholds. These thresholds can be set to control the sensitivity of filtering, ensuring that content meets desired standards before it is processed or returned as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ab11d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masked Result from gpt-4o: **To resolve the issue, follow these steps to create a Docker registry in MASKED_ORG via the AI Launchpad:**\n",
      "\n",
      "1. Open the AI Launchpad.\n",
      "2. Navigate to the MASKED_ORG Administration section.\n",
      "3. Select the Docker Registry option.\n",
      "4. Enter the desired name for your Docker registry.\n",
      "5. Provide your Docker credentials in the following JSON format:\n",
      "\n",
      "{\n",
      "    \".dockerconfigjson\": \"{\\\"auths\\\":{\\\"https://hub.docker.com\\\":{\\\"username\\\":\\\"myusername\\\",\\\"password\\\":\\\"myaccesstoken\\\"}}}\"\n",
      "}\n",
      "\n",
      "Make sure to replace myusername with your actual Docker username and myaccesstoken with your Docker access token.\n",
      "\n",
      "Once you've provided these details, you should be able to successfully add the Docker registry to your MASKED_ORG Launchpad.\n",
      "Masked Result from gemini-1.5-pro: {  \\n\\n\".dockerconfigjson\": \"{\\\\\\\\\\\\\\\\\"auths\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\"https://hub.docker.com\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\"username\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\"myusername\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\"password\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\"myaccesstoken\\\\\\\\\\\\\\\\\"}}}\"\\\\n\\n}\n",
      "\n",
      "Masked Result from meta--llama3-70b-instruct: {  \n",
      ".dockerconfigjson\": \"{\\\\\\\\\"auths\\\\\\\\\":{\\\\\\\\\\\\\"https://hub.docker.com\\\\\\\\\":{\\\\\\\\\\\\\"username\\\\\\\\\":\\\\\\\\\\\\\"myusername\\\\\\\\\\\",\\\\\\\\\\\\\"password\\\\\\\\\":\\\\\\\\\\\\\"myaccesstoken\\\\\\\\\\\\\"}}}\"\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from gen_ai_hub.orchestration.utils import load_text_file\n",
    "from gen_ai_hub.orchestration.models.data_masking import DataMasking\n",
    "from gen_ai_hub.orchestration.models.sap_data_privacy_integration import SAPDataPrivacyIntegration, MaskingMethod, ProfileEntity\n",
    "from gen_ai_hub.orchestration.models.azure_content_filter import AzureContentFilter\n",
    "from gen_ai_hub.orchestration.models.config import OrchestrationConfig, Template\n",
    "from gen_ai_hub.orchestration.models.message import SystemMessage, UserMessage\n",
    "from gen_ai_hub.orchestration.models.template import Template, TemplateValue\n",
    "from gen_ai_hub.orchestration.models.llm import LLM\n",
    "from gen_ai_hub.orchestration.service import OrchestrationService\n",
    "\n",
    "# Setup Data Masking\n",
    "data_masking = DataMasking(\n",
    "    providers=[\n",
    "        SAPDataPrivacyIntegration(\n",
    "            method=MaskingMethod.ANONYMIZATION,  # or MaskingMethod.PSEUDONYMIZATION\n",
    "            entities=[\n",
    "                ProfileEntity.EMAIL,\n",
    "                ProfileEntity.PHONE,\n",
    "                ProfileEntity.PERSON,\n",
    "                ProfileEntity.ORG,\n",
    "                ProfileEntity.LOCATION\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define content filters\n",
    "input_filter = AzureContentFilter(\n",
    "    hate=0,\n",
    "    sexual=4,\n",
    "    self_harm=0,\n",
    "    violence=2,\n",
    ")\n",
    "output_filter = AzureContentFilter(\n",
    "    hate=0,\n",
    "    sexual=4,\n",
    "    self_harm=0,\n",
    "    violence=2,\n",
    ")\n",
    "\n",
    "# Models to query\n",
    "models = [\"gpt-4o\", \"gemini-1.5-pro\", \"meta--llama3-70b-instruct\"]\n",
    "responses = {}\n",
    "\n",
    "# Simulate Query and Context\n",
    "query = \"docker config\"\n",
    "docs = db.similarity_search_with_score(query, k=5)\n",
    "context = ''.join(str(docs))\n",
    "\n",
    "for model_name in models:\n",
    "    # Orchestration Config Setup for each model\n",
    "    config = OrchestrationConfig(\n",
    "        template=Template(\n",
    "            messages=[\n",
    "                SystemMessage(\n",
    "                    \"\"\"You are a helpful AI assistant. You are provided with the top 5 RAG results (Context) from a Reddit post. Use the following Context to answer the User_input by selecting the most relevant response. Ensure you provide an answer **exactly as it appears** in the Context, with no alterations or variations. Do not generate any new information.\\\n",
    "            NOTE: Use only the provided Context, and do not alter it in any way.Don't hallucinate anything apart from Context provided\"\"\"),\n",
    "                UserMessage(\"User_input: {{?text}}, Context: {{?context}}\"),\n",
    "            ]\n",
    "        ),\n",
    "        llm=LLM(name=model_name),\n",
    "        data_masking=data_masking,  # Ensure masking is part of the config\n",
    "        input_filters=[input_filter],\n",
    "        output_filters=[output_filter]\n",
    "    )\n",
    "\n",
    "    orchestration_service = OrchestrationService(api_url=YOUR_API_URL, config=config)\n",
    "\n",
    "    # Execute Orchestration Service\n",
    "    result = orchestration_service.run(\n",
    "        config=config,\n",
    "        template_values=[\n",
    "            TemplateValue(name=\"text\", value=query),\n",
    "            TemplateValue(name=\"context\", value=context)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Check for masked entities in the response\n",
    "    masked_result = result.orchestration_result.choices[0].message.content\n",
    "    \n",
    "    # Store the masked result in the responses dictionary\n",
    "    responses[model_name] = masked_result\n",
    "\n",
    "# Print the final results after data masking and content filtering\n",
    "for model, result in responses.items():\n",
    "    print(f\"Masked Result from {model}:\", result)\n",
    "\n",
    "# Accessing individual results separately for evaluation metrics\n",
    "gpt_4o_result = responses[\"gpt-4o\"]\n",
    "gemini_1_5_pro_result = responses[\"gemini-1.5-pro\"]\n",
    "meta_llama3_70b_instruct_result = responses[\"meta--llama3-70b-instruct\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1bd7b158",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'**To resolve the issue, follow these steps to create a Docker registry in MASKED_ORG via the AI Launchpad:**\\n\\n1. Open the AI Launchpad.\\n2. Navigate to the MASKED_ORG Administration section.\\n3. Select the Docker Registry option.\\n4. Enter the desired name for your Docker registry.\\n5. Provide your Docker credentials in the following JSON format:\\n\\n{\\n    \".dockerconfigjson\": \"{\\\\\"auths\\\\\":{\\\\\"https://hub.docker.com\\\\\":{\\\\\"username\\\\\":\\\\\"myusername\\\\\",\\\\\"password\\\\\":\\\\\"myaccesstoken\\\\\"}}}\"\\n}\\n\\nMake sure to replace myusername with your actual Docker username and myaccesstoken with your Docker access token.\\n\\nOnce you\\'ve provided these details, you should be able to successfully add the Docker registry to your MASKED_ORG Launchpad.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpt_4o_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4d12263a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{  \\\\n\\\\n\".dockerconfigjson\": \"{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"auths\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"https://hub.docker.com\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"username\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"myusername\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"password\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"myaccesstoken\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\"}}}\"\\\\\\\\n\\\\n}\\n'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_1_5_pro_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "48980570",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{  \\n.dockerconfigjson\": \"{\\\\\\\\\\\\\\\\\"auths\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\\\\\"https://hub.docker.com\\\\\\\\\\\\\\\\\":{\\\\\\\\\\\\\\\\\\\\\\\\\"username\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\"myusername\\\\\\\\\\\\\\\\\\\\\",\\\\\\\\\\\\\\\\\\\\\\\\\"password\\\\\\\\\\\\\\\\\":\\\\\\\\\\\\\\\\\\\\\\\\\"myaccesstoken\\\\\\\\\\\\\\\\\\\\\\\\\"}}}\"'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_llama3_70b_instruct_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "721bb9a4",
   "metadata": {},
   "source": [
    "## Evaluation Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "148953b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from lexical_diversity import lex_div as ld\n",
    "import numpy as np\n",
    "\n",
    "nltk.data.path.append('nltk_data')\n",
    "\n",
    "# Lexical richness evaluation functions  \n",
    "def calculate_rttr(text):\n",
    "    words = word_tokenize(text)\n",
    "    num_tokens = len(words)\n",
    "    types = len(set(words))\n",
    "    if num_tokens == 0:\n",
    "        return 0  # Avoid division by zero\n",
    "    rttr = types / np.sqrt(num_tokens)\n",
    "    return rttr\n",
    "\n",
    "def calculate_maas(text):\n",
    "    words = word_tokenize(text)\n",
    "    num_tokens = len(words)\n",
    "    types = len(set(words))\n",
    "    if num_tokens == 0 or types == 0:\n",
    "        return float('inf')  # Return a large number for very poor results\n",
    "    maas = (np.log(num_tokens) - np.log(types)) / (np.log(num_tokens)**2)\n",
    "    return maas\n",
    "\n",
    "def calculate_mattr(text, window_size=50):\n",
    "    words = word_tokenize(text)\n",
    "    return ld.mattr(words, window_size)\n",
    "\n",
    "def calculate_mtld(text, ttr_threshold=0.72):\n",
    "    words = word_tokenize(text)\n",
    "    return ld.mtld(words, ttr_threshold)\n",
    "\n",
    "def rttr_result(rttr):\n",
    "    if rttr > 7.0:\n",
    "        return 'good'\n",
    "    elif 5.0 <= rttr < 7.0:\n",
    "        return 'intermediate'\n",
    "    else:  # rttr < 5.0\n",
    "        return 'bad'\n",
    "\n",
    "def maas_result(maas):\n",
    "    if maas < 0.02:\n",
    "        return 'good'\n",
    "    elif 0.02 <= maas <= 0.04:\n",
    "        return 'intermediate'\n",
    "    elif maas > 0.04:\n",
    "        return 'bad'\n",
    "\n",
    "def mattr_result(mattr):\n",
    "    if mattr > 0.85:\n",
    "        return 'good'\n",
    "    elif 0.65 < mattr <= 0.85:\n",
    "        return 'intermediate'\n",
    "    else:  # mattr <= 0.65\n",
    "        return 'bad'\n",
    "\n",
    "def mtld_result(mtld):\n",
    "    if mtld > 80:\n",
    "        return 'good'\n",
    "    elif 60 < mtld <= 80:\n",
    "        return 'intermediate'\n",
    "    else:  # mtld <= 60\n",
    "        return 'bad'\n",
    "\n",
    "def evaluate_lexical_richness(text):  \n",
    "    rttr = calculate_rttr(text)  \n",
    "    maas = calculate_maas(text)  \n",
    "    mattr = calculate_mattr(text)  \n",
    "    mtld = calculate_mtld(text)  \n",
    "\n",
    "    # Categorization based on thresholds  \n",
    "    rttr_category = rttr_result(rttr)\n",
    "    maas_category = maas_result(maas)\n",
    "    mattr_category = mattr_result(mattr)\n",
    "    mtld_category = mtld_result(mtld)\n",
    "\n",
    "    # Overall evaluation: majority voting  \n",
    "    categories = [rttr_category, maas_category, mattr_category, mtld_category]  \n",
    "    overall_category = max(set(categories), key=categories.count)  \n",
    "    \n",
    "    # print({'RTTR': {'category': rttr_category, 'value': rttr},  \n",
    "    #     'Maas': {'category': maas_category, 'value': maas},  \n",
    "    #     'MATTR': {'category': mattr_category, 'value': mattr},  \n",
    "    #     'MTLD': {'category': mtld_category, 'value': mtld},  \n",
    "    #     'Overall': overall_category })\n",
    "    \n",
    "    return {  \n",
    "        'RTTR': {'category': rttr_category, 'value': rttr},  \n",
    "        'Maas': {'category': maas_category, 'value': maas},  \n",
    "        'MATTR': {'category': mattr_category, 'value': mattr},  \n",
    "        'MTLD': {'category': mtld_category, 'value': mtld},  \n",
    "        'Overall': overall_category  \n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aaa34265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------+-----------------+--------------+-----------------+--------------+------------------+---------------+-----------------+--------------+--------------+\n",
      "|           Model           | RTTR (Category) | RTTR (Value) | Maas (Category) | Maas (Value) | MATTR (Category) | MATTR (Value) | MTLD (Category) | MTLD (Value) |   Overall    |\n",
      "+---------------------------+-----------------+--------------+-----------------+--------------+------------------+---------------+-----------------+--------------+--------------+\n",
      "|           gpt-4o          |   intermediate  |    6.1649    |   intermediate  |    0.0277    |       bad        |     0.5807    |       bad       |   15.9779    | intermediate |\n",
      "|       gemini-1.5-pro      |       bad       |    2.4797    |       bad       |    0.0686    |       bad        |     0.3617    |       bad       |    6.8187    |     bad      |\n",
      "| meta--llama3-70b-instruct |       bad       |     2.44     |       bad       |    0.0699    |       bad        |     0.3721    |       bad       |    6.6548    |     bad      |\n",
      "+---------------------------+-----------------+--------------+-----------------+--------------+------------------+---------------+-----------------+--------------+--------------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "# Evaluate lexical richness for each response  \n",
    "model_metrics = {\n",
    "    \"gpt-4o\": evaluate_lexical_richness(gpt_4o_result),\n",
    "    \"gemini-1.5-pro\": evaluate_lexical_richness(gemini_1_5_pro_result),\n",
    "    \"meta--llama3-70b-instruct\": evaluate_lexical_richness(meta_llama3_70b_instruct_result)\n",
    "} \n",
    "\n",
    "# Function to collect and format metrics for all models into a table  \n",
    "def format_metrics_to_table(model_metrics: dict):  \n",
    "    table = PrettyTable()  \n",
    "    table.field_names = [\"Model\", \"RTTR (Category)\", \"RTTR (Value)\", \"Maas (Category)\", \"Maas (Value)\",  \n",
    "                         \"MATTR (Category)\", \"MATTR (Value)\", \"MTLD (Category)\", \"MTLD (Value)\", \"Overall\"]  \n",
    " \n",
    "    for model_name, metrics in model_metrics.items():  \n",
    "        table.add_row([  \n",
    "            model_name,  \n",
    "            metrics['RTTR']['category'],   \n",
    "            round(metrics['RTTR']['value'], 4),  # Round for better display\n",
    "            metrics['Maas']['category'],  \n",
    "            round(metrics['Maas']['value'], 4),  \n",
    "            metrics['MATTR']['category'],  \n",
    "            round(metrics['MATTR']['value'], 4),  \n",
    "            metrics['MTLD']['category'],  \n",
    "            round(metrics['MTLD']['value'], 4), \n",
    "            metrics['Overall']  \n",
    "        ])  \n",
    "\n",
    "    print(table)\n",
    " \n",
    "# Format and display metrics in a table  \n",
    "format_metrics_to_table(model_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade73ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
